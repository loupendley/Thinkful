{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://www.thinkful.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised Learning Capstone: Build you own NLP model  \n",
    "\n",
    "For this challenge, you will need to choose a corpus of data from nltk or another source that includes categories you can predict and create an analysis pipeline that includes the following steps:\n",
    "\n",
    "For this project you'll dig into a large amount of text and apply most of what you've covered in this unit and in the course so far.\n",
    "\n",
    "1.  First, pick a set of texts. This can be either a series of novels, chapters, or articles. Anything you'd like. It just has to have multiple entries of varying characteristics. At least 100 should be good. There should also be at least 10 different authors, but try to keep the texts related (either all on the same topic of from the same branch of literature - something to make classification a bit more difficult than obviously different subjects).\n",
    "\n",
    "This capstone can be an extension of your NLP challenge if you wish to use the same corpus. If you found problems with that data set that limited your analysis, however, it may be worth using what you learned to choose a new corpus. Reserve 25% of your corpus as a test set.\n",
    "\n",
    "The first technique is to create a series of clusters. Try several techniques and pick the one you think best represents your data. Make sure there is a narrative and reasoning around why you have chosen the given clusters. Are authors consistently grouped into the same cluster?\n",
    "\n",
    "2.  Next, perform some unsupervised feature generation and selection using the techniques covered in this unit and elsewhere in the course. Using those features then build models to attempt to classify your texts by author. Try different permutations of unsupervised and supervised techniques to see which combinations have the best performance.\n",
    "\n",
    "3.  Lastly return to your holdout group. Does your clustering on those members perform as you'd expect? Have your clusters remained stable or changed dramatically? What about your model? Is it's performance consistent?\n",
    "\n",
    "If there is a divergence in the relative stability of your model and your clusters, delve into why.\n",
    "\n",
    "Your end result should be a write up of how clustering and modeling compare for classifying your texts. What are the advantages of each? Why would you want to use one over the other? Approximately 3-5 pages is a good length for your write up, and remember to include visuals to help tell your story!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My authors:\n",
    "\n",
    "1. John Buchan\n",
    "    2. The Thirty-nine Steps (10 chapters) URL: http://www.gutenberg.org/cache/epub/558/pg558.txt\n",
    "    2. Mr. Standfast (22 chapters) URL: https://www.gutenberg.org/ebooks/560.txt.utf-8\n",
    "    \n",
    "1. Edgar Rice Burroughs\n",
    "   2. Tarzan of the Apes (28 chapters) URL: https://www.gutenberg.org/ebooks/78.txt.utf-8\n",
    "   2. Son of Tarzan (27 chapters) URL: https://www.gutenberg.org/ebooks/90.txt.utf-8\n",
    "   \n",
    "1. Alexander Dumas\n",
    "   2. The Count of Monte Cristo (117 chapters) URL: https://www.gutenberg.org/files/1184/1184-0.txt\n",
    "   2. The Three Muskateers (66 chapters) URL: https://www.gutenberg.org/files/1257/1257-0.txt\n",
    "   \n",
    "1. H. Rider Haggard\n",
    "   2. King Solomon's Mines (20 chapters) URL: https://www.gutenberg.org/ebooks/2166.txt.utf-8\n",
    "   2. Finished (23 chapters) https://www.gutenberg.org/ebooks/1724.txt.utf-8\n",
    "\n",
    "1. Anthony Hope\n",
    "   2. The Prisoner of Zennda (22 chapters) URL: https://www.gutenberg.org/files/95/95-0.txt\n",
    "   2. Rupert of Hentzau (21 chapters) URL: https://www.gutenberg.org/files/1145/1145-0.txt\n",
    "   \n",
    "1. Rudyard Kipling\n",
    "   2. Kim (15 chapters) URL: https://www.gutenberg.org/ebooks/2226.txt.utf-8\n",
    "   2. Captains Courageous (10 chapters) URL: https://www.gutenberg.org/ebooks/2225.txt.utf-8\n",
    "   \n",
    "1. Talbot Mundy\n",
    "   2. King of the Kyber Rifles (28 chapters) URL: https://www.gutenberg.org/files/6066/6066-0.txt\n",
    "   2. Lion of Petra (13 chapters) URL: https://www.gutenberg.org/ebooks/19307.txt.utf-8\n",
    "   \n",
    "1. Baroness Orczy\n",
    "   2. The Scarlet Pimpernel (31 chapters) URL: https://www.gutenberg.org/ebooks/60.txt.utf-8\n",
    "   2. The Elusive Pimpernel (35 chapters) URL: https://www.gutenberg.org/files/2785/2785-0.txt\n",
    "   \n",
    "1. Jules Verne\n",
    "   2. Around the World in Eighty Days (37 chapters) URL: https://www.gutenberg.org/ebooks/103.txt.utf-8\n",
    "   2. Five Weeks in a Balloon (44 chapters) URL: https://www.gutenberg.org/files/3526/3526-0.txt\n",
    "   \n",
    "1. Edgar Wallace\n",
    "   2. Bones in London (12 chapters) URL: https://www.gutenberg.org/ebooks/27525.txt.utf-8\n",
    "   2. The Book of All-Power (19 chapters) URL: https://www.gutenberg.org/ebooks/24920.txt.utf-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions that need answering:\n",
    "\n",
    " 1. What question are you trying to solve (or prove wrong) ?   \n",
    " __No questions to answer for this challenge.__\n",
    " 1. What kind of data do you have? -> describe the source.. \n",
    " __Sentiment analaysis, using bag of words, tfidf, Random Forest, Bernoulli Naive Bayes, and Multinomial Naive Bayes.__\n",
    " 1. Do some EDA, plots\n",
    " 1. What's missing from the data and how do you deal with it?  \n",
    " __No missing data here.__\n",
    " 1. How can you add, change, or remove features to get more out of your data?  \n",
    " __No added features here; it's sentiment analysis.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Report Template\n",
    "\n",
    "#### \n",
    "\n",
    "\n",
    "#### Key Learning. \n",
    "You cannot always improve on a model for even 5 percentage points.  Especially when using bag of words which has no configurable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "max_iterations         = 10            # set it to > 0 for determining the features inportance\n",
    "random_state           = 57\n",
    "rows_in_training_set   = 10000\n",
    "rows_in_test_set       = 200000\n",
    "test_size              = 0.10\n",
    "train_size             = 0.90\n",
    "rfc_test_size          = 50000\n",
    "rfc_train_size         = 5000\n",
    "sample_size            = 10\n",
    "run_CountVectorizer    = False\n",
    "run_TfidfVectorizer    = True\n",
    "BegTimeStampNewlines   = 3\n",
    "EndTimeStampNewlines   = 3\n",
    "EndTimeStamp           = '\\n'*EndTimeStampNewlines+'End'\n",
    "BegTimeStamp           = 'End'+'\\n'*BegTimeStampNewlines\n",
    "SustainerSTDDEVLimit   = 0.020\n",
    "\n",
    "num_clusters = 3\n",
    "target_column = 'yyyy'\n",
    "xcolumnname = 'xxxx'\n",
    "CrossValidations = 5 # We are using 5 cross validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Controls for running sentiment_analyzer\n",
    "flag_to_run_rf = False\n",
    "flag_to_plot_them = False\n",
    "flag_to_run_correlation_matrix = False\n",
    "flag_to_run_features_importance = False\n",
    "flag_to_run_gradient_boosting  = False\n",
    "flag_to_run_linear_regression  = False\n",
    "flag_to_run_logistic_regression = False\n",
    "flag_to_run_lasso_regression = False\n",
    "flag_to_run_ridge_regression = False\n",
    "flag_to_run_svc = False\n",
    "flag_to_run_vectorizer_nb = False\n",
    "flag_to_run_sentiment_analyzer = False\n",
    "flag_to_run_affinity_propagation = False\n",
    "flag_to_run_kmeans = False\n",
    "flag_to_run_mean_shift = False\n",
    "flag_to_run_spectral_clustering = False\n",
    "flag_to_run_elbow_plot = False\n",
    "\n",
    "debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'chardet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-73b0b92cb5a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mchardet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'chardet'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import chardet\n",
    "import datetime\n",
    "from sklearn import datasets, ensemble, metrics, linear_model\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "import time, sys\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, GridSearchCV,cross_val_score, train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler, normalize\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import pairwise_distances, mean_squared_error\n",
    "from sklearn.cluster import AffinityPropagation, KMeans, MeanShift, estimate_bandwidth, SpectralClustering\n",
    "from scipy.spatial.distance import cdist\n",
    "import spacy\n",
    "import re\n",
    "from nltk.corpus import gutenberg, stopwords\n",
    "import nltk\n",
    "from collections import Counter\n",
    "import gensim\n",
    "from gensim.models import word2vec\n",
    "import random\n",
    "\n",
    "nltk.download('gutenberg') # Load the gutenberg nltk works\n",
    "nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# add this to a dictionary\n",
    "# Constants\n",
    "max_iterations         = 10            # set it to > 0 for determining the features inportance\n",
    "random_state           = 57\n",
    "test_size              = 0.10\n",
    "train_size             = 0.90\n",
    "\n",
    "begin_string = '\\n'*3+'Begin'\n",
    "end_string = 'End'+'\\n'*3\n",
    "\n",
    "# Regression/Classification control\n",
    "Regression = False \n",
    "\n",
    "print(\"Regression = {}\".format(Regression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_row', 1000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_time_to_complete():\n",
    "    objects = ('BernoulliNB', 'MultinomialNB', 'Logistic Regression')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    performance = [18,17,32]\n",
    "\n",
    "    plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('Time in Minutes')\n",
    "    plt.title('Yelp Sentiment Analysis Time to Complete')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def file_stuff():\n",
    "    # Use this for stand-alone file\n",
    "    \n",
    "    path = \"../../../../\"\n",
    "    filename = \"Datafiles/bostonmarathon/results/2013/results.csv\"\n",
    "    print(\"fullfilename = {}\".format(path+filename))\n",
    "    df = pd.read_csv(path+filename)\n",
    "    print(\"There are {} rows in this file.\".format(df.shape[0]))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    '''\n",
    "    # Utility function for standard text cleaning.\n",
    "    '''\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    \n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def load_clean_parse_group_gutenberg(gutenberg_file, author, percent_of_file): \n",
    "    \"\"\"\n",
    "    # currently, this function handles:\n",
    "    #    Persuasion, Austen\n",
    "    #    Alice In Wonderland Austen\n",
    "    #    Paradise Lost Milton\n",
    "    #    Moby Dick Melville\n",
    "    \"\"\"\n",
    "\n",
    "    # Load and clean the data.\n",
    "    if gutenberg_file == \"persuasion\":\n",
    "        file_to_load = gutenberg.raw('austen-persuasion.txt')\n",
    "        book = re.sub(r'Chapter \\d+', '', persuasion)\n",
    "    elif gutenberg_file == \"alice\":\n",
    "        file_to_load = gutenberg.raw('carroll-alice.txt')\n",
    "        book = re.sub(r'CHAPTER .*', '', file_to_load)\n",
    "    elif gutenberg_file == \"paradise\":\n",
    "        file_to_load = gutenberg.raw('milton-paradise.txt')\n",
    "        book = re.sub(r'BOOK .*', '', file_to_load)\n",
    "    elif gutenberg_file == \"moby\":\n",
    "        file_to_load = gutenberg.raw('melville-moby_dick.txt')\n",
    "        book = re.sub(r'BOOK .*', '', file_to_load)\n",
    "\n",
    "    book = text_cleaner(book[:int(len(book)/percent_of_file)])\n",
    "    \n",
    "    nlp = spacy.load('en')\n",
    "    book_doc = nlp(book)\n",
    "    \n",
    "    print(\"book_doc datatype is {}\".format(type(book_doc)))\n",
    "    \n",
    "#     book_sents = pd.DataFrame() # I just added this\n",
    "#     book_sents = [[sent, author] for sent in book_doc.sents]\n",
    "    return pd.DataFrame([[sent, author] for sent in book_doc.sents]), book_doc\n",
    "    \n",
    "#     return book_sents, book_doc # previously, I had return pd.DataFrame(book_sents), book_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def parse_gutenberg(book):\n",
    "    '''\n",
    "    # Parse the cleaned novels\n",
    "    '''\n",
    "    \n",
    "    nlp = spacy.load('en')\n",
    "#     book_doc = nlp(book)\n",
    "\n",
    "    return nlp(book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def group_gutenberg(book_doc, author):\n",
    "    '''\n",
    "    # Group into sentences.\n",
    "    '''\n",
    "    print(\"book_doc datatype is {}\".format(type(book_doc)))\n",
    "    \n",
    "    book_sents = [[sent, author] for sent in book_doc.sents]\n",
    "\n",
    "    # Combine the sentences from the two novels into one data frame.\n",
    "#     sentences = pd.DataFrame(book_sents)\n",
    "    if debug:\n",
    "        sentences.head()\n",
    "        \n",
    "    return pd.DataFrame(book_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def dataset_cleanup(df):\n",
    "\n",
    "    # data Cleanup --> last used for the Boston Marathon challenge\n",
    "    \n",
    "#     Left over from the Boston Marathon challenge...\n",
    "  \n",
    "    df['gender_int'] = np.where(df['gender'] == 'M', 1, 0).astype(float)\n",
    "    df['bib_int'] = df['bib'].replace(to_replace=r'[W|F]', value='-', regex=True).astype(int)\n",
    "    kcolumns = ['5k', '10k', '20k', '25k', '30k', '35k', '40k', 'half']\n",
    "    for kcol in kcolumns:\n",
    "        df[kcol] = np.where(df[kcol] == '-', 0, df[kcol])\n",
    "        df[kcol] = df[kcol].astype(float)\n",
    "    df['5kpace']   = df['5k']/5.0\n",
    "    df['10kpace']  = df['10k']/10.0\n",
    "    df['20kpace']  = df['20k']/20.0\n",
    "    df['halfpace'] = df['half']/21.095\n",
    "    df['25kpace']  = df['25k']/25.0\n",
    "    df['30kpace']  = df['30k']/30.0\n",
    "    df['35kpace']  = df['35k']/35.0\n",
    "    df['40kpace']  = df['40k']/40.0\n",
    "    df['officialpace'] = df['official']/42.19\n",
    "    # df['raceavg'] = ,axis=0).mean()\n",
    "    df['racestd'] = df[['5kpace','10kpace','20kpace','halfpace','25kpace','30kpace','35kpace','40kpace','officialpace']].std(axis=1)\n",
    "    df['raceavg'] = df[['5kpace','10kpace','20kpace','halfpace','25kpace','30kpace','35kpace','40kpace','officialpace']].mean(axis=1)\n",
    "#     X = df[['age', 'gender_int','genderdiv', 'country', 'official','racestd','raceavg']]\n",
    "#     X = pd.get_dummies(X)\n",
    "\n",
    "    df.drop('ctz', axis=1, inplace=True)\n",
    "    df.drop('state',axis=1, inplace=True)\n",
    "    # these are the 2% sustainers.  They can be running at any pace, but they are consistent!\n",
    "    df['sustainer'] = np.where(df['racestd'] <= SustainerSTDDEVLimit, 1, 0).astype(float) # they sustained their pace very well for the race\n",
    "    scaler = MinMaxScaler()\n",
    "    \n",
    "    scaler.fit(df[['age']])\n",
    "    df['age_scaled'] = scaler.transform(df[['age']]).astype(float)\n",
    "    \n",
    "    scaler.fit(df[['overall']])\n",
    "    df['overall_scaled'] = scaler.transform(df[['overall']]).astype(float)\n",
    "    \n",
    "    scaler.fit(df[['pace']])\n",
    "    df['pace_scaled'] = scaler.transform(df[['pace']])\n",
    "    \n",
    "    scaler.fit(df[['official']])\n",
    "    df['official_scaled'] = scaler.transform(df[['official']]).astype(float)\n",
    "    \n",
    "    display('columns are now', df.columns)\n",
    "#     df = fcn_MinMaxScaler(df, 'age', 'age_scaled')\n",
    "#     df = fcn_MinMaxScaler(df, 'official', 'official_scaled')\n",
    "    X = df[['age_scaled', 'sustainer', 'gender_int', 'racestd']]\n",
    "#     X = pd.get_dummies(X)\n",
    "   \n",
    "    \n",
    "    display(\"df columns cpt 92310: \", df.columns)\n",
    "    \n",
    "    global target_column, xcolumnname, ycolumnname\n",
    "    \n",
    "#     target_column = 'overall_scaled'\n",
    "#     xcolumnname = 'age_scaled'\n",
    "    ycolumnname = target_column\n",
    "    \n",
    "    y = df[target_column]\n",
    "    printFormatted(\"target, y column is {}\".format(target_column))\n",
    "\n",
    "    if debug == True:\n",
    "        print_timestamp(\"X and y variables created\")\n",
    "        \n",
    "    printFormatted('we have cleaned up the dataframe.')\n",
    "    display_column_names('df values', df)\n",
    "    display_column_names('X values', X)\n",
    "    return df, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def printFormatted(string):\n",
    "    newline = '\\n'\n",
    "    display(Markdown(string))\n",
    "    write_to_logfile(string+newline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def fcn_MinMaxScaler(dataframe, orig_column, new_column):\n",
    "    display(\"cp 1: In fcn_MinMaxScaler.  shape is:\", dataframe.shape)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(dataframe[['{}'.format(orig_column)]])\n",
    "    dataframe[['{}'.format(new_column)]] = scaler.transform(dataframe['{}'.format(orig_column)])\n",
    "    display(\"cp 2: In fcn_MinMaxScaler.  shape is:\", dataframe.shape)\n",
    "    \n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_facet():\n",
    "    g = sns.FacetGrid(data=df, col='stars')\n",
    "    g.map(plt.hist, 'message_length', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def write_to_logfile(message, mdformat=''):\n",
    "    bufsize = 0\n",
    "    with open('TestResults.md', 'a+') as the_file:\n",
    "        the_file.write('{} {}'.format(mdformat, message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_model_accuracy():\n",
    "    objects = ('BernoulliNB', 'MultinomialNB', 'Logistic Regression')\n",
    "    y_pos = np.arange(len(objects))\n",
    "    performance = [75.81,85.98,91.08]\n",
    "\n",
    "    plt.bar(y_pos, performance, align='center', alpha=0.5)\n",
    "    plt.xticks(y_pos, objects)\n",
    "    plt.ylabel('Accuracy Percent')\n",
    "    plt.title('Yelp Sentiment Analysis Accuracy')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def print_timestamp(displaytext):    \n",
    "    import sys\n",
    "    import datetime\n",
    "    datetime_now = str(datetime.datetime.now())\n",
    "    printFormatted(\"{:19.19}: In: {} {} \".format(datetime_now, sys._getframe(1).f_code.co_name, displaytext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def return_current_datetime():\n",
    "    datetime_now = str(datetime.datetime.now())\n",
    "    return datetime_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def data_demographics(dataframe, num_rows):\n",
    "\n",
    "    display(\"dataframe.isnull().sum()\", dataframe.isnull().sum())\n",
    "\n",
    "    display(\"dataframe.columns\\n\", dataframe.columns)\n",
    "    display(\"dataframe.head({})\\n\".format(num_rows), dataframe.head(num_rows))\n",
    "\n",
    "    display(\"dataframe.sample({})\\n\".format(num_rows), dataframe.sample(num_rows))\n",
    "    display(\"dataframe.dtypes\\n\", dataframe.dtypes)\n",
    "    display(\"dataframe.describe()\\n\", dataframe.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_them():\n",
    "    for column in X_train.columns:\n",
    "#         plt.hist(X_train[column]*100, bins=40)\n",
    "        plt.scatter(y_train, X_train[column]*100)\n",
    "        plt.xlabel(column)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def rfc_and_feature_importances(rf):    # Here we are using Random Forest classifier method to determine the top 30 features.\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, train_size=train_size)\n",
    "    \n",
    "    ## Fit the model on your training data.\n",
    "    rf.fit(X_train, y_train) \n",
    "    \n",
    "    ## And score it on your testing data.\n",
    "    rf.score(X_test, y_test)\n",
    "\n",
    "    feature_importance = rf.feature_importances_\n",
    "\n",
    "    # Make importances relative to max importance.\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    cols=X.columns[sorted_idx].tolist() \n",
    "    cols=cols[::-1]\n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "    plt.yticks(pos, X.columns[sorted_idx])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.title('Variable Importance')\n",
    "    plt.show()\n",
    "#     print(\"We are returning these columns {}\".format(cols))\n",
    "    return cols[:30] # return it sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def run_features_importance(rf,n):\n",
    "# Here we will return the feature importances\n",
    "    all_feature_important_columns = []\n",
    " \n",
    "    for i in range(1,n):\n",
    "        print_timestamp('running rfc iteration {} features importance for {} times'.format(i,n))\n",
    "        columns2 = rfc_and_feature_importances(rf)\n",
    "#         columns2.extend('{}'.format(i))\n",
    "        all_feature_important_columns = all_feature_important_columns + columns2\n",
    "    #     print(\"all_feature_import_columns={}\".format(all_feature_important_columns))\n",
    "\n",
    "    print(\"\\nBOD:\\nall_feature_important_columns = {}\\nEOD\".format(sorted(all_feature_important_columns)))\n",
    "    for feature in set(all_feature_important_columns):\n",
    "        print_timestamp(\"the NOC of feature {} in all_feature_important_columns is {}\".format(feature, all_feature_important_columns.count(feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def run_correlation_matrix():\n",
    "    \n",
    "    print_timestamp('Begin'+'\\n'*3)\n",
    "    \n",
    "    # Setup the correlation matrix.\n",
    "    corrmat = X.corr()\n",
    "    print(corrmat)\n",
    "\n",
    "    # Set up the subplots\n",
    "    f, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "    # Let's draw the heatmap using seaborn.\n",
    "    sns.heatmap(corrmat, vmax=.6, square=True)\n",
    "    plt.show()\n",
    "    \n",
    "    print_timestamp('\\n'*3+'End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def data_characteristics():\n",
    "    \n",
    "    printFormatted(\"#### Columns used in the dataset\")\n",
    "    display(df.columns)\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    printFormatted(\"#### Describe of the df dataset\")\n",
    "    display(df.describe())\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    printFormatted(\"#### Sample of 10 from the dataset\")\n",
    "    display(df.sample(sample_size))\n",
    "\n",
    "    print(\"\\n\\n\")\n",
    "    printFormatted(\"#### Number of nulls in X\")\n",
    "    display(X.isnull().sum())\n",
    "    print(\"\\n\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def training_test_set(X, y):\n",
    "#     global X_train, X_test, y_train, y_test\n",
    "    # Let's fit it with the RFC training set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, train_size=train_size, random_state=0)\n",
    "    print(\"train_size = {}, X_train is {}, and y_train is {}\".format(train_size, len(X_train), len(y_train)))\n",
    "    print(\"test_size  = {}, X_test  is {}, and y_test is {}\".format(test_size, len(X_test), len(y_test)))\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def run_rf(X_train=None, X_test=None, y_train=None, y_test=None, params=None, cross_validate=None):\n",
    "    \n",
    "    rfc = ensemble.RandomForestClassifier(n_estimators=1000)\n",
    "    if params != None:\n",
    "        print(\"In run_rf, params = {}\".format(params)) \n",
    "        rfc.set_params(**params)\n",
    "        \n",
    "    ## Fit the model on your training data.\n",
    "    rfc_fit = rfc.fit(X_train, y_train)  \n",
    "    \n",
    "    #   Let's score it with the test data set    this is new 13-Aug-2019\n",
    "    print_training_and_test_scores(rfc_fit, X_train, X_test, y_train, y_test) # new on 13-Aug-2019\n",
    "    \n",
    "#   Let's produce the metrics scores\n",
    "    print_metrics_score(rfc_fit, X_train, X_test, y_train, y_test) # new on 13-Aug-2019\n",
    "    \n",
    "#   Let's run cross validation \n",
    "    if cross_validate == True:\n",
    "        print_cross_validation_scores(rfc_fit, X_train, X_test, y_train, y_test)\n",
    "        \n",
    "#   Let's run the confusion matrix\n",
    "    if confusion_matrix == True:\n",
    "        confusion_matrix_function(rfc_fit, X_train, X_test, y_train, y_test)\n",
    "    \n",
    "#     ## Let's score it with the training data set\n",
    "#     train_score = rfc.score(X_train, y_train)\n",
    "#     printFormatted(\"### Training score = {:.2%}\".format(train_score))\n",
    "\n",
    "#     ## Let's score it with the test data set\n",
    "#     test_score = rfc.score(X_test, y_test)\n",
    "#     printFormatted(\"### Test score = {:.2%}\".format(test_score))\n",
    "    \n",
    "#     metrics_train_score = metrics.accuracy_score(y_train, y_pred_class2)\n",
    "#     metrics_test_score =  metrics.accuracy_score(y_test, y_pred_class)\n",
    "\n",
    "#     printFormatted('###  Metrics train accuracy score = {:.2%} with {}'.format(metrics_train_score, 'Random Forest Classifier'))\n",
    "#     printFormatted('###  Metrics test accuracy score = {:.2%} with {}'.format(metrics_test_score, 'Random Forest Classifier'))\n",
    "    \n",
    "#     if cross_validate == True:\n",
    "#         accuracy = cross_val_score(rfc, X_train, y_train, scoring='accuracy', cv = 5)\n",
    "#         printFormatted(\"### Cross validation scores:  {}\".format(accuracy))\n",
    "#         printFormatted(\"### Accuracy of Model with Cross Validation average is: {:.2%}\".format(accuracy.mean()))\n",
    "        \n",
    "#     #   Let's produce the metrics scores\n",
    "#     print_metrics_score(mnb_fit, X_train, X_test, y_train, y_test) # new on 13-Aug-2019\n",
    "      \n",
    "    print_timestamp('End run_rfr part 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def run_BernoulliNB(X_train=None, X_test=None, y_train=None, y_test=None, params=None, cross_validate=None):\n",
    "    \n",
    "    # Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "\n",
    "    # Instantiate our model and store it in a new variable.\n",
    "    bnb = BernoulliNB()\n",
    "\n",
    "    # Fit our model to the data.\n",
    "    bnb_fit = bnb.fit(X_train, y_train)\n",
    "\n",
    "    # Classify, storing the result in a new variable.\n",
    "#     y_pred = bnb.predict(data)\n",
    "#     y_pred = bnb.predict(X_train)\n",
    "\n",
    "    # Display our results.\n",
    "#     print(\"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "#        X_train.shape[0],\n",
    "#         (y_test != y_pred).sum() \n",
    "#     ))\n",
    "    \n",
    "#   Let's score it with the test data set    this is new 13-Aug-2019\n",
    "    print_training_and_test_scores(bnb_fit, X_train, X_test, y_train, y_test) # new on 13-Aug-2019\n",
    "    \n",
    "#   Let's produce the metrics scores\n",
    "    print_metrics_score(bnb_fit, X_train, X_test, y_train, y_test) # new on 13-Aug-2019\n",
    "    \n",
    "#   Let's run cross validation \n",
    "    if cross_validate == True:\n",
    "        print_cross_validation_scores(bnb_fit, X_train, X_test, y_train, y_test)\n",
    "        \n",
    "#   Let's run the confusion matrix\n",
    "    if confusion_matrix == True:\n",
    "        confusion_matrix_function(bnb_fit, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def sentiment_analyzer(path, parameters, classifier, tfidf_parms, X_train=None, X_test=None, y_train=None, y_test=None, cross_validate=None):\n",
    "    # path A = the old path\n",
    "    # path B = the new path, no CountVectorizer at all\n",
    "    \n",
    "# run block of code and catch warnings\n",
    "  \n",
    "    if debug == True:\n",
    "        print_timestamp(BegTimeStamp+\" running with path={}\".format(path))\n",
    "    \n",
    "    global vectorized\n",
    "    vectorized = True\n",
    "    \n",
    "    pipeline_array = []\n",
    "   \n",
    "    if path == \"A\":\n",
    "        if classifier == 'bnb':\n",
    "            pipeline_array.append(Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(**tfidf_parms)),\n",
    "                ('clf',   BernoulliNB(**parameters))\n",
    "            ]))\n",
    "        elif classifier == 'svc':\n",
    "            pipeline_array.append(Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(**tfidf_parms)),\n",
    "                ('clf',   SVC(kernel = 'linear', **parameters))\n",
    "            ])) \n",
    "        elif classifier == 'mlb':\n",
    "            pipeline_array.append(Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(**tfidf_parms)),\n",
    "                ('clf',   MultinomialNB(**parameters))\n",
    "            ]))\n",
    "        elif classifier == 'logit':\n",
    "            pipeline_array.append(Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(**tfidf_parms)),\n",
    "                ('clf',   LogisticRegression(**parameters))\n",
    "            ]))\n",
    "        elif classifier == 'rfc':\n",
    "            pipeline_array.append(Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(**tfidf_parms)),\n",
    "                ('clf',   ensemble.RandomForestClassifier(**parameters))\n",
    "            ]))  \n",
    "            \n",
    "    elif path == \"B\":\n",
    "        if classifier == 'bnb':\n",
    "            pipeline_array.append(Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(**tfidf_parms)),\n",
    "                ('clf',   BernoulliNB(**parameters))\n",
    "            ]))\n",
    "        elif classifier == 'svc':\n",
    "            pipeline_array.append(Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(**tfidf_parms)),\n",
    "                ('clf',   SVC(kernel = 'linear', **parameters))\n",
    "            ])) \n",
    "        elif classifier == 'mlb':\n",
    "            pipeline_array.append(Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(**tfidf_parms)),\n",
    "                ('clf',   MultinomialNB(**parameters))\n",
    "            ]))\n",
    "        elif classifier == 'logit':\n",
    "            pipeline_array.append(Pipeline([\n",
    "                ('tfidf', TfidfVectorizer()),\n",
    "                ('clf',   LogisticRegression(**parameters))\n",
    "            ]))\n",
    "        elif classifier == 'rfc':\n",
    "            pipeline_array.append(Pipeline([\n",
    "                ('tfidf', TfidfVectorizer(**tfidf_parms)),\n",
    "                ('clf',   ensemble.RandomForestClassifier(**parameters))\n",
    "            ]))\n",
    "\n",
    "    pipe = pipeline_array[0]\n",
    "    \n",
    "    try:\n",
    "        vect_name_list = str(pipe.named_steps['vect']).split('(')\n",
    "        vect_name = \"vect = {}, \".format(vect_name_list[0])\n",
    "    except:\n",
    "        vect_name = ''\n",
    "\n",
    "    classifier_name_list=str(pipe.named_steps['clf']).split('(')\n",
    "    classifier_name=classifier_name_list[0]\n",
    "    tfidf_name_list = str(pipe.named_steps['tfidf']).split('(')\n",
    "    if len(tfidf_name_list) > 0:\n",
    "        tfidf_name = tfidf_name_list[0]\n",
    "    else:\n",
    "        tfidf_name = ''\n",
    "\n",
    "    printFormatted(\"###  Now running with: {} tfidf={} and clf={} {}\\nparameters={} \\n\\n tfidf_parms={}\".format( vect_name,\n",
    "                                                                                                tfidf_name,\n",
    "                                                                                                classifier_name,\n",
    "                                                                                                return_current_datetime(),\n",
    "                                                                                                parameters,\n",
    "                                                                                                tfidf_parms\n",
    "                                                                                                ))\n",
    "    pipefit = pipe.fit(X_train, y_train)\n",
    "\n",
    "#   Let's score it with the test data set    this is new 13-Aug-2019\n",
    "    print_training_and_test_scores(pipefit, X_train, X_test, y_train, y_test) # new on 13-Aug-2019\n",
    "    \n",
    "#   Let's produce the metrics scores\n",
    "    print_metrics_score(pipefit, X_train, X_test, y_train, y_test) # new on 13-Aug-2019\n",
    "    \n",
    "#   Let's run cross validation \n",
    "    if cross_validate == True:\n",
    "        print_cross_validation_scores(pipefit, X_train, X_test, y_train, y_test)\n",
    "        \n",
    "#   Let's run the confusion matrix\n",
    "    if confusion_matrix == True:\n",
    "        confusion_matrix_function(pipefit, X_train, X_test, y_train, y_test)\n",
    "            \n",
    "    if debug == True:\n",
    "        printFormatted(\"Steps information: {}\".format(pipe.steps))\n",
    "        print_timestamp(\"Finished running pipeline with:\\n{}: \".format(classifier_name))\n",
    "        \n",
    "    print_timestamp(EndTimeStamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def print_training_and_test_scores(model, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    ## Let's score it with the test data set    this is new 13-Aug-2019\n",
    "    training_score = model.score(X_train, y_train) \n",
    "    printFormatted(\"### Training score = {:.2%}\".format(training_score))\n",
    "    \n",
    "    ## Let's score it with the test data set  this is new 13-Aug-2019\n",
    "    test_score = model.score(X_test, y_test)\n",
    "    printFormatted(\"### Test score = {:.2%}\".format(test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def print_metrics_score(fit_model, X_train, X_test, y_train, y_test):\n",
    "    y_pred_class  = fit_model.predict(X_test)\n",
    "    metrics_test_score =  metrics.accuracy_score(y_test, y_pred_class)\n",
    "    printFormatted('###  Metrics test accuracy score = {:.2%}'.format(metrics_test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def print_cross_validation_scores(fit_model, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "        accuracy = cross_val_score(fit_model, X_train, y_train, scoring='accuracy', cv = 5)\n",
    "        printFormatted(\"### Cross validation scores:  {}\".format(accuracy))\n",
    "        printFormatted(\"### Accuracy of Model with Cross Validation average is: {:.2%}\".format(accuracy.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def run_gradient_boosting():\n",
    "\n",
    "    print_timestamp('Begin')\n",
    "    \n",
    "    clf = ensemble.GradientBoostingClassifier(**params)\n",
    "\n",
    "    #Let's run cross validate score with the training data set\n",
    "    cross_val_score(clf, X_train, y_train, cv=5)\n",
    "\n",
    "    loss_function = 'deviance' # could be exponential\n",
    "    depth_value = 8\n",
    "    params = {'n_estimators': 500,\n",
    "              'max_depth': 8,\n",
    "              'loss_function': loss_function,\n",
    "              'max_leaf_nodes': depth_value, # 8 worked best...\n",
    "              'min_samples_leaf': depth_value * 3\n",
    "              ,'random_state' : random_state\n",
    "             }\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    predict_train = clf.predict(X_train)\n",
    "    predict_test = clf.predict(X_test)\n",
    "    \n",
    "    print_timestamp('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def run_svc(X_train=None, X_test=None, y_train=None, y_test=None, cross_validate=None, params=None):\n",
    "\n",
    "    print_timestamp('\\n'*3+'Begin run_svc')\n",
    "    \n",
    "    # Let's do a linear Support Vector Classifier\n",
    "    print_timestamp('Running SVC(kernel=linear')\n",
    "    svm = SVC(kernel = 'linear')\n",
    "    \n",
    "    if params == True:\n",
    "        print(\"In run_rf, params = {}\".format(params)) \n",
    "        svm.set_params(**params)\n",
    "    \n",
    "    # Let's fit the training model\n",
    "    print_timestamp('Running svm.fit')\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Let's score the training set\n",
    "    print_timestamp('Running svm.score for the training set')\n",
    "    svm_training_score = svm.score(X_train, y_train)\n",
    "    printFormatted(\"###  SVM Training score={:.2%}\".format(svm_training_score))\n",
    "\n",
    "    # Let's score the test set\n",
    "    print_timestamp('Running svm.fit for the test set')\n",
    "    svm_test_score = svm.score(X_test, y_test)\n",
    "    printFormatted(\"###  SVM Test score={:.2%}\".format(svm_test_score))\n",
    "\n",
    "    if cross_validate == True:\n",
    "        accuracy = cross_val_score(svm, X_train, y_train, scoring='accuracy', cv = 5)\n",
    "        printFormatted(\"### Cross validation scores:  {}\".format(accuracy))\n",
    "        printFormatted(\"### Accuracy of Model with Cross Validation average is: {:.2%}\".format(accuracy.mean()))\n",
    "\n",
    "    print_timestamp('\\n'*3+'End run_svc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def run_logistic_regression():\n",
    "    print_timestamp('\\n'*3+'Begin')\n",
    "\n",
    "    lr = LogisticRegression(C=1e20, solver='lbfgs', max_iter=1000)\n",
    "\n",
    "    print_timestamp('Running lr.fit for the training set')\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    print_timestamp('Running lr.fit for the training set')\n",
    "    print('\\nR-squared simple model training set yields:')\n",
    "    print(lr.score(X_train, y_train))\n",
    "    print(\"here comes the test set\")\n",
    "    lrscore = lr.score(X_test, y_test)\n",
    "    printFormatted(\"###  Logistic Regression score={:.2%}\".format(lrscore))\n",
    "    \n",
    "    print_timestamp('\\n'*3+'End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def run_linear_regression():\n",
    "\n",
    "    print_timestamp('\\n'*3+'Begin')\n",
    "\n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "    print_timestamp('Running regr.fit for the training set')\n",
    "    regr.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"\\nCoeffecients: \\n\", regr.coef_)\n",
    "    print(\"\\nIntercept: \\n\", regr.intercept_)\n",
    "    print(\"\\nR-squared for training data set:\")\n",
    "    print(regr.score(X_train, y_train))\n",
    "    \n",
    "    print(\"\\nR-squared for test data set:\")\n",
    "    print(regr.score(X_test, y_test))\n",
    "    \n",
    "    print_timestamp('End run_linear_regression.\\n\\n')\n",
    "    \n",
    "    print_timestamp('\\n'*3+'End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def run_ridge_regression():\n",
    "    # Fitting a ridge regression model. Alpha is the regularization\n",
    "    # parameter (usually called lambda). As alpha gets larger, parameter\n",
    "    # shrinkage grows more pronounced. Note that by convention, the\n",
    "    # intercept is not regularized. Since we standardized the data\n",
    "    # earlier, the intercept should be equal to zero and can be dropped.\n",
    "    print_timestamp('\\n'*3+'Begin')\n",
    "    \n",
    "    ridgeregr = linear_model.Ridge(alpha=10, fit_intercept=False) \n",
    "    ridgeregr.fit(X_train, y_train)\n",
    "    print(ridgeregr.score(X_train, y_train))\n",
    "\n",
    "    print_timestamp('\\n'*3+'End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def run_affinity_propagation(data, target):\n",
    "      \n",
    "    print_timestamp('\\n'*3+'starting AffinityPropagation')\n",
    "\n",
    "    print_timestamp('\\n'*3+'Begin')\n",
    "    \n",
    "    ap = AffinityPropagation()\n",
    "#     ap = AffinityPropagation(damping=0.5,\n",
    "#                          max_iter=200,\n",
    "#                          convergence_iter=15,\n",
    "#                          copy=True,\n",
    "#                          preference=None,\n",
    "#                          affinity='euclidean',\n",
    "#                          verbose=False) \n",
    "\n",
    "    model = ap.fit(data)\n",
    "    pred = ap.predict(data)\n",
    "\n",
    "    Z = merge_predict_and_cluster(data, target, pred) # let's merge the data dataframe, prediction, and the cluster\n",
    "    \n",
    "    # Pull the number of clusters and cluster assignments for each data point.\n",
    "    cluster_centers_indices = ap.cluster_centers_indices_\n",
    "    n_clusters_ = len(cluster_centers_indices)\n",
    "    labels = ap.labels_\n",
    "    \n",
    "    print('Estimated number of clusters: {}'.format(n_clusters_))\n",
    "\n",
    "    labels = model.labels_\n",
    "    \n",
    "    print(\"from run_affinity_propagation {}\".format(metrics.silhouette_score(data, labels, metric='euclidean')))\n",
    "    \n",
    "    print_timestamp('\\n'*3+'finished with AffinityPropagation')\n",
    "    \n",
    "    return Z, n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "pycharm": {
     "is_executing": false
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def run_kmeans(data, target, K):\n",
    "\n",
    "    print_timestamp('\\n'*3+'Begin')\n",
    "    print(\"running with number of clusters = {}\".format(K))\n",
    "    km = KMeans(n_clusters=K, random_state=42)\n",
    "\n",
    "#     pred = KMeans(n_clusters=K, random_state=42).fit_predict(data)\n",
    "    pred = km.fit_predict(data)\n",
    "#     Z = pd.DataFrame()\n",
    "    Z = merge_predict_and_cluster(data, target, pred) # let's merge the data dataframe, prediction, and the cluster\n",
    "#     Z = pd.merge(data, pd.DataFrame(pred), left_index=True, right_index=True)\n",
    "#     display_column_names('first Z values', Z)\n",
    "#     Z.rename(columns={Z.columns[-1]: 'cluster'}, inplace=True)\n",
    "#     display_column_names('second Z values', Z)\n",
    "#     Z = pd.merge(Z, target, left_index=True, right_index=True)\n",
    "#     display_column_names('third Z values', Z)\n",
    "#     print(\"z columns are {}\".format(Z.columns))\n",
    "\n",
    "    if debug == True:  \n",
    "        print(\"the shape of Kmeans_pred is {}, and the shape of X is {}, and the shape of Z is {}\".format(pred.shape,\n",
    "                                                                                                      data.shape,\n",
    "                                                                                                      Z.shape))\n",
    "        display(Z.head(100))\n",
    "        display_column_names('Z below values', Z)\n",
    "\n",
    "        count = Z.groupby(['cluster']).count() \n",
    "        display(\"Z: Count by clusters are this:\\n\", count) \n",
    "  \n",
    "    return Z\n",
    "        \n",
    "    print_timestamp('\\n'*3+'End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def merge_predict_and_cluster(dataframe, target, predict):\n",
    "    Z = pd.merge(dataframe, target, left_index=True, right_index=True)\n",
    "    Z = pd.merge(Z, pd.DataFrame(predict), left_index=True, right_index=True)\n",
    "    Z.rename(columns={Z.columns[-1]: 'cluster'}, inplace=True)\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def confusion_matrix_function(model_fit, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    y_pred_class  = model_fit.predict(X_test)\n",
    "    \n",
    "    conf_matrix = confusion_matrix_function(y_test, y_pred_class)\n",
    "    printFormatted(\"### Confusion Matrix:  {}\".format(conf_matrixscores))\n",
    "    \n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def run_spectral_clustering(data, target, K):\n",
    "    display_dataframe_shape('entering run_spectral_clustering, data has shape of:', data)\n",
    "    display_dataframe_shape('entering run_spectral_clustering, target has shape of:', target)\n",
    "    print_timestamp('\\n'*3+'Begin')\n",
    "    \n",
    "#     for clusternum in range(2, K):\n",
    "    print_timestamp(\"Running spectral_clustering with {} clusters.\".format(K))\n",
    "    n_clusters=K\n",
    "\n",
    "    # Declare and fit the model.\n",
    "    sc = SpectralClustering(n_clusters=K)\n",
    "    sc.fit(data)\n",
    "\n",
    "    #Predicted clusters.\n",
    "    predict=sc.fit_predict(data)\n",
    "\n",
    "    Z = merge_predict_and_cluster(data, target, predict) # let's merge the data dataframe, prediction, and the cluster\n",
    "\n",
    "    if debug == True:\n",
    "        display_dataframe_shape('in run_spectral_clustering, Z has shape of:', Z)\n",
    "        display_dataframe_shape('in run_spectral_clustering, target has shape of:', target)\n",
    "        display(\"the datatypes of Z are\", Z.dtypes)\n",
    "\n",
    "#     plt.scatter(Z['cluster'], Z[target_column], c=Z['cluster'])\n",
    "#     plt.show()\n",
    "\n",
    "    labels = sc.labels_\n",
    "    print(\"from spectral clustering {}\".format(metrics.silhouette_score(data, labels, metric='euclidean')))\n",
    "\n",
    "#     print('Comparing the assigned categories to the ones in the data:')\n",
    "#     print(pd.crosstab(target,predict))\n",
    "    \n",
    "    print_timestamp('\\n'*3+'End')\n",
    "    \n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def do_the_elbow(X):\n",
    "    printFormatted(\"## We are plotting the elbow method!\")\n",
    "    # calculate distortion for a range of number of cluster\n",
    "    distortions = []\n",
    "    for i in range(1, 11):\n",
    "        km = KMeans(\n",
    "            n_clusters=i, init='random',\n",
    "            n_init=10, max_iter=300,\n",
    "            tol=1e-04, random_state=0\n",
    "        )\n",
    "        km.fit(X)\n",
    "        distortions.append(km.inertia_)\n",
    "\n",
    "    # plot\n",
    "    plt.plot(range(1, 11), distortions, marker='o')\n",
    "    plt.xlabel('Number of clusters')\n",
    "    plt.ylabel('Distortion')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_it_clusters(dataframe, xvalue, yvalue, title):\n",
    "    \n",
    "    if debug == True:\n",
    "        display_dataframe_shape('entry received in plot_it_clusters', dataframe)\n",
    "        display(dataframe.dtypes)\n",
    "\n",
    "    data_demographics(dataframe, 10)\n",
    "        \n",
    "    plt.rcParams['figure.figsize'] = [xvalue, yvalue]\n",
    "    plt.xlabel(xcolumnname)\n",
    "    plt.ylabel(ycolumnname)\n",
    "    \n",
    "    df0 = dataframe[dataframe.cluster == 0]\n",
    "    df1 = dataframe[dataframe.cluster == 1]\n",
    "    df2 = dataframe[dataframe.cluster == 2]\n",
    "    df3 = dataframe[dataframe.cluster == 3]\n",
    "    df4 = dataframe[dataframe.cluster == 4]\n",
    "    df5 = dataframe[dataframe.cluster == 5]\n",
    "    \n",
    "    plt.scatter(df0[xcolumnname], df0[ycolumnname], color='green')\n",
    "    plt.scatter(df1[xcolumnname], df1[ycolumnname], color='red')\n",
    "    plt.scatter(df2[xcolumnname], df2[ycolumnname], color='blue')\n",
    "    plt.scatter(df3[xcolumnname], df3[ycolumnname], color='black')\n",
    "    plt.scatter(df4[xcolumnname], df4[ycolumnname], color='magenta')\n",
    "    plt.scatter(df5[xcolumnname], df5[ycolumnname], color='orange')\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "        \n",
    "#     plt.scatter(km.cluster_centers_[:,0],km.cluster_centers_[:,1],color='purple',marker='*',label='centroid')\n",
    "    \n",
    "#     if type == 'KMeans':\n",
    "#         plt.xlabel('Age')\n",
    "#         plt.ylabel('Income ($)')\n",
    "#         plt.legend()\n",
    "#         plt.scatter(km.cluster_centers[:,0], \n",
    "#                     km.cluster_centers[:,1],\n",
    "#                     marker = '*',\n",
    "#                     label = 'centroid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def run_mean_shift(data, target):\n",
    "    \n",
    "    print_timestamp('\\n'*3+'Begin')  \n",
    "\n",
    "    X_train = data\n",
    "    \n",
    "    # Here we set the bandwidth. This function automatically derives a bandwidth\n",
    "    # number based on an inspection of the distances among points in the data.\n",
    "    bandwidth = estimate_bandwidth(X_train, quantile=0.2, n_samples=500)\n",
    "\n",
    "    # Declare and fit the model.\n",
    "    ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "    if debug == True:\n",
    "        display_dataframe_shape('this is the shape of data coming into run_mean_shift', data)\n",
    "    ms.fit(data)\n",
    "\n",
    "    if debug == True:\n",
    "        display_dataframe_shape('this is the shape of target coming into run_mean_shift', target)\n",
    "    pred = ms.predict(data)\n",
    "    if debug == True:\n",
    "        display_dataframe_shape('this is the shape of pred after predict in run_mean_shift', data)\n",
    "        \n",
    "    Z = merge_predict_and_cluster(data, target, pred) # let's merge the data dataframe, prediction, and the cluster\n",
    "\n",
    "    # Extract cluster assignments for each data point.\n",
    "    labels = ms.labels_\n",
    "\n",
    "    print(\"from mean shift {}\".format(metrics.silhouette_score(data, labels, metric='euclidean')))\n",
    "    \n",
    "    # Coordinates of the cluster centers.\n",
    "    cluster_centers = ms.cluster_centers_\n",
    "\n",
    "    # Count our clusters.\n",
    "    n_clusters_ = len(np.unique(labels))\n",
    "\n",
    "    print(\"Number of estimated clusters: {}\".format(n_clusters_))\n",
    "    \n",
    "    print_timestamp('\\n'*3+'End')\n",
    "    \n",
    "    return Z, n_clusters_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def run_tfidf_vectorizer(df, max_df=0.5, min_df=2, stop_words='english', lowercase=True, use_idf=True, norm=u'l2', smooth_idf=True):\n",
    "    print_timestamp(\"in run_tfidf_vectorizer: df is a {} datatype.\".format(type(df)))\n",
    "    vectorizer = TfidfVectorizer(\n",
    "                             max_df=max_df, # drop words that occur in more than half the paragraphs\n",
    "                             min_df=min_df, # only use words that appear at least twice\n",
    "                             stop_words=stop_words, \n",
    "                             lowercase=lowercase, #convert everything to lower case (since Alice in Wonderland has the HABIT of CAPITALIZING WORDS for EMPHASIS)\n",
    "                             use_idf=use_idf,#we definitely want to use inverse document frequencies in our weighting\n",
    "                             norm=norm, #Applies a correction factor so that longer paragraphs and shorter paragraphs get treated equally\n",
    "                             smooth_idf=smooth_idf #Adds 1 to all document frequencies, as if an extra document existed that used every word once.  Prevents divide-by-zero errors\n",
    "                            )\n",
    "\n",
    "    #Applying the vectorizer\n",
    "    tfidf_df = vectorizer.fit(df)\n",
    "    \n",
    "    return tfidf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    # Visual inspection identifies a form of punctuation spaCy does not\n",
    "    # recognize: the double dash '--'.  Better get rid of it now!\n",
    "    text = re.sub(r'--',' ',text)\n",
    "    text = re.sub(\"[\\[].*?[\\]]\", \"\", text)\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def bag_of_words(text):\n",
    "    \n",
    "    # Filter out punctuation and stop words.\n",
    "    allwords = [token.lemma_\n",
    "                for token in text\n",
    "                if not token.is_punct\n",
    "                and not token.is_stop]\n",
    "    \n",
    "    # Return the most common words.\n",
    "    return [item[0] for item in Counter(allwords).most_common(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def bow_features_dev(sentences, common_words):\n",
    "    display(sentences.head(10))\n",
    "    num_sentences_to_print = 10\n",
    "    print(\"inside bow_features: sentences is a {} datatype, of {} length,\\nand common_words is a {} datatype of {} length.\"\n",
    "          .format(type(sentences), sentences.shape[0], type(common_words), len(common_words)))\n",
    "    print(\"here come {} sentences: {}\".format(num_sentences_to_print, sentences[0:num_sentences_to_print]))\n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    print(\"in bow_features: sentences.iloc[0] = {}\".format(sentences.iloc[0]))\n",
    "    df['text_sentence'] = sentences.iloc[0] # this could be the problem\n",
    "    df['text_source'] = sentences.iloc[1]   # this too could be the problem...\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    num_values = len(list(enumerate(df['text_sentence'])))\n",
    "    print(\"There are {} enumerated items for iterations.\".format(num_values))\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return pd.DataFrame(df)\n",
    "\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def bow_features(sentences, common_words):\n",
    "  \n",
    "    # Scaffold the data frame and initialize counts to zero.\n",
    "    df = pd.DataFrame(columns=common_words)\n",
    "    df['text_sentence'] = sentences[0] # this could be the problem\n",
    "    df['text_source'] = sentences[1]   # this too could be the problem...\n",
    "    df.loc[:, common_words] = 0\n",
    "    \n",
    "    # Process each row, counting the occurrence of words in each sentence.\n",
    "    for i, sentence in enumerate(df['text_sentence']):\n",
    "        \n",
    "        # Convert the sentence to lemmas, then filter out punctuation,\n",
    "        # stop words, and uncommon words.\n",
    "        words = [token.lemma_\n",
    "                 for token in sentence\n",
    "                 if (\n",
    "                     not token.is_punct\n",
    "                     and not token.is_stop\n",
    "                     and token.lemma_ in common_words\n",
    "                 )]\n",
    "        \n",
    "        # Populate the row with word counts.\n",
    "        for word in words:\n",
    "            df.loc[i, word] += 1\n",
    "        \n",
    "        # This counter is just to make sure the kernel didn't hang.\n",
    "        if i % 50 == 0:\n",
    "            print(\"Processing row {}\".format(i))\n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def run_mnb(X_train=None, X_test=None, y_train=None, y_test=None, cross_validate=None, params=None):\n",
    "\n",
    "    mnb = MultinomialNB()\n",
    "    \n",
    "    if params == True:\n",
    "        print(\"In run_rf, params = {}\".format(params)) \n",
    "        mnb.set_params(**params)\n",
    "        \n",
    "    mnb_fit = mnb.fit(X_train, y_train)\n",
    "        \n",
    "#     training_score = mnb.score(X_train, y_train) \n",
    "#     printFormatted(\"### Training score = {:.2%}\".format(training_score))\n",
    "    \n",
    "#      ## Let's score it with the test data set\n",
    "#     test_score = mnb.score(X_test, y_test)\n",
    "    \n",
    "    #   Let's score it with the test data set    this is new 13-Aug-2019\n",
    "    print_training_and_test_scores(mnb_fit, X_train, X_test, y_train, y_test) # new on 13-Aug-2019\n",
    "    \n",
    "#   Let's produce the metrics scores\n",
    "    print_metrics_score(mnb_fit, X_train, X_test, y_train, y_test) # new on 13-Aug-2019\n",
    "    \n",
    "    if cross_validate == True:\n",
    "        print_cross_validation_scores(mnb_fit, X_train, X_test, y_train, y_test)\n",
    "        \n",
    "    if confusion_matrix == True:\n",
    "        confusion_matrix_function(mnb_fit, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def word2vec_function(sentences, workers=4, min_count=10, window=6, sg=0, sample=1e-3, size=300, hs=1):\n",
    "# import gensim\n",
    "# from gensim.models import word2vec\n",
    "# original values from the curriculum:\n",
    "# workers = 4, min_count=10, window=6, sg=0, sample=1e-3, size=300, hs=1\n",
    "\n",
    "    model = word2vec.Word2Vec(\n",
    "        sentences,\n",
    "        workers=workers,     # Number of threads to run in parallel (if your computer does parallel processing).\n",
    "        min_count=min_count,  # Minimum word count threshold.\n",
    "        window=window,      # Number of words around target word to consider.\n",
    "        sg=sg,          # Use CBOW because our corpus is small.\n",
    "        sample=sample ,  # Penalize frequent words.\n",
    "        size=size,      # Word vector length.\n",
    "        hs=hs           # Use hierarchical softmax.\n",
    "    )\n",
    "\n",
    "    print('done!')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def vectorizer_nb(type_of_vectorizer):\n",
    "\n",
    "    print_timestamp(BegTimeStamp)\n",
    "    \n",
    "    # 1. import and instantiate CountVectorizer (with the default parameters)\n",
    "\n",
    "    # 2. instantiate CountVectorizer (vectorizer)\n",
    "\n",
    "#     X = df.message\n",
    "#     y = df.sentiment_label\n",
    "\n",
    "    # split X and y into training and testing sets\n",
    "    # by default, it splits 75% training and 25% test\n",
    "    # random_state=1 for reproducibility\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "    # 3. fit & transform\n",
    "    if type_of_vectorizer == 'Count':\n",
    "        print(\"We are running with CountVectorizer\")\n",
    "        vectorizer = CountVectorizer()\n",
    "        vectorizer.fit(X_train)\n",
    "        vectorizer_method = 'CountVectorizer'\n",
    "    elif type_of_vectorizer == 'Tfidf':\n",
    "        print(\"We are running with TfidfVectorizer\")\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectorizer.fit_transform(X_train)\n",
    "        vectorizer_method = 'TfidfVectorizer'\n",
    "    \n",
    "    # 4. transform training data\n",
    "    X_train_dtm = vectorizer.transform(X_train)\n",
    "\n",
    "    # equivalently: combine fit and transform into a single step\n",
    "    # this is faster and what most people would do\n",
    "    X_train_dtm = vectorizer.fit_transform(X_train)\n",
    "\n",
    "    # 4. transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "    X_test_dtm = vectorizer.transform(X_test)\n",
    "\n",
    "    # 1. import\n",
    "\n",
    "    # 2. instantiate a Multinomial Naive Bayes model\n",
    "    nb = MultinomialNB()\n",
    "\n",
    "    # 3. train the model \n",
    "    # using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "\n",
    "    nb.fit(X_train_dtm, y_train)\n",
    "    \n",
    "    \n",
    "    # 4. make class predictions for X_test_dtm\n",
    "    y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "    # calculate accuracy of class predictions\n",
    "\n",
    "    met_test_score = metrics.accuracy_score(y_test, y_pred_class)\n",
    "    printFormatted('###  With {} vectorizer, the metrics accuracy score = {:.2%}'.format(vectorizer_method,\n",
    "                                                                                         met_test_score))\n",
    "    \n",
    "    print_timestamp(EndTimeStamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def display_column_names(label, df):\n",
    "    display(\"Label: {}: Column names are:\".format(label), df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def display_datatype(var):\n",
    "    # this function just returns the data type of the variable var\n",
    "    return \"{}\".format(type(var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def display_dataframe_shape(label, df):\n",
    "    display(\"Label: {}: Dataframe shape is:\".format(label), df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def run_it(X_train, X_test, y_train, y_test, y):\n",
    "    \n",
    "#     file_stuff()\n",
    "    \n",
    "#     data_cleanup()\n",
    "    \n",
    "    print_timestamp('\\n'*3+'Begin')\n",
    "    \n",
    "    if Regression == True:\n",
    "        print_timestamp(\"We are running with a Regression model\")\n",
    "    elif Regression == False:\n",
    "        print_timestamp(\"We are running with a Classifier model\")\n",
    "    else:\n",
    "        print_timestamp(\"We have failed to set the Regression variable\")\n",
    "        sys.exit(main())\n",
    "        \n",
    "\n",
    "    if flag_to_plot_them == True:\n",
    "        plot_them()\n",
    "\n",
    "    if flag_to_run_features_importance == True:\n",
    "        \n",
    "        number_of_features_to_consider = 50\n",
    "        params = {'n_estimators': 100}\n",
    "\n",
    "        if Regression == True:\n",
    "            print_timestamp('We are running RandomForestRegressor')\n",
    "            rf = ensemble.RandomForestRegressor(**params)\n",
    "            \n",
    "        else:\n",
    "            print_timestamp('We are running RandomForestClassifier')\n",
    "            rf = ensemble.RandomForestClassifier(**params)\n",
    "\n",
    "        run_features_importance(rf, number_of_features_to_consider)\n",
    "\n",
    "    if flag_to_run_correlation_matrix == True:\n",
    "        run_correlation_matrix()\n",
    "        \n",
    "    if flag_to_run_sentiment_analyzer == True:\n",
    "        path = \"B\"\n",
    "\n",
    "\n",
    "        for path in ['A']:\n",
    "            for vectorizer_iterator in ['logit', 'mlb', 'bnb']:\n",
    "                if vectorizer_iterator == 'rfc':\n",
    "                    sentiment_analyzer(path=path, parameters=params, classifier=vectorizer_iterator, tfidf_parms=tfidf_parms)\n",
    "\n",
    "                elif vectorizer_iterator == 'bnb':\n",
    "                    parameters = {}\n",
    "                    sentiment_analyzer(path=path, parameters=parameters, classifier=vectorizer_iterator, tfidf_parms=tfidf_parms)\n",
    "\n",
    "                elif vectorizer_iterator == 'mlb':\n",
    "                    parameters = {}\n",
    "                    sentiment_analyzer(path=path, parameters=parameters, classifier=vectorizer_iterator, tfidf_parms=tfidf_parms)\n",
    "\n",
    "                elif vectorizer_iterator == 'logit': # newton-cg took too long. sag and saga about the same as lbfgs.\n",
    "                    tfidf_parms = {'max_features' :  10000 } # determined this through iterative testing\n",
    "                    parameters = {'C' :1e20, 'solver': 'lbfgs', 'max_iter': 1000} # max_iter=100 reports warning, try 1000\n",
    "                    sentiment_analyzer(path=path, parameters=parameters, classifier=vectorizer_iterator, tfidf_parms=tfidf_parms)\n",
    "\n",
    "                elif vectorizer_iterator == 'svc':\n",
    "                    parameters = {}\n",
    "                    sentiment_analyzer(path=path, parameters=parameters, classifier=vectorizer_iterator, tfidf_parms=tfidf_parms)\n",
    "                    if confusion_matrix != None:\n",
    "                        confusion_matrix_function(y_test, y_pred_class)\n",
    "\n",
    "    if flag_to_run_rf == True:\n",
    "        #     params = {}\n",
    "        params = {'n_estimators': 100} \n",
    "\n",
    "        if Regression == True:\n",
    "            rf = ensemble.RandomForestRegressor(**params)\n",
    "            print_timestamp('We are running RandomForestRegressor')\n",
    "        else:\n",
    "            rf = ensemble.RandomForestClassifier(**params)\n",
    "            print_timestamp('We are running RandomForestClassifier')\n",
    "\n",
    "        run_rf(rf)\n",
    "\n",
    "    if flag_to_run_gradient_boosting  == True:\n",
    "        run_gradient_boosting()\n",
    "\n",
    "    if flag_to_run_linear_regression  == True:\n",
    "        run_linear_regression()\n",
    "\n",
    "    if flag_to_run_logistic_regression == True:\n",
    "        run_logistic_regression()\n",
    "\n",
    "    if flag_to_run_svc == True:\n",
    "        run_svc() \n",
    "\n",
    "    if flag_to_run_ridge_regression == True:\n",
    "        run_ridge_regression()\n",
    "        \n",
    "    if flag_to_run_vectorizer_nb == True:\n",
    "        for vectorizer_iterator in ['Count', 'Tfidf']:\n",
    "            vectorizer_nb(vectorizer_iterator)\n",
    "        \n",
    "    if flag_to_run_kmeans == True:\n",
    "        method = KMeans(\n",
    "             n_clusters=num_clusters\n",
    "#                 ,random_state=42\n",
    "#                 ,init='random'\n",
    "#                 ,n_init=10\n",
    "#                 ,max_iter=300\n",
    "#                 ,tol=1e-04 \n",
    "        )\n",
    "        df1 = run_kmeans(X_train, y_train, num_clusters)\n",
    "        plot_it_clusters(df1, xvalue=16, yvalue=16, title=\"KMeans with number of clusters = {}\".format(num_clusters))\n",
    "        display(\"next plot please\")\n",
    "\n",
    "    if flag_to_run_affinity_propagation == True:\n",
    "        display_column_names('columns of X_train going into affinity_propagation: ', X_train)\n",
    "        df2, ap_num_clusters = run_affinity_propagation(X_train, y_train)\n",
    "        plot_it_clusters(df2, xvalue=16, yvalue=16, title=\"Affinity Propagation with number of clusters = {}\".format(ap_num_clusters))\n",
    "        \n",
    "    if flag_to_run_mean_shift == True:\n",
    "        df3, mean_shift_num_clusters = run_mean_shift(X_train, y_train)\n",
    "        plot_it_clusters(df3, xvalue=16, yvalue=16, title=\"Mean Shift with number of clusters = {}\".format(mean_shift_num_clusters))\n",
    "    \n",
    "    if flag_to_run_spectral_clustering == True:\n",
    "        df4 = run_spectral_clustering(X_train, y_train, K=num_clusters)\n",
    "        plot_it_clusters(df4, xvalue=16, yvalue=16,title=\"Spectral clustering with number of clusters = {}\".format(num_clusters) )\n",
    "\n",
    "    print_timestamp('End'+'\\n'*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def main(entry_point):\n",
    "        \n",
    "    if entry_point == 0:\n",
    "        print_timestamp(\"Starting main()\")\n",
    "        df = file_stuff()\n",
    "        data_demographics(df, 5)\n",
    "        display_column_names('post data_demographics of df', df)\n",
    "        df, X, y = dataset_cleanup(df)\n",
    "        display_column_names('post dataset_cleanup on X', X)\n",
    "        data_demographics(df, 5)\n",
    "        display_column_names('post data_demographics on X #2', X)\n",
    "#         make_X_and_Y()\n",
    "        X_train, X_test, y_train, y_test = training_test_set(X, y)\n",
    "        display_column_names('after training_test_set: columns of X_train going into affinity_propagation: ', X_train)\n",
    "#         data_characteristics()\n",
    "#         plot_time_to_complete()\n",
    "#         plot_model_accuracy()\n",
    "#         plot_facet()\n",
    "\n",
    "    if flag_to_run_elbow_plot == True:    do_the_elbow(X)\n",
    "    run_it(X_train, X_test, y_train, y_test, y)\n",
    "        \n",
    "    print_timestamp(\"Ending main()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def do_word_counts_from_text_files(gutenberg_books, regex=None, book_divisor=1 ):\n",
    "    print_timestamp(\"Starting main_nlp()\")\n",
    "      \n",
    "    sentences = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    book_list = [('milton-paradise.txt',r'BOOK .*') , ('melville-moby_dick.txt',r'BOOK .*',)]\n",
    "#     gutenberg_books is a list of files on the computer\n",
    "    for book in book_list:\n",
    "#     paradise_book = 'milton-paradise.txt'\n",
    "#     moby_book = 'melville-moby_dick.txt'\n",
    "\n",
    "        book - gutenberg.raw(book)\n",
    "        book = re.sub(book[1],'', book)\n",
    "#     paradise = gutenberg.raw(paradise_book)\n",
    "#     paradise = re.sub(r'BOOK .*', '', paradise)\n",
    "\n",
    "#     moby = gutenberg.raw(moby_book)\n",
    "#     moby = re.sub(r'BOOK .*', '', moby)\n",
    "        book = text_cleaner(book[:int(len(book)/book_divisor)])\n",
    "\n",
    "\n",
    "    paradise = text_cleaner(paradise[:int(len(paradise)/paradise_divisor)])\n",
    "    moby     = text_cleaner(moby[:int(len(moby)/moby_divisor)])\n",
    "\n",
    "    if debug == True:\n",
    "        print(\"length of paradise is {}, and length of moby is {}.\".format(len(paradise), len(moby)))\n",
    "\n",
    "    paradise_doc = nlp(paradise)\n",
    "    moby_doc = nlp(moby)\n",
    "\n",
    "    paradise_sents = [[sent, \"Milton\"] for sent in paradise_doc.sents]\n",
    "    moby_sents = [[sent, \"Melville\"] for sent in moby_doc.sents]\n",
    "\n",
    "    print(\"paradise_sents is a {} datatype, and moby_sents is a {} datatype.\".format(display_datatype(paradise_sents), display_datatype(moby_sents)))\n",
    "    # a better way to do this is with pd.append... from https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html\n",
    "#     >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n",
    "#     >>> df\n",
    "#        A  B\n",
    "#     0  1  2\n",
    "#     1  3  4\n",
    "#     >>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n",
    "#     >>> df.append(df2, ignore_index=True)\n",
    "#            A  B\n",
    "#         0  1  2\n",
    "#         1  3  4\n",
    "#         2  5  6\n",
    "#         3  7  8\n",
    "    sentences = pd.DataFrame(paradise_sents + moby_sents) \n",
    "    sentences = pd.DataFrame(paradise_sents)\n",
    "    sentences.append(moby_sents, ignore_index=True)\n",
    "    \n",
    "    if debug == True:\n",
    "        display(\"Here is a sample from sentences:\\n\", sentences.sample(20))  \n",
    "        print(\"sentences is a {} datatype.\".format(display_datatype(sentences)))\n",
    "        sentences.head(30)\n",
    "\n",
    "    paradisewords = bag_of_words(paradise_doc)\n",
    "    mobywords = bag_of_words(moby_doc)\n",
    "    common_words = list(set(paradisewords + mobywords))\n",
    "    word_counts = bow_features(sentences, common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def main_nlp(entry_point):\n",
    "    \n",
    "    # this function was specifically designed for this NLP Challenge\n",
    "    \n",
    "    if entry_point == 0:\n",
    "        confusion_matrix = None\n",
    "        \n",
    "        paradise_divisor = 20 # was 20\n",
    "        moby_divisor     = 53 # was 53\n",
    "        \n",
    "        print_timestamp(\"Starting main_nlp()\")\n",
    "        \n",
    "        paradise_book = 'milton-paradise.txt'\n",
    "        moby_book = 'melville-moby_dick.txt'\n",
    "        \n",
    "        paradise = gutenberg.raw(paradise_book)\n",
    "        paradise = re.sub(r'BOOK .*', '', paradise)\n",
    "\n",
    "        moby = gutenberg.raw(moby_book)\n",
    "        moby = re.sub(r'BOOK .*', '', moby)\n",
    "        \n",
    "        paradise = text_cleaner(paradise[:int(len(paradise)/paradise_divisor)])\n",
    "        moby     = text_cleaner(moby[:int(len(moby)/moby_divisor)])\n",
    "        \n",
    "        if debug == True:\n",
    "            print(\"length of paradise is {}, and length of moby is {}.\".format(len(paradise), len(moby)))\n",
    "        \n",
    "        paradise_doc = nlp(paradise)\n",
    "        moby_doc = nlp(moby)\n",
    "        \n",
    "        paradise_sents = [[sent, \"Milton\"] for sent in paradise_doc.sents]\n",
    "        moby_sents = [[sent, \"Melville\"] for sent in moby_doc.sents]\n",
    "\n",
    "        print(\"paradise_sents is a {} datatype, and moby_sents is a {} datatype.\".format(display_datatype(paradise_sents), display_datatype(moby_sents)))\n",
    "        sentences = pd.DataFrame(paradise_sents + moby_sents) \n",
    "        if debug == True:\n",
    "            display(\"Here is a sample from sentences:\\n\", sentences.sample(20))  \n",
    "            print(\"sentences is a {} datatype.\".format(display_datatype(sentences)))\n",
    "            sentences.head(30)\n",
    "        \n",
    "        paradisewords = bag_of_words(paradise_doc)\n",
    "        mobywords = bag_of_words(moby_doc)\n",
    "        common_words = list(set(paradisewords + mobywords))\n",
    "        word_counts = bow_features(sentences, common_words)\n",
    "        \n",
    "        if debug == True:  display(\"words_counts sample:\\n\", word_counts.sample(20))\n",
    "        word_counts['author'] = np.where(word_counts['text_source'] == 'Milton', pd.to_numeric(1), pd.to_numeric(0))\n",
    "\n",
    "        X = np.array(word_counts.drop(['text_sentence', 'text_source', 'author'], 1))\n",
    "        Y = word_counts['author']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=0)\n",
    "        \n",
    "        for runit in range(0,2):\n",
    "            if runit == 0:\n",
    "                \n",
    "                n_estimators = 100\n",
    "                \n",
    "                params = {'n_estimators': n_estimators}\n",
    "                printFormatted('## Running Random Forests with Word Counts')\n",
    "                run_rf(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, params=params, cross_validate=True)\n",
    "\n",
    "                printFormatted('## Running MultiNomial Naive Bayes with Word Counts')\n",
    "                params = {}\n",
    "                run_mnb(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, params=params, cross_validate=True)\n",
    "\n",
    "                printFormatted('## Running Bernoulli Naive Bayes with Word Counts')\n",
    "                run_BernoulliNB(X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, params=params, cross_validate=True) \n",
    "       \n",
    "            else:\n",
    "            \n",
    "                author = []\n",
    "                all_paras = []\n",
    "                for paragraph in gutenberg.paras(paradise_book):\n",
    "                    para = paragraph[0]\n",
    "                    para = [re.sub(r'--', '', word) for word in para]\n",
    "                    all_paras.append(' '.join(para))\n",
    "                    author.append('Milton')\n",
    "\n",
    "                for paragraph in gutenberg.paras(moby_book):\n",
    "                    para = paragraph[0]\n",
    "                    para = [re.sub(r'--', '', word) for word in para]\n",
    "                    all_paras.append(' '.join(para))\n",
    "                    author.append('Melville')\n",
    "\n",
    "                paragraphs = pd.DataFrame()        \n",
    "                paragraphs['paragraphs'] = all_paras\n",
    "                paragraphs['author'] = author\n",
    "                paragraphs['author'] = np.where(paragraphs['author'] == 'Milton', pd.to_numeric(1), pd.to_numeric(0))\n",
    "                \n",
    "                if debug == True:\n",
    "                    display(\"paragraphs sampe:\\n\", paragraphs.sample(20))\n",
    "                    display(\"describe paragraphs\\n\", paragraphs.describe())\n",
    "\n",
    "                X = paragraphs['paragraphs']\n",
    "                Y = paragraphs['author']\n",
    "                printFormatted('## Running with Paragraph Counts and tfidf and others')\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=0)\n",
    "                params = {}\n",
    "                tfidf_parms = {}\n",
    "                for vectorizer_iterator in ['rfc', 'bnb', 'mlb', 'svc']:\n",
    "\n",
    "                    path = 'A'\n",
    "                    if vectorizer_iterator == 'rfc':\n",
    "                        sentiment_analyzer(path=path, parameters=params, classifier=vectorizer_iterator, tfidf_parms=tfidf_parms, \n",
    "                                           X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, cross_validate=True)\n",
    "\n",
    "                    elif vectorizer_iterator == 'bnb':\n",
    "                        parameters = {}\n",
    "                        sentiment_analyzer(path=path, parameters=params, classifier=vectorizer_iterator, tfidf_parms=tfidf_parms, \n",
    "                                           X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, cross_validate=True)\n",
    "\n",
    "                    elif vectorizer_iterator == 'mlb':\n",
    "                        parameters = {}\n",
    "                        sentiment_analyzer(path=path, parameters=params, classifier=vectorizer_iterator, tfidf_parms=tfidf_parms, \n",
    "                                           X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, cross_validate=True)\n",
    "                        \n",
    "                    elif vectorizer_iterator == 'logit': # newton-cg took too long. sag and saga about the same as lbfgs.\n",
    "                        tfidf_parms = {'max_features' : 10000 } # determined this through iterative testing\n",
    "                        \n",
    "                        parameters = {'C' :1e20, 'solver': 'lbfgs', 'max_iter': 1000} # max_iter=100 reports warning, try 1000\n",
    "                        sentiment_analyzer(path=path, parameters=parameters, classifier=vectorizer_iterator, tfidf_parms=tfidf_parms, \n",
    "                                           X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, cross_validate=True)\n",
    "\n",
    "                    elif vectorizer_iterator == 'svc':\n",
    "                        parameters = {}\n",
    "                        sentiment_analyzer(path=path, parameters=parameters, classifier=vectorizer_iterator, tfidf_parms=tfidf_parms, \n",
    "                                           X_train=X_train, X_test=X_test, y_train=y_train, y_test=y_test, cross_validate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it ran ok, dude!\n"
     ]
    }
   ],
   "source": [
    "# main_nlp(0)\n",
    "print(\"it ran ok, dude!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now processing book=01_Buchan_01_ThirtyNineSteps.txt\n",
      "book_details=['01', 'Buchan', '01', 'ThirtyNineSteps.txt']\n",
      "author_number=100, book_number=10, author_booknum=110\n",
      "*** THERE ARE 749 chapters in the book 01_Buchan_01_ThirtyNineSteps.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=750, and we are in book:01_Buchan_01_ThirtyNineSteps.txt\n",
      "\n",
      "endparagraph = 749\n",
      "Now processing book=01_Buchan_02_MrStandFast.txt\n",
      "book_details=['01', 'Buchan', '02', 'MrStandFast.txt']\n",
      "author_number=100, book_number=20, author_booknum=120\n",
      "*** THERE ARE 2025 chapters in the book 01_Buchan_02_MrStandFast.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=2026, and we are in book:01_Buchan_02_MrStandFast.txt\n",
      "\n",
      "endparagraph = 2025\n",
      "Now processing book=02_Burroughs_01_TarzanOfTheApes.txt\n",
      "book_details=['02', 'Burroughs', '01', 'TarzanOfTheApes.txt']\n",
      "author_number=200, book_number=10, author_booknum=210\n",
      "*** THERE ARE 2717 chapters in the book 02_Burroughs_01_TarzanOfTheApes.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=2718, and we are in book:02_Burroughs_01_TarzanOfTheApes.txt\n",
      "\n",
      "endparagraph = 2717\n",
      "Now processing book=02_Burroughs_04_SonOfTarzan.txt\n",
      "book_details=['02', 'Burroughs', '04', 'SonOfTarzan.txt']\n",
      "author_number=200, book_number=40, author_booknum=240\n",
      "*** THERE ARE 1428 chapters in the book 02_Burroughs_04_SonOfTarzan.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=1429, and we are in book:02_Burroughs_04_SonOfTarzan.txt\n",
      "\n",
      "endparagraph = 1428\n",
      "Now processing book=03_Dumas_01_MonteCristo.txt\n",
      "book_details=['03', 'Dumas', '01', 'MonteCristo.txt']\n",
      "author_number=300, book_number=10, author_booknum=310\n",
      "*** THERE ARE 14997 chapters in the book 03_Dumas_01_MonteCristo.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=14998, and we are in book:03_Dumas_01_MonteCristo.txt\n",
      "\n",
      "endparagraph = 14997\n",
      "Now processing book=03_Dumas_02_ThreeMusketeers.txt\n",
      "book_details=['03', 'Dumas', '02', 'ThreeMusketeers.txt']\n",
      "author_number=300, book_number=20, author_booknum=320\n",
      "*** THERE ARE 8214 chapters in the book 03_Dumas_02_ThreeMusketeers.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=8215, and we are in book:03_Dumas_02_ThreeMusketeers.txt\n",
      "\n",
      "endparagraph = 8214\n",
      "Now processing book=06_Haggard_01_KingSolomonsMines.txt\n",
      "book_details=['06', 'Haggard', '01', 'KingSolomonsMines.txt']\n",
      "author_number=600, book_number=10, author_booknum=610\n",
      "*** THERE ARE 1609 chapters in the book 06_Haggard_01_KingSolomonsMines.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=1610, and we are in book:06_Haggard_01_KingSolomonsMines.txt\n",
      "\n",
      "endparagraph = 1609\n",
      "Now processing book=06_Haggard_08_Finished.txt\n",
      "book_details=['06', 'Haggard', '08', 'Finished.txt']\n",
      "author_number=600, book_number=80, author_booknum=680\n",
      "*** THERE ARE 2056 chapters in the book 06_Haggard_08_Finished.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=2057, and we are in book:06_Haggard_08_Finished.txt\n",
      "\n",
      "endparagraph = 2056\n",
      "Now processing book=07_Hope_01_PrisonerOfZenda.txt\n",
      "book_details=['07', 'Hope', '01', 'PrisonerOfZenda.txt']\n",
      "author_number=700, book_number=10, author_booknum=710\n",
      "*** THERE ARE 1753 chapters in the book 07_Hope_01_PrisonerOfZenda.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=1754, and we are in book:07_Hope_01_PrisonerOfZenda.txt\n",
      "\n",
      "endparagraph = 1753\n",
      "Now processing book=07_Hope_02_RupertOffHentzau.txt\n",
      "book_details=['07', 'Hope', '02', 'RupertOffHentzau.txt']\n",
      "author_number=700, book_number=20, author_booknum=720\n",
      "*** THERE ARE 2157 chapters in the book 07_Hope_02_RupertOffHentzau.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=2158, and we are in book:07_Hope_02_RupertOffHentzau.txt\n",
      "\n",
      "endparagraph = 2157\n",
      "Now processing book=08_Kipling_01_Kim.txt\n",
      "book_details=['08', 'Kipling', '01', 'Kim.txt']\n",
      "author_number=800, book_number=10, author_booknum=810\n",
      "*** THERE ARE 2606 chapters in the book 08_Kipling_01_Kim.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=2607, and we are in book:08_Kipling_01_Kim.txt\n",
      "\n",
      "endparagraph = 2606\n",
      "Now processing book=08_Kipling_02_CaptainsCourageous.txt\n",
      "book_details=['08', 'Kipling', '02', 'CaptainsCourageous.txt']\n",
      "author_number=800, book_number=20, author_booknum=820\n",
      "*** THERE ARE 1308 chapters in the book 08_Kipling_02_CaptainsCourageous.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=1309, and we are in book:08_Kipling_02_CaptainsCourageous.txt\n",
      "\n",
      "endparagraph = 1308\n",
      "Now processing book=12_Mundy_01_KingOfTheKhyberRifles.txt\n",
      "book_details=['12', 'Mundy', '01', 'KingOfTheKhyberRifles.txt']\n",
      "author_number=1200, book_number=10, author_booknum=1210\n",
      "*** THERE ARE 2897 chapters in the book 12_Mundy_01_KingOfTheKhyberRifles.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=2898, and we are in book:12_Mundy_01_KingOfTheKhyberRifles.txt\n",
      "\n",
      "endparagraph = 2897\n",
      "Now processing book=12_Mundy_02_LionOfPetra.txt\n",
      "book_details=['12', 'Mundy', '02', 'LionOfPetra.txt']\n",
      "author_number=1200, book_number=20, author_booknum=1220\n",
      "*** THERE ARE 1529 chapters in the book 12_Mundy_02_LionOfPetra.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=1530, and we are in book:12_Mundy_02_LionOfPetra.txt\n",
      "\n",
      "endparagraph = 1529\n",
      "Now processing book=13_Orczy_01_ScarletPimpernel.txt\n",
      "book_details=['13', 'Orczy', '01', 'ScarletPimpernel.txt']\n",
      "author_number=1300, book_number=10, author_booknum=1310\n",
      "*** THERE ARE 2082 chapters in the book 13_Orczy_01_ScarletPimpernel.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=2083, and we are in book:13_Orczy_01_ScarletPimpernel.txt\n",
      "\n",
      "endparagraph = 2082\n",
      "Now processing book=13_Orczy_03_Elusive Pimpernel.txt\n",
      "book_details=['13', 'Orczy', '03', 'Elusive Pimpernel.txt']\n",
      "author_number=1300, book_number=30, author_booknum=1330\n",
      "*** THERE ARE 2036 chapters in the book 13_Orczy_03_Elusive Pimpernel.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=2037, and we are in book:13_Orczy_03_Elusive Pimpernel.txt\n",
      "\n",
      "endparagraph = 2036\n",
      "Now processing book=16_Verne_01_AroundTheWorldInEightyDays.txt\n",
      "book_details=['16', 'Verne', '01', 'AroundTheWorldInEightyDays.txt']\n",
      "author_number=1600, book_number=10, author_booknum=1610\n",
      "*** THERE ARE 1727 chapters in the book 16_Verne_01_AroundTheWorldInEightyDays.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=1728, and we are in book:16_Verne_01_AroundTheWorldInEightyDays.txt\n",
      "\n",
      "endparagraph = 1727\n",
      "Now processing book=16_Verne_02_Five WeeksIn_a_Balloon.txt\n",
      "book_details=['16', 'Verne', '02', 'Five WeeksIn', 'a', 'Balloon.txt']\n",
      "author_number=1600, book_number=20, author_booknum=1620\n",
      "*** THERE ARE 2841 chapters in the book 16_Verne_02_Five WeeksIn_a_Balloon.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=2842, and we are in book:16_Verne_02_Five WeeksIn_a_Balloon.txt\n",
      "\n",
      "endparagraph = 2841\n",
      "Now processing book=17_Wallace_04_BonesInLondon.txt\n",
      "book_details=['17', 'Wallace', '04', 'BonesInLondon.txt']\n",
      "author_number=1700, book_number=40, author_booknum=1740\n",
      "*** THERE ARE 2373 chapters in the book 17_Wallace_04_BonesInLondon.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=2374, and we are in book:17_Wallace_04_BonesInLondon.txt\n",
      "\n",
      "endparagraph = 2373\n",
      "Now processing book=17_Wallace_05_The BookOfAll-Power.txt\n",
      "book_details=['17', 'Wallace', '05', 'The BookOfAll-Power.txt']\n",
      "author_number=1700, book_number=50, author_booknum=1750\n",
      "*** THERE ARE 1825 chapters in the book 17_Wallace_05_The BookOfAll-Power.txt\n",
      "\n",
      " #### BREAK ENCOUNTERED !!!\n",
      "And we are at paragraph_number=1826, and we are in book:17_Wallace_05_The BookOfAll-Power.txt\n",
      "\n",
      "endparagraph = 1825\n",
      "The books have all\n",
      "Been loaded.\n",
      "Sir.\n",
      "Anything else for the evening?\n",
      "\n",
      "At the end, and there are (58949, 5) lines in paragraph_book\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>book</th>\n",
       "      <th>author_book</th>\n",
       "      <th>chapter</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>ï »¿ The Project Gutenberg EBook of The Thirty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>This eBook is for the use of anyone anywhere a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>Title : The Thirty - nine Steps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>Author : John Buchan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>Posting Date : July 30 , 2008 [ EBook # 558 ] ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>Language : English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>*** START OF THIS PROJECT GUTENBERG EBOOK THE ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>Produced by Jo Churcher .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>The Thirty - Nine Steps</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>by John Buchan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>1</td>\n",
       "      <td>Contents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>Chapter I The Man Who Died Chapter II The Milk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>TO THOMAS ARTHUR NELSON ( LOTHIAN AND BORDER H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>My Dear Tommy ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>You and I have long cherished an affection for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>J . B .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>2</td>\n",
       "      <td>Sept . 1915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>Chapter I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>The Man Who Died</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>I returned from the City about three oâ  clo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>It made me bite my lips to think of the plans ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>But from the first I was disappointed with it .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>That afternoon I had been worrying my brokers ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>About six oâ  clock I went home , dressed , ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>My flat was the first floor in a new block beh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>I was just fitting my key into the door when I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>â  Can I speak to you ? â  he said .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>I got my door open and motioned him in .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>â  Is the door locked ? â  he asked feveri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>â  Iâ  m very sorry , â  he said humbly .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    author  book  author_book  chapter  \\\n",
       "0      100    10          110        1   \n",
       "1      100    10          110        1   \n",
       "2      100    10          110        1   \n",
       "3      100    10          110        1   \n",
       "4      100    10          110        1   \n",
       "5      100    10          110        1   \n",
       "6      100    10          110        1   \n",
       "7      100    10          110        1   \n",
       "8      100    10          110        1   \n",
       "9      100    10          110        1   \n",
       "10     100    10          110        1   \n",
       "11     100    10          110        2   \n",
       "12     100    10          110        2   \n",
       "13     100    10          110        2   \n",
       "14     100    10          110        2   \n",
       "15     100    10          110        2   \n",
       "16     100    10          110        2   \n",
       "17     100    10          110        3   \n",
       "18     100    10          110        3   \n",
       "19     100    10          110        3   \n",
       "20     100    10          110        3   \n",
       "21     100    10          110        3   \n",
       "22     100    10          110        3   \n",
       "23     100    10          110        3   \n",
       "24     100    10          110        3   \n",
       "25     100    10          110        3   \n",
       "26     100    10          110        3   \n",
       "27     100    10          110        3   \n",
       "28     100    10          110        3   \n",
       "29     100    10          110        3   \n",
       "\n",
       "                                            paragraph  \n",
       "0   ï »¿ The Project Gutenberg EBook of The Thirty...  \n",
       "1   This eBook is for the use of anyone anywhere a...  \n",
       "2                     Title : The Thirty - nine Steps  \n",
       "3                                Author : John Buchan  \n",
       "4   Posting Date : July 30 , 2008 [ EBook # 558 ] ...  \n",
       "5                                  Language : English  \n",
       "6   *** START OF THIS PROJECT GUTENBERG EBOOK THE ...  \n",
       "7                           Produced by Jo Churcher .  \n",
       "8                             The Thirty - Nine Steps  \n",
       "9                                      by John Buchan  \n",
       "10                                           Contents  \n",
       "11  Chapter I The Man Who Died Chapter II The Milk...  \n",
       "12  TO THOMAS ARTHUR NELSON ( LOTHIAN AND BORDER H...  \n",
       "13                                    My Dear Tommy ,  \n",
       "14  You and I have long cherished an affection for...  \n",
       "15                                            J . B .  \n",
       "16                                        Sept . 1915  \n",
       "17                                          Chapter I  \n",
       "18                                   The Man Who Died  \n",
       "19  I returned from the City about three oâ  clo...  \n",
       "20  It made me bite my lips to think of the plans ...  \n",
       "21    But from the first I was disappointed with it .  \n",
       "22  That afternoon I had been worrying my brokers ...  \n",
       "23  About six oâ  clock I went home , dressed , ...  \n",
       "24  My flat was the first floor in a new block beh...  \n",
       "25  I was just fitting my key into the door when I...  \n",
       "26           â  Can I speak to you ? â  he said .  \n",
       "27           I got my door open and motioned him in .  \n",
       "28  â  Is the door locked ? â  he asked feveri...  \n",
       "29    â  Iâ  m very sorry , â  he said humbly .  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>book</th>\n",
       "      <th>author_book</th>\n",
       "      <th>chapter</th>\n",
       "      <th>paragraph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58919</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>\" Yes , I ' m that ,\" said Cherry , helping he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58920</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>Malcolm slapped him on the knee .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58921</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>\" You ' ve brought more from Russia than we ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58922</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>\" But not the greatest prize .\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58923</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>She shook her head .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58924</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>\" It is gone ,\" she said quietly , \" and if Ru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58925</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>He nodded .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58926</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>\" I have not even ,\" she smiled , \" poor Israe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58927</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>\" I was a careless fool ,\" growled Malcolm , \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58928</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>\" Aw !\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58929</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>\"' Broke ' is exactly the word ,\" she said che...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58930</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>He had a book in his hand -- the \" Book of All...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58931</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>\" Where ----?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58932</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>\" Found it on the road ,\" he said .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58933</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>\" You found it ?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58934</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>She reached out her hand for the volume , but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58935</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>\" I can ' t read Russian ,\" he said .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58936</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>\" THE BOOK OF ALL - POWER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58937</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>\" Herein is the magic of power and the words a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58938</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>Cherry was silent .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58939</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>\" That ' s a lie ,\" he said quietly , \" for it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58940</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>She took it from his hand , wondering , and tu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58941</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>* * * * *</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58942</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>\" That was how Kensky kept his money evidently...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58943</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>The girl turned her bewildered face to Cherry .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58944</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>\" Did you know that this was money ?\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58945</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>\" Sure ,\" he said ; \" didn ' t I start in to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58946</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>THE END</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58947</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>End of the Project Gutenberg EBook of The Book...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58948</th>\n",
       "      <td>1700</td>\n",
       "      <td>50</td>\n",
       "      <td>1750</td>\n",
       "      <td>21</td>\n",
       "      <td>*** END OF THIS PROJECT GUTENBERG EBOOK THE BO...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       author  book  author_book  chapter  \\\n",
       "58919    1700    50         1750       21   \n",
       "58920    1700    50         1750       21   \n",
       "58921    1700    50         1750       21   \n",
       "58922    1700    50         1750       21   \n",
       "58923    1700    50         1750       21   \n",
       "58924    1700    50         1750       21   \n",
       "58925    1700    50         1750       21   \n",
       "58926    1700    50         1750       21   \n",
       "58927    1700    50         1750       21   \n",
       "58928    1700    50         1750       21   \n",
       "58929    1700    50         1750       21   \n",
       "58930    1700    50         1750       21   \n",
       "58931    1700    50         1750       21   \n",
       "58932    1700    50         1750       21   \n",
       "58933    1700    50         1750       21   \n",
       "58934    1700    50         1750       21   \n",
       "58935    1700    50         1750       21   \n",
       "58936    1700    50         1750       21   \n",
       "58937    1700    50         1750       21   \n",
       "58938    1700    50         1750       21   \n",
       "58939    1700    50         1750       21   \n",
       "58940    1700    50         1750       21   \n",
       "58941    1700    50         1750       21   \n",
       "58942    1700    50         1750       21   \n",
       "58943    1700    50         1750       21   \n",
       "58944    1700    50         1750       21   \n",
       "58945    1700    50         1750       21   \n",
       "58946    1700    50         1750       21   \n",
       "58947    1700    50         1750       21   \n",
       "58948    1700    50         1750       21   \n",
       "\n",
       "                                               paragraph  \n",
       "58919  \" Yes , I ' m that ,\" said Cherry , helping he...  \n",
       "58920                  Malcolm slapped him on the knee .  \n",
       "58921  \" You ' ve brought more from Russia than we ha...  \n",
       "58922                    \" But not the greatest prize .\"  \n",
       "58923                               She shook her head .  \n",
       "58924  \" It is gone ,\" she said quietly , \" and if Ru...  \n",
       "58925                                        He nodded .  \n",
       "58926  \" I have not even ,\" she smiled , \" poor Israe...  \n",
       "58927  \" I was a careless fool ,\" growled Malcolm , \"...  \n",
       "58928                                            \" Aw !\"  \n",
       "58929  \"' Broke ' is exactly the word ,\" she said che...  \n",
       "58930  He had a book in his hand -- the \" Book of All...  \n",
       "58931                                     \" Where ----?\"  \n",
       "58932                \" Found it on the road ,\" he said .  \n",
       "58933                                  \" You found it ?\"  \n",
       "58934  She reached out her hand for the volume , but ...  \n",
       "58935              \" I can ' t read Russian ,\" he said .  \n",
       "58936                          \" THE BOOK OF ALL - POWER  \n",
       "58937  \" Herein is the magic of power and the words a...  \n",
       "58938                                Cherry was silent .  \n",
       "58939  \" That ' s a lie ,\" he said quietly , \" for it...  \n",
       "58940  She took it from his hand , wondering , and tu...  \n",
       "58941                                          * * * * *  \n",
       "58942  \" That was how Kensky kept his money evidently...  \n",
       "58943    The girl turned her bewildered face to Cherry .  \n",
       "58944              \" Did you know that this was money ?\"  \n",
       "58945  \" Sure ,\" he said ; \" didn ' t I start in to b...  \n",
       "58946                                            THE END  \n",
       "58947  End of the Project Gutenberg EBook of The Book...  \n",
       "58948  *** END OF THIS PROJECT GUTENBERG EBOOK THE BO...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus.reader.plaintext import PlaintextCorpusReader\n",
    "\n",
    "debug = None\n",
    "big_paras = []\n",
    "\n",
    "corpusdir = '/Users/lou/GITHubProjects/Thinkful/Datafiles/UnsupervisedLearningCapstone/fiction_corpus/'\n",
    "fiction_corpus = PlaintextCorpusReader(corpusdir, '.*') \n",
    "documents_stat = fiction_corpus.fileids()\n",
    "\n",
    "paragraph_book = pd.DataFrame()\n",
    "paragraph_list = []\n",
    "        \n",
    "for book in documents_stat: #documents_stat:\n",
    "    print(\"Now processing book={}\".format(book))\n",
    "    paragraph_list = []\n",
    "    paragraph_number = -1\n",
    "    EndDisplay = False\n",
    "    endparagraph = -1\n",
    "    paragraphcounter = -1\n",
    "    chapter = 1\n",
    "    book_details=book.split('_')\n",
    "    print(\"book_details={}\".format(book_details))\n",
    "    author_number = int(int(book_details[0]) * 100)\n",
    "    book_number = int(int(book_details[2]) * 10)\n",
    "    author_booknumber = int(int(book_details[0]) * 100 + int(book_details[2]) * 10)\n",
    "    print(\"author_number={}, book_number={}, author_booknum={}\".format(author_number,\n",
    "                                                                       book_number,\n",
    "                                                                       author_booknumber))\n",
    "    \n",
    "    # get the number of chapters in the book\n",
    "    for paras in fiction_corpus.paras(book): \n",
    "        paragraph = \" \".join(paras[0])\n",
    "        paragraphcounter += 1\n",
    "        if debug:    \n",
    "            print(\"paragraphcounter={}\".format(paragraphcounter))\n",
    "            print(\"paragraph={}\".format(paragraph))\n",
    "            \n",
    "        if u\"*** END\".upper() in paragraph:\n",
    "            endparagraph = paragraphcounter\n",
    "            print(\"*** THERE ARE {} chapters in the book {}\".format(endparagraph, book))\n",
    "            if debug:    \n",
    "                print(\"endparagraph = {}\".format(endparagraph))\n",
    "            break\n",
    "    \n",
    "    # iterate through all of the paragraphs in the current book\n",
    "    for paras in fiction_corpus.paras(book):\n",
    "        paragraph = \" \".join(paras[0])\n",
    "        paragraph_number += 1\n",
    "        if paragraph_number > endparagraph: # have we gone past the end of the actual book, into the Gutenberg legal stuff?\n",
    "            print(\"\\n #### BREAK ENCOUNTERED !!!\\nAnd we are at paragraph_number={}, and we are in book:{}\\n\".format(paragraph_number,book))\n",
    "            print(\"endparagraph = {}\".format(endparagraph))\n",
    "            \n",
    "            # add the paragraph_list(list) to the paragraph_book(dataframe)\n",
    "            paragraph_book = paragraph_book.append(paragraph_list, ignore_index=True)\n",
    "            paragraph_list = []\n",
    "            break\n",
    "        else:\n",
    "            if \"CHAPTER\" in paragraph.upper():\n",
    "                chapter += 1\n",
    "                if debug:  print(\"chapter is now {}\".format(chapter))\n",
    "\n",
    "            paragraph_list.append([author_number, book_number, author_booknumber, chapter, paragraph])\n",
    "print(\"The books have all\\nBeen loaded.\\nSir.\\nAnything else for the evening?\\n\")\n",
    "paragraph_book.columns = ['author','book','author_book','chapter','paragraph']\n",
    "print(\"At the end, and there are {} lines in paragraph_book\".format(paragraph_book.shape))\n",
    "\n",
    "display(paragraph_book.head(30))\n",
    "display(paragraph_book.tail(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Summary of result runs\n",
    "\n",
    "|Model|NLP Feature Generator|Training Score|:Test Score|Metrics Accuracy|Accuracy of Model|Status|\n",
    "|:----|:--------------------|:-------------|:----------|:---------------|:----------------|:----|\n",
    "|Random Forests|Word Counts|98.37|86.59|86.59|82.05| |\n",
    "|Multinomial Naive Bayes|Word Counts|97.55|92.28|92.28|88.58| |\n",
    "|Bernoulli Naive Bayes|Word Counts|82.34|83.33|83.33|76.09| |\n",
    "|Random Forests|tfidf|99.76|98.76|98.76|99.11|**Winner** |\n",
    "|Multinomial Naive Bayes|tfidf|99.11|98.76|98.76|99.11|**Winner** |\n",
    "|Bernoulli Naive Bayes|tfidf|99.05|98.76|98.76|99.11|**Winner**|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# paragraph_book.columns = ['author','booknum','author_booknum','chapter','paragraph']\n",
    "# display(paragraph_book)\n",
    "# epcr.chapters(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
