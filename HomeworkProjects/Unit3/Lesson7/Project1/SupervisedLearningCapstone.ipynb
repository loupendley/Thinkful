{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.kaggle.com/sherinclaudia/sarcastic-comments-on-reddit'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning Capstone  \n",
    "#### You're ready to put into practice everything you've learned so far.  \n",
    "\n",
    "####  First: Go out and find a dataset of interest. It could be from one of our recommended resources, some other aggregation, or scraped yourself. Just make sure it has lots of variables in it, including an outcome of interest to you.  \n",
    "\n",
    "####  Second: Explore the data. Get to know the data. Spend a lot of time going over its quirks and peccadilloes. You should understand how it was gathered, what's in it, and what the variables look like.  \n",
    "\n",
    "####  Third: Model your outcome of interest. You should try several different approaches and really work to tune a variety of models before using the model evaluation techniques to choose what you consider to be the best performer. Make sure to think about explanatory versus predictive power and experiment with both.  \n",
    "\n",
    "####  So, here is the deliverable: Prepare a slide deck and 15 minute presentation that guides viewers through your model. Be sure to cover a few specific things:  \n",
    "\n",
    "1. A specified research question your model addresses  \n",
    "1. How you chose your model specification and what alternatives you compared it to  \n",
    "1. The practical uses of your model for an audience of interest  \n",
    "1. Any weak points or shortcomings of your model  \n",
    "\n",
    "\n",
    "This presentation is not a drill. You'll be presenting this slide deck live to a group as the culmination of your work in the last two supervised learning units. As a secondary matter, your slides and / or the Jupyter notebook you use or adapt them into should be worthy of inclusion as examples of your work product when applying to jobs.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions that need answering:\n",
    "\n",
    " 1. What question are you trying to solve (or prove wrong) ?   \n",
    " __We are determining if a post was sarcastic.__\n",
    " 1. What kind of data do you have? -> describe the source.. \n",
    " __The dataset includes 1.3 million sarcastic comments from Reddit.  The data includes balanced and unbalanced   __\n",
    " 1. Do some EDA, plots\n",
    " 1. What's missing from the data and how do you deal with it?  \n",
    " __stuff.    __\n",
    " 1. Where are the outliers and why should we pay attention to them?  \n",
    " __stuff   ...__\n",
    " 1. How can you add, change, or remove features to get more out of your data?  \n",
    " __Feature importances, PCA, dropping low variance items, correlated feature pairs, features too highly correlated, feature engineering, transforming, timestamp and make a month, day, year column from it.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "max_iterations         = 10            # set it to > 0 for determining the features inportance\n",
    "random_state           = 57\n",
    "rows_in_training_set   = 10000\n",
    "rows_in_test_set       = 200000\n",
    "test_size              = 0.10\n",
    "train_size             = 0.90\n",
    "rfc_test_size          = 50000\n",
    "rfc_train_size         = 5000\n",
    "run_CountVectorizer    = False\n",
    "run_TfidfVectorizer    = True\n",
    "BegTimeStampNewlines   = 3\n",
    "EndTimeStampNewlines   = 3\n",
    "EndTimeStamp           = '\\n'*EndTimeStampNewlines+'End'\n",
    "BegTimeStamp           = 'End'+'\\n'*BegTimeStampNewlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controls\n",
    "flag_to_run_rf = False\n",
    "flag_to_plot_them = False\n",
    "flag_to_run_correlation_matrix = False\n",
    "flag_to_run_features_importance = False\n",
    "flag_to_run_gradient_boosting  = False\n",
    "flag_to_run_linear_regression  = False\n",
    "flag_to_run_logistic_regression = False\n",
    "flag_to_run_lasso_regression = False\n",
    "flag_to_run_ridge_regression = False\n",
    "flag_to_run_svc = False\n",
    "flag_to_run_vectorizer_nb = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import chardet\n",
    "import datetime\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time, sys\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression = False\n"
     ]
    }
   ],
   "source": [
    "# add this to a dictionary\n",
    "# Constants\n",
    "max_iterations         = 10            # set it to > 0 for determining the features inportance\n",
    "random_state           = 57\n",
    "test_size              = 0.10\n",
    "train_size             = 0.90\n",
    "\n",
    "begin_string = '\\n'*3+'Begin'\n",
    "end_string = 'End'+'\\n'*3\n",
    "\n",
    "# Regression/Classification control\n",
    "Regression = False \n",
    "\n",
    "print(\"Regression = {}\".format(Regression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_row', 1000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 26,709 entries in the data file Sarcasm_Headlines_Dataset.json\n",
      "columns=Index(['article_link', 'headline', 'is_sarcastic'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "file = 'Sarcasm_Headlines_Dataset.json'\n",
    "path = path=\"../../../../Datafiles/\"\n",
    "column_names = []\n",
    "\n",
    "with open(path+file, 'rb') as f:\n",
    "    result = chardet.detect(f.read()) # or readline if the file is large\n",
    "# df=pd.read_csv(path+file,encoding=result['encoding'],header=None, names = column_names)\n",
    "df = pd.read_json(path+file, lines=True)\n",
    "print(\"there are {:,} entries in the data file {}\".format(len(df), file))\n",
    "print(\"columns={}\".format(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have cleaned up the dataframe.\n"
     ]
    }
   ],
   "source": [
    "# data Cleanup\n",
    "columns_to_cleanup = []\n",
    "for column in columns_to_cleanup:\n",
    "    print(\"we are now cleaning up column {}\".format(column))\n",
    "    df[column].fillna(-1, inplace=True)\n",
    "# df['BareNuclei'] = np.where(df['BareNuclei'] == '?',-1, df['BareNuclei'])\n",
    "# df['Class'] = np.where(df['Class'] == 4, 1, 0)\n",
    "df['message'] = df['headline']\n",
    "df['sentiment_label'] = df['is_sarcastic']\n",
    "\n",
    "# convert to a numerical variable.  \n",
    "# set only the 4's and 5's to 1, which is positive, and all others to 0.\n",
    "# df['sentiment_label'] = df.sentiment.map({4:1, 5: 1, 3:0, 2: 0, 1:0})\n",
    "print('we have cleaned up the dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_timestamp_old(displaytext):    \n",
    "    import sys\n",
    "    import datetime\n",
    "    datetime_now = str(datetime.datetime.now())\n",
    "    print(\"{:19.19}: {} \".format(datetime_now, displaytext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_timestamp(displaytext):    \n",
    "    import sys\n",
    "    import datetime\n",
    "    datetime_now = str(datetime.datetime.now())\n",
    "    print(\"{:19.19}: In: {} {} \".format(datetime_now, sys._getframe(1).f_code.co_name, displaytext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printFormatted(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "article_link       0\n",
       "headline           0\n",
       "is_sarcastic       0\n",
       "message            0\n",
       "sentiment_label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>message</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/advancing...</td>\n",
       "      <td>advancing the world's women</td>\n",
       "      <td>0</td>\n",
       "      <td>advancing the world's women</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/how-meat-...</td>\n",
       "      <td>the fascinating case for eating lab-grown meat</td>\n",
       "      <td>0</td>\n",
       "      <td>the fascinating case for eating lab-grown meat</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/boxed-col...</td>\n",
       "      <td>this ceo will send your kids to school, if you...</td>\n",
       "      <td>0</td>\n",
       "      <td>this ceo will send your kids to school, if you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://politics.theonion.com/top-snake-handle...</td>\n",
       "      <td>top snake handler leaves sinking huckabee camp...</td>\n",
       "      <td>1</td>\n",
       "      <td>top snake handler leaves sinking huckabee camp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/fridays-m...</td>\n",
       "      <td>friday's morning email: inside trump's presser...</td>\n",
       "      <td>0</td>\n",
       "      <td>friday's morning email: inside trump's presser...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/airline-p...</td>\n",
       "      <td>airline passengers tackle man who rushes cockp...</td>\n",
       "      <td>0</td>\n",
       "      <td>airline passengers tackle man who rushes cockp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/facebook-...</td>\n",
       "      <td>facebook reportedly working on healthcare feat...</td>\n",
       "      <td>0</td>\n",
       "      <td>facebook reportedly working on healthcare feat...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>https://www.huffingtonpost.comhttp://www.thegu...</td>\n",
       "      <td>north korea praises trump and urges us voters ...</td>\n",
       "      <td>0</td>\n",
       "      <td>north korea praises trump and urges us voters ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jeffrey-l...</td>\n",
       "      <td>actually, cnn's jeffrey lord has been 'indefen...</td>\n",
       "      <td>0</td>\n",
       "      <td>actually, cnn's jeffrey lord has been 'indefen...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/barcelona...</td>\n",
       "      <td>barcelona holds huge protest in support of ref...</td>\n",
       "      <td>0</td>\n",
       "      <td>barcelona holds huge protest in support of ref...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://entertainment.theonion.com/nuclear-bom...</td>\n",
       "      <td>nuclear bomb detonates during rehearsal for 's...</td>\n",
       "      <td>1</td>\n",
       "      <td>nuclear bomb detonates during rehearsal for 's...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://www.theonion.com/cosby-lawyer-asks-why...</td>\n",
       "      <td>cosby lawyer asks why accusers didn't come for...</td>\n",
       "      <td>1</td>\n",
       "      <td>cosby lawyer asks why accusers didn't come for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>https://www.theonion.com/stock-analysts-confus...</td>\n",
       "      <td>stock analysts confused, frightened by boar ma...</td>\n",
       "      <td>1</td>\n",
       "      <td>stock analysts confused, frightened by boar ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/bloomberg...</td>\n",
       "      <td>bloomberg's program to build better cities jus...</td>\n",
       "      <td>0</td>\n",
       "      <td>bloomberg's program to build better cities jus...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/craig-hic...</td>\n",
       "      <td>craig hicks indicted</td>\n",
       "      <td>0</td>\n",
       "      <td>craig hicks indicted</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         article_link                                           headline  is_sarcastic                                            message  sentiment_label\n",
       "0   https://www.huffingtonpost.com/entry/versace-b...  former versace store clerk sues over secret 'b...             0  former versace store clerk sues over secret 'b...                0\n",
       "1   https://www.huffingtonpost.com/entry/roseanne-...  the 'roseanne' revival catches up to our thorn...             0  the 'roseanne' revival catches up to our thorn...                0\n",
       "2   https://local.theonion.com/mom-starting-to-fea...  mom starting to fear son's web series closest ...             1  mom starting to fear son's web series closest ...                1\n",
       "3   https://politics.theonion.com/boehner-just-wan...  boehner just wants wife to listen, not come up...             1  boehner just wants wife to listen, not come up...                1\n",
       "4   https://www.huffingtonpost.com/entry/jk-rowlin...  j.k. rowling wishes snape happy birthday in th...             0  j.k. rowling wishes snape happy birthday in th...                0\n",
       "5   https://www.huffingtonpost.com/entry/advancing...                        advancing the world's women             0                        advancing the world's women                0\n",
       "6   https://www.huffingtonpost.com/entry/how-meat-...     the fascinating case for eating lab-grown meat             0     the fascinating case for eating lab-grown meat                0\n",
       "7   https://www.huffingtonpost.com/entry/boxed-col...  this ceo will send your kids to school, if you...             0  this ceo will send your kids to school, if you...                0\n",
       "8   https://politics.theonion.com/top-snake-handle...  top snake handler leaves sinking huckabee camp...             1  top snake handler leaves sinking huckabee camp...                1\n",
       "9   https://www.huffingtonpost.com/entry/fridays-m...  friday's morning email: inside trump's presser...             0  friday's morning email: inside trump's presser...                0\n",
       "10  https://www.huffingtonpost.com/entry/airline-p...  airline passengers tackle man who rushes cockp...             0  airline passengers tackle man who rushes cockp...                0\n",
       "11  https://www.huffingtonpost.com/entry/facebook-...  facebook reportedly working on healthcare feat...             0  facebook reportedly working on healthcare feat...                0\n",
       "12  https://www.huffingtonpost.comhttp://www.thegu...  north korea praises trump and urges us voters ...             0  north korea praises trump and urges us voters ...                0\n",
       "13  https://www.huffingtonpost.com/entry/jeffrey-l...  actually, cnn's jeffrey lord has been 'indefen...             0  actually, cnn's jeffrey lord has been 'indefen...                0\n",
       "14  https://www.huffingtonpost.com/entry/barcelona...  barcelona holds huge protest in support of ref...             0  barcelona holds huge protest in support of ref...                0\n",
       "15  https://entertainment.theonion.com/nuclear-bom...  nuclear bomb detonates during rehearsal for 's...             1  nuclear bomb detonates during rehearsal for 's...                1\n",
       "16  https://www.theonion.com/cosby-lawyer-asks-why...  cosby lawyer asks why accusers didn't come for...             1  cosby lawyer asks why accusers didn't come for...                1\n",
       "17  https://www.theonion.com/stock-analysts-confus...  stock analysts confused, frightened by boar ma...             1  stock analysts confused, frightened by boar ma...                1\n",
       "18  https://www.huffingtonpost.com/entry/bloomberg...  bloomberg's program to build better cities jus...             0  bloomberg's program to build better cities jus...                0\n",
       "19  https://www.huffingtonpost.com/entry/craig-hic...                               craig hicks indicted             0                               craig hicks indicted                0"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the current time of start is 2019-06-09 23:18:24.962331\n"
     ]
    }
   ],
   "source": [
    "# Definine outcome and predictors.\n",
    "print(\"the current time of start is {}\".format(str(datetime.datetime.now())))\n",
    "\n",
    "# Make the categorical variables below into enumerated categorical variables\n",
    "for dummy_column in []: # Remove these for now...\n",
    "    df = pd.concat([df, pd.get_dummies(df[dummy_column])], axis=1)\n",
    "df.columns = df.columns.str.replace(' ', '')\n",
    "\n",
    "# y = df['Class']\n",
    "# columns_excluded = ['Class','SampleCodeNumber'] # skip Class, the label, and SampleCodeNumber, which we do not need\n",
    "# X = df.loc[:, ~df.columns.isin(columns_excluded)]\n",
    "\n",
    "# print(\"End is {}\".format(str(datetime.datetime.now())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the current time of start is 2019-06-09 23:18:24.968567\n"
     ]
    }
   ],
   "source": [
    "# Definine outcome and predictors.\n",
    "print(\"the current time of start is {}\".format(str(datetime.datetime.now())))\n",
    "\n",
    "y = df['sentiment_label']\n",
    "X = df['message']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    former versace store clerk sues over secret 'b...\n",
       "1    the 'roseanne' revival catches up to our thorn...\n",
       "2    mom starting to fear son's web series closest ...\n",
       "3    boehner just wants wife to listen, not come up...\n",
       "4    j.k. rowling wishes snape happy birthday in th...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(20)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count              26709\n",
       "unique             26602\n",
       "top       sunday roundup\n",
       "freq                  10\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_them():\n",
    "    for column in X_train.columns:\n",
    "#         plt.hist(X_train[column]*100, bins=40)\n",
    "        plt.scatter(y_train, X_train[column]*100)\n",
    "        plt.xlabel(column)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc_and_feature_importances(rf):    # Here we are using Random Forest classifier method to determine the top 30 features.\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, train_size=train_size)\n",
    "    \n",
    "    ## Fit the model on your training data.\n",
    "    rf.fit(X_train, y_train) \n",
    "    \n",
    "    ## And score it on your testing data.\n",
    "    rf.score(X_test, y_test)\n",
    "\n",
    "    feature_importance = rf.feature_importances_\n",
    "\n",
    "    # Make importances relative to max importance.\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    cols=X.columns[sorted_idx].tolist() \n",
    "    cols=cols[::-1]\n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "    plt.yticks(pos, X.columns[sorted_idx])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.title('Variable Importance')\n",
    "    plt.show()\n",
    "#     print(\"We are returning these columns {}\".format(cols))\n",
    "    return cols[:30] # return it sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_features_importance(rf,n):\n",
    "# Here we will return the feature importances\n",
    "    all_feature_important_columns = []\n",
    " \n",
    "    for i in range(1,n):\n",
    "        print_timestamp('running rfc iteration {} features importance for {} times'.format(i,n))\n",
    "        columns2 = rfc_and_feature_importances(rf)\n",
    "#         columns2.extend('{}'.format(i))\n",
    "        all_feature_important_columns = all_feature_important_columns + columns2\n",
    "    #     print(\"all_feature_import_columns={}\".format(all_feature_important_columns))\n",
    "\n",
    "    print(\"\\nBOD:\\nall_feature_important_columns = {}\\nEOD\".format(sorted(all_feature_important_columns)))\n",
    "    for feature in set(all_feature_important_columns):\n",
    "        print_timestamp(\"the NOC of feature {} in all_feature_important_columns is {}\".format(feature, all_feature_important_columns.count(feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_correlation_matrix():\n",
    "    \n",
    "    print_timestamp('Begin'+'\\n'*3)\n",
    "    \n",
    "    # Setup the correlation matrix.\n",
    "    corrmat = X.corr()\n",
    "    print(corrmat)\n",
    "\n",
    "    # Set up the subplots\n",
    "    f, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "    # Let's draw the heatmap using seaborn.\n",
    "    sns.heatmap(corrmat, vmax=.6, square=True)\n",
    "    plt.show()\n",
    "    \n",
    "    print_timestamp('\\n'*3+'End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size = 0.9, X_train is 24038, and y_train is 24038\n",
      "test_size  = 0.1, X_test  is 2671, and y_test is 2671\n"
     ]
    }
   ],
   "source": [
    "# Let's fit it with the RFC training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, train_size=train_size, random_state=0)\n",
    "print(\"train_size = {}, X_train is {}, and y_train is {}\".format(train_size, len(X_train), len(y_train)))\n",
    "print(\"test_size  = {}, X_test  is {}, and y_test is {}\".format(test_size, len(X_test), len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf(rf):\n",
    "    print_timestamp('Begin run_rf part 1')\n",
    "    \n",
    "    ## Fit the model on your training data.\n",
    "    rf.fit(X_train, y_train)   \n",
    "    \n",
    "    ## Let's score it with the training data set\n",
    "    train_score = rf.score(X_train, y_train)\n",
    "    print(\"Training score = {}\".format(train_score))\n",
    "\n",
    "    ## Let's score it with the test data set\n",
    "    test_score = rf.score(X_test, y_test)\n",
    "    \n",
    "    print(\"Test score = {}\".format(test_score))\n",
    "    #Let's run cross validate score with the training data set\n",
    "#     cross_val_score(rf, X_train, y_train, cv=5)\n",
    "    \n",
    "    print_timestamp('End run_rfr part 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try predicting with gradient boosting classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gradient_boosting():\n",
    "\n",
    "    print_timestamp('Begin')\n",
    "    \n",
    "    clf = ensemble.GradientBoostingClassifier(**params)\n",
    "\n",
    "    #Let's run cross validate score with the training data set\n",
    "    cross_val_score(clf, X_train, y_train, cv=5)\n",
    "\n",
    "    loss_function = 'deviance' # could be exponential\n",
    "    depth_value = 8\n",
    "    params = {'n_estimators': 500,\n",
    "              'max_depth': 8,\n",
    "              'loss_function': loss_function,\n",
    "              'max_leaf_nodes': depth_value, # 8 worked best...\n",
    "              'min_samples_leaf': depth_value * 3\n",
    "              ,'random_state' : random_state\n",
    "             }\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    predict_train = clf.predict(X_train)\n",
    "    predict_test = clf.predict(X_test)\n",
    "    \n",
    "    print_timestamp('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svc():\n",
    "\n",
    "    print_timestamp('\\n'*3+'Begin run_svc')\n",
    "    \n",
    "    # Let's do a linear Support Vector Classifier\n",
    "    print_timestamp('Running SVC(kernel=linear')\n",
    "    svm = SVC(kernel = 'linear')\n",
    "    \n",
    "    # Let's fit the training model\n",
    "    print_timestamp('Running svm.fit')\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Let's score the training set\n",
    "    print_timestamp('Running svm.score for the training set')\n",
    "    svm.score(X_train, y_train)\n",
    "    \n",
    "    # Let's score the test set\n",
    "    print_timestamp('Running svm.fit for the test set')\n",
    "    svm.score(X_test, y_test)\n",
    "\n",
    "    print_timestamp('\\n'*3+'End run_svc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regression():\n",
    "    print_timestamp('\\n'*3+'Begin')\n",
    "\n",
    "    lr = LogisticRegression(C=1e20, solver='lbfgs', max_iter=1000)\n",
    "\n",
    "    print_timestamp('Running lr.fit for the training set')\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    print_timestamp('Running lr.fit for the training set')\n",
    "    print('\\nR-squared simple model training set yields:')\n",
    "    print(lr.score(X_train, y_train))\n",
    "    print(\"here comes the test set\")\n",
    "    lrscore = lr.score(X_test, y_test)\n",
    "    printFormatted(\"###  Logistic Regression score={:.2%}\".format(lrscore))\n",
    "    \n",
    "    print_timestamp('\\n'*3+'End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression():\n",
    "\n",
    "    print_timestamp('\\n'*3+'Begin')\n",
    "\n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "    print_timestamp('Running regr.fit for the training set')\n",
    "    regr.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"\\nCoeffecients: \\n\", regr.coef_)\n",
    "    print(\"\\nIntercept: \\n\", regr.intercept_)\n",
    "    print(\"\\nR-squared for training data set:\")\n",
    "    print(regr.score(X_train, y_train))\n",
    "    \n",
    "    print(\"\\nR-squared for test data set:\")\n",
    "    print(regr.score(X_test, y_test))\n",
    "    \n",
    "    print_timestamp('End run_linear_regression.\\n\\n')\n",
    "    \n",
    "    print_timestamp('\\n'*3+'End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def run_ridge_regression():\n",
    "    # Fitting a ridge regression model. Alpha is the regularization\n",
    "    # parameter (usually called lambda). As alpha gets larger, parameter\n",
    "    # shrinkage grows more pronounced. Note that by convention, the\n",
    "    # intercept is not regularized. Since we standardized the data\n",
    "    # earlier, the intercept should be equal to zero and can be dropped.\n",
    "    print_timestamp('\\n'*3+'Begin')\n",
    "    \n",
    "    ridgeregr = linear_model.Ridge(alpha=10, fit_intercept=False) \n",
    "    ridgeregr.fit(X_train, y_train)\n",
    "    print(ridgeregr.score(X_train, y_train))\n",
    "\n",
    "    print_timestamp('\\n'*3+'End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer_nb(type_of_vectorizer):\n",
    "\n",
    "    print_timestamp(BegTimeStamp)\n",
    "    \n",
    "    # 1. import and instantiate CountVectorizer (with the default parameters)\n",
    "\n",
    "    # 2. instantiate CountVectorizer (vectorizer)\n",
    "\n",
    "#     X = df.message\n",
    "#     y = df.sentiment_label\n",
    "\n",
    "    # split X and y into training and testing sets\n",
    "    # by default, it splits 75% training and 25% test\n",
    "    # random_state=1 for reproducibility\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "    # 3. fit & transform\n",
    "    if type_of_vectorizer == 'Count':\n",
    "        print(\"We are running with CountVectorizer\")\n",
    "        vectorizer = CountVectorizer()\n",
    "        vectorizer.fit(X_train)\n",
    "        vectorizer_method = 'CountVectorizer'\n",
    "    elif type_of_vectorizer == 'Tfidf':\n",
    "        print(\"We are running with TfidfVectorizer\")\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectorizer.fit_transform(X_train)\n",
    "        vectorizer_method = 'TfidfVectorizer'\n",
    "    \n",
    "    # 4. transform training data\n",
    "    X_train_dtm = vectorizer.transform(X_train)\n",
    "\n",
    "    # equivalently: combine fit and transform into a single step\n",
    "    # this is faster and what most people would do\n",
    "    X_train_dtm = vectorizer.fit_transform(X_train)\n",
    "\n",
    "    # 4. transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "    X_test_dtm = vectorizer.transform(X_test)\n",
    "\n",
    "    # 1. import\n",
    "\n",
    "    # 2. instantiate a Multinomial Naive Bayes model\n",
    "    nb = MultinomialNB()\n",
    "\n",
    "    # 3. train the model \n",
    "    # using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "\n",
    "    nb.fit(X_train_dtm, y_train)\n",
    "    \n",
    "    \n",
    "    # 4. make class predictions for X_test_dtm\n",
    "    y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "    # calculate accuracy of class predictions\n",
    "\n",
    "    met_test_score = metrics.accuracy_score(y_test, y_pred_class)\n",
    "    printFormatted('###  With {} vectorizer, the metrics accuracy score = {:.2%}'.format(vectorizer_method,\n",
    "                                                                                         met_test_score))\n",
    "    \n",
    "    print_timestamp(EndTimeStamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    print_timestamp('\\n'*3+'Begin')\n",
    "    \n",
    "    if Regression == True:\n",
    "        print_timestamp(\"We are running with a Regression model\")\n",
    "    elif Regression == False:\n",
    "        print_timestamp(\"We are running with a Classifier model\")\n",
    "    else:\n",
    "        print_timestamp(\"We have failed to set the Regression variable\")\n",
    "        sys.exit(main())\n",
    "        \n",
    "\n",
    "    if flag_to_plot_them == True:\n",
    "        plot_them()\n",
    "\n",
    "    if flag_to_run_features_importance == True:\n",
    "        \n",
    "        number_of_features_to_consider = 50\n",
    "        params = {'n_estimators': 100}\n",
    "\n",
    "        if Regression == True:\n",
    "            print_timestamp('We are running RandomForestRegressor')\n",
    "            rf = ensemble.RandomForestRegressor(**params)\n",
    "            \n",
    "        else:\n",
    "            print_timestamp('We are running RandomForestClassifier')\n",
    "            rf = ensemble.RandomForestClassifier(**params)\n",
    "\n",
    "        run_features_importance(rf, number_of_features_to_consider)\n",
    "\n",
    "    if flag_to_run_correlation_matrix == True:\n",
    "        run_correlation_matrix()\n",
    "\n",
    "    if flag_to_run_rf == True:\n",
    "        #     params = {}\n",
    "        params = {'n_estimators': 100} \n",
    "\n",
    "        if Regression == True:\n",
    "            rf = ensemble.RandomForestRegressor(**params)\n",
    "            print_timestamp('We are running RandomForestRegressor')\n",
    "        else:\n",
    "            rf = ensemble.RandomForestClassifier(**params)\n",
    "            print_timestamp('We are running RandomForestClassifier')\n",
    "\n",
    "        run_rf(rf)\n",
    "\n",
    "    if flag_to_run_gradient_boosting  == True:\n",
    "        run_gradient_boosting()\n",
    "\n",
    "    if flag_to_run_linear_regression  == True:\n",
    "        run_linear_regression()\n",
    "\n",
    "    if flag_to_run_logistic_regression == True:\n",
    "        run_logistic_regression()\n",
    "\n",
    "    if flag_to_run_svc == True:\n",
    "        run_svc() \n",
    "\n",
    "    if flag_to_run_ridge_regression == True:\n",
    "        run_ridge_regression()\n",
    "        \n",
    "    if flag_to_run_vectorizer_nb == True:\n",
    "        for vectorizer_iterator in ['Count', 'Tfidf']:\n",
    "            vectorizer_nb(vectorizer_iterator)\n",
    "\n",
    "    print_timestamp('End'+'\\n'*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-09 23:18:25: In: main \n",
      "\n",
      "\n",
      "Begin \n",
      "2019-06-09 23:18:25: In: main We are running with a Classifier model \n",
      "2019-06-09 23:18:25: In: vectorizer_nb End\n",
      "\n",
      "\n",
      " \n",
      "We are running with CountVectorizer\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "###  With CountVectorizer vectorizer, the metrics accuracy score = 85.70%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-09 23:18:25: In: vectorizer_nb \n",
      "\n",
      "\n",
      "End \n",
      "2019-06-09 23:18:25: In: vectorizer_nb End\n",
      "\n",
      "\n",
      " \n",
      "We are running with TfidfVectorizer\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "###  With TfidfVectorizer vectorizer, the metrics accuracy score = 83.11%"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-09 23:18:26: In: vectorizer_nb \n",
      "\n",
      "\n",
      "End \n",
      "2019-06-09 23:18:26: In: main End\n",
      "\n",
      "\n",
      " \n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
