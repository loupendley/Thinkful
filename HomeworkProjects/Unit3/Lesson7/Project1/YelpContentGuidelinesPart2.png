{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.kaggle.com/sherinclaudia/sarcastic-comments-on-reddit'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning Capstone  \n",
    "#### You're ready to put into practice everything you've learned so far.  \n",
    "\n",
    "####  First: Go out and find a dataset of interest. It could be from one of our recommended resources, some other aggregation, or scraped yourself. Just make sure it has lots of variables in it, including an outcome of interest to you.  \n",
    "\n",
    "####  Second: Explore the data. Get to know the data. Spend a lot of time going over its quirks and peccadilloes. You should understand how it was gathered, what's in it, and what the variables look like.  \n",
    "\n",
    "####  Third: Model your outcome of interest. You should try several different approaches and really work to tune a variety of models before using the model evaluation techniques to choose what you consider to be the best performer. Make sure to think about explanatory versus predictive power and experiment with both.  \n",
    "\n",
    "####  So, here is the deliverable: Prepare a slide deck and 15 minute presentation that guides viewers through your model. Be sure to cover a few specific things:  \n",
    "\n",
    "1. A specified research question your model addresses  \n",
    "1. How you chose your model specification and what alternatives you compared it to  \n",
    "1. The practical uses of your model for an audience of interest  \n",
    "1. Any weak points or shortcomings of your model  \n",
    "\n",
    "\n",
    "This presentation is not a drill. You'll be presenting this slide deck live to a group as the culmination of your work in the last two supervised learning units. As a secondary matter, your slides and / or the Jupyter notebook you use or adapt them into should be worthy of inclusion as examples of your work product when applying to jobs.\n",
    "\n",
    "Good luck!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions that need answering:\n",
    "\n",
    " 1. What question are you trying to solve (or prove wrong) ?   \n",
    " __We are determining if a post was sarcastic.__\n",
    " 1. What kind of data do you have? -> describe the source.. \n",
    " __The dataset includes 1.3 million sarcastic comments from Reddit.  The data includes balanced and unbalanced   __\n",
    " 1. Do some EDA, plots\n",
    " 1. What's missing from the data and how do you deal with it?  \n",
    " __stuff.    __\n",
    " 1. Where are the outliers and why should we pay attention to them?  \n",
    " __stuff   ...__\n",
    " 1. How can you add, change, or remove features to get more out of your data?  \n",
    " __Feature importances, PCA, dropping low variance items, correlated feature pairs, features too highly correlated, feature engineering, transforming, timestamp and make a month, day, year column from it.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "max_iterations         = 10            # set it to > 0 for determining the features inportance\n",
    "random_state           = 57\n",
    "rows_in_training_set   = 10000\n",
    "rows_in_test_set       = 200000\n",
    "test_size              = 0.10\n",
    "train_size             = 0.90\n",
    "rfc_test_size          = 50000\n",
    "rfc_train_size         = 5000\n",
    "run_CountVectorizer    = False\n",
    "run_TfidfVectorizer    = True\n",
    "BegTimeStampNewlines   = 3\n",
    "EndTimeStampNewlines   = 3\n",
    "EndTimeStamp           = '\\n'*EndTimeStampNewlines+'End'\n",
    "BegTimeStamp           = 'End'+'\\n'*BegTimeStampNewlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controls\n",
    "flag_to_run_rf = False\n",
    "flag_to_plot_them = False\n",
    "flag_to_run_correlation_matrix = False\n",
    "flag_to_run_features_importance = False\n",
    "flag_to_run_gradient_boosting  = False\n",
    "flag_to_run_linear_regression  = True\n",
    "flag_to_run_logistic_regression = False\n",
    "flag_to_run_lasso_regression = False\n",
    "flag_to_run_ridge_regression = False\n",
    "flag_to_run_svc = False\n",
    "flag_to_run_vectorizer_nb = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import chardet\n",
    "import datetime\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time, sys\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from IPython.display import Markdown, display\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression = False\n"
     ]
    }
   ],
   "source": [
    "# add this to a dictionary\n",
    "# Constants\n",
    "max_iterations         = 10            # set it to > 0 for determining the features inportance\n",
    "random_state           = 57\n",
    "test_size              = 0.10\n",
    "train_size             = 0.90\n",
    "\n",
    "begin_string = '\\n'*3+'Begin'\n",
    "end_string = 'End'+'\\n'*3\n",
    "\n",
    "# Regression/Classification control\n",
    "Regression = False \n",
    "\n",
    "print(\"Regression = {}\".format(Regression))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "pd.set_option('display.max_rows', 3000)\n",
    "pd.set_option('display.max_row', 3000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 2,500 entries in the data file SanDiegoCountySoldProperties_12_Months.csv\n",
      "columns=Index(['Listing Pictures', 'MLS #', 'Status', 'Style', 'Full Address', 'Zip', 'Community', 'MapCoord', 'Beds', 'TotB', 'EstSF', 'YrBlt', 'DOMLS', 'ListPrice', 'Lst Date', 'Sold Price', 'COEDate'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "file = 'SanDiegoCountySoldProperties_12_Months.csv'\n",
    "path = path=\"../../../../Datafiles/SanDiegoRealEstate/\"\n",
    "column_names = []\n",
    "\n",
    "with open(path+file, 'rb') as f:\n",
    "    result = chardet.detect(f.read()) # or readline if the file is large\n",
    "df=pd.read_csv(path+file,encoding=result['encoding'])# ,header=None, names = column_names)\n",
    "# df = pd.read_json(path+file, lines=True)\n",
    "print(\"there are {:,} entries in the data file {}\".format(len(df), file))\n",
    "print(\"columns={}\".format(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on column SoldPrice\n",
      "working on column EstSF\n",
      "we have cleaned up the dataframe.\n"
     ]
    }
   ],
   "source": [
    "# data Cleanup\n",
    "# columns_to_cleanup = []\n",
    "# for column in columns_to_cleanup:\n",
    "#     print(\"we are now cleaning up column {}\".format(column))\n",
    "#     df[column].fillna(-1, inplace=True)\n",
    "# df['BareNuclei'] = np.where(df['BareNuclei'] == '?',-1, df['BareNuclei'])\n",
    "# df['Class'] = np.where(df['Class'] == 4, 1, 0)\n",
    "# df['message'] = df['headline']\n",
    "# df['sentiment_label'] = df['is_sarcastic']\n",
    "df.columns = df.columns.str.replace(' ', '')\n",
    "# convert to a numerical variable.  \n",
    "# set only the 4's and 5's to 1, which is positive, and all others to 0.\n",
    "# df['sentiment_label'] = df.sentiment.map({4:1, 5: 1, 3:0, 2: 0, 1:0})\n",
    "df['SoldPrice'].fillna(0, inplace=True)\n",
    "\n",
    "df['SoldPrice'].fillna('0', inplace=True)\n",
    "for column_name in ['SoldPrice', 'EstSF']:\n",
    "    print(\"working on column {}\".format(column_name))\n",
    "    df[column_name] = df[column_name].str.replace(',', '')\n",
    "    df[column_name] = df[column_name].str.replace('$', '')\n",
    "    df[column_name] = df[column_name].astype(int)\n",
    "df['Price_per_sq_ft'] = df['SoldPrice'] / df['EstSF']\n",
    "print('we have cleaned up the dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_timestamp_old(displaytext):    \n",
    "    import sys\n",
    "    import datetime\n",
    "    datetime_now = str(datetime.datetime.now())\n",
    "    print(\"{:19.19}: {} \".format(datetime_now, displaytext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_timestamp(displaytext):    \n",
    "    import sys\n",
    "    import datetime\n",
    "    datetime_now = str(datetime.datetime.now())\n",
    "    print(\"{:19.19}: In: {} {} \".format(datetime_now, sys._getframe(1).f_code.co_name, displaytext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printFormatted(string):\n",
    "    display(Markdown(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.isnull().sum()\n",
    "# df1 = df[df.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "sub = '-'\n",
    "# df.mask(df.ListPrice.str.contains(r'[\\$]'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'applymap'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-227-7d24a1157b81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# df['SoldPrice']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SoldPrice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misreal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5065\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5066\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5067\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5069\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Series' object has no attribute 'applymap'"
     ]
    }
   ],
   "source": [
    "df.columns\n",
    "df.head(20)\n",
    "# df['SoldPrice']\n",
    "df['SoldPrice'].applymap(np.isreal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definine outcome and predictors.\n",
    "print(\"the current time of start is {}\".format(str(datetime.datetime.now())))\n",
    "\n",
    "# Make the categorical variables below into enumerated categorical variables\n",
    "for dummy_column in []: # Remove these for now...\n",
    "    df = pd.concat([df, pd.get_dummies(df[dummy_column])], axis=1)\n",
    "df.columns = df.columns.str.replace(' ', '')\n",
    "\n",
    "# y = df['Class']\n",
    "# columns_excluded = ['Class','SampleCodeNumber'] # skip Class, the label, and SampleCodeNumber, which we do not need\n",
    "# X = df.loc[:, ~df.columns.isin(columns_excluded)]\n",
    "\n",
    "# print(\"End is {}\".format(str(datetime.datetime.now())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definine outcome and predictors.\n",
    "print(\"the current time of start is {}\".format(str(datetime.datetime.now())))\n",
    "\n",
    "y = df['SoldPrice']\n",
    "X=df[['Zip','Beds','TotB','EstSF','YrBlt','DOMLS','Price_per_sq_ft']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.sample(20)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Zip</th>\n",
       "      <th>Beds</th>\n",
       "      <th>TotB</th>\n",
       "      <th>EstSF</th>\n",
       "      <th>YrBlt</th>\n",
       "      <th>DOMLS</th>\n",
       "      <th>Price_per_sq_ft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2499.000</td>\n",
       "      <td>2500.000</td>\n",
       "      <td>2500.000</td>\n",
       "      <td>2500.000</td>\n",
       "      <td>2500.000</td>\n",
       "      <td>2500.000</td>\n",
       "      <td>2500.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>91912.026</td>\n",
       "      <td>3.296</td>\n",
       "      <td>2.702</td>\n",
       "      <td>1893.129</td>\n",
       "      <td>1989.088</td>\n",
       "      <td>29.552</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.361</td>\n",
       "      <td>1.013</td>\n",
       "      <td>0.906</td>\n",
       "      <td>3486.205</td>\n",
       "      <td>20.523</td>\n",
       "      <td>32.145</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>91901.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1894.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>91910.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1284.750</td>\n",
       "      <td>1973.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>260.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91913.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>1640.000</td>\n",
       "      <td>1995.000</td>\n",
       "      <td>18.500</td>\n",
       "      <td>295.712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>91914.000</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2233.250</td>\n",
       "      <td>2005.000</td>\n",
       "      <td>41.000</td>\n",
       "      <td>339.533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>91932.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>171407.000</td>\n",
       "      <td>2019.000</td>\n",
       "      <td>261.000</td>\n",
       "      <td>inf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Zip     Beds     TotB      EstSF    YrBlt    DOMLS  Price_per_sq_ft\n",
       "count  2499.000 2500.000 2500.000   2500.000 2500.000 2500.000         2500.000\n",
       "mean  91912.026    3.296    2.702   1893.129 1989.088   29.552              inf\n",
       "std       6.361    1.013    0.906   3486.205   20.523   32.145              nan\n",
       "min   91901.000    0.000    0.000      0.000 1894.000    0.000            2.476\n",
       "25%   91910.000    3.000    2.000   1284.750 1973.000    8.000          260.697\n",
       "50%   91913.000    3.000    3.000   1640.000 1995.000   18.500          295.712\n",
       "75%   91914.000    4.000    3.000   2233.250 2005.000   41.000          339.533\n",
       "max   91932.000    7.000   10.000 171407.000 2019.000  261.000              inf"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zip                1\n",
       "Beds               0\n",
       "TotB               0\n",
       "EstSF              0\n",
       "YrBlt              0\n",
       "DOMLS              0\n",
       "Price_per_sq_ft    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Zip                float64\n",
       "Beds                 int64\n",
       "TotB                 int64\n",
       "EstSF                int64\n",
       "YrBlt                int64\n",
       "DOMLS                int64\n",
       "Price_per_sq_ft    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_them():\n",
    "    for column in X_train.columns:\n",
    "#         plt.hist(X_train[column]*100, bins=40)\n",
    "        plt.scatter(y_train, X_train[column]*100)\n",
    "        plt.xlabel(column)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc_and_feature_importances(rf):    # Here we are using Random Forest classifier method to determine the top 30 features.\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, train_size=train_size)\n",
    "    \n",
    "    ## Fit the model on your training data.\n",
    "    rf.fit(X_train, y_train) \n",
    "    \n",
    "    ## And score it on your testing data.\n",
    "    rf.score(X_test, y_test)\n",
    "\n",
    "    feature_importance = rf.feature_importances_\n",
    "\n",
    "    # Make importances relative to max importance.\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    cols=X.columns[sorted_idx].tolist() \n",
    "    cols=cols[::-1]\n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "    plt.yticks(pos, X.columns[sorted_idx])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.title('Variable Importance')\n",
    "    plt.show()\n",
    "#     print(\"We are returning these columns {}\".format(cols))\n",
    "    return cols[:30] # return it sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_features_importance(rf,n):\n",
    "# Here we will return the feature importances\n",
    "    all_feature_important_columns = []\n",
    " \n",
    "    for i in range(1,n):\n",
    "        print_timestamp('running rfc iteration {} features importance for {} times'.format(i,n))\n",
    "        columns2 = rfc_and_feature_importances(rf)\n",
    "#         columns2.extend('{}'.format(i))\n",
    "        all_feature_important_columns = all_feature_important_columns + columns2\n",
    "    #     print(\"all_feature_import_columns={}\".format(all_feature_important_columns))\n",
    "\n",
    "    print(\"\\nBOD:\\nall_feature_important_columns = {}\\nEOD\".format(sorted(all_feature_important_columns)))\n",
    "    for feature in set(all_feature_important_columns):\n",
    "        print_timestamp(\"the NOC of feature {} in all_feature_important_columns is {}\".format(feature, all_feature_important_columns.count(feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_correlation_matrix():\n",
    "    \n",
    "    print_timestamp('Begin'+'\\n'*3)\n",
    "    \n",
    "    # Setup the correlation matrix.\n",
    "    corrmat = X.corr()\n",
    "    print(corrmat)\n",
    "\n",
    "    # Set up the subplots\n",
    "    f, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "    # Let's draw the heatmap using seaborn.\n",
    "    sns.heatmap(corrmat, vmax=.6, square=True)\n",
    "    plt.show()\n",
    "    \n",
    "    print_timestamp('\\n'*3+'End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_size = 0.9, X_train is 2250, and y_train is 2250\n",
      "test_size  = 0.1, X_test  is 250, and y_test is 250\n"
     ]
    }
   ],
   "source": [
    "# Let's fit it with the RFC training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, train_size=train_size, random_state=0)\n",
    "print(\"train_size = {}, X_train is {}, and y_train is {}\".format(train_size, len(X_train), len(y_train)))\n",
    "print(\"test_size  = {}, X_test  is {}, and y_test is {}\".format(test_size, len(X_test), len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_rf(rf):\n",
    "    print_timestamp('Begin run_rf part 1')\n",
    "    \n",
    "    ## Fit the model on your training data.\n",
    "    rf.fit(X_train, y_train)   \n",
    "    \n",
    "    ## Let's score it with the training data set\n",
    "    train_score = rf.score(X_train, y_train)\n",
    "    print(\"Training score = {}\".format(train_score))\n",
    "\n",
    "    ## Let's score it with the test data set\n",
    "    test_score = rf.score(X_test, y_test)\n",
    "    \n",
    "    print(\"Test score = {}\".format(test_score))\n",
    "    #Let's run cross validate score with the training data set\n",
    "#     cross_val_score(rf, X_train, y_train, cv=5)\n",
    "    \n",
    "    print_timestamp('End run_rfr part 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try predicting with gradient boosting classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gradient_boosting():\n",
    "\n",
    "    print_timestamp('Begin')\n",
    "    \n",
    "    clf = ensemble.GradientBoostingClassifier(**params)\n",
    "\n",
    "    #Let's run cross validate score with the training data set\n",
    "    cross_val_score(clf, X_train, y_train, cv=5)\n",
    "\n",
    "    loss_function = 'deviance' # could be exponential\n",
    "    depth_value = 8\n",
    "    params = {'n_estimators': 500,\n",
    "              'max_depth': 8,\n",
    "              'loss_function': loss_function,\n",
    "              'max_leaf_nodes': depth_value, # 8 worked best...\n",
    "              'min_samples_leaf': depth_value * 3\n",
    "              ,'random_state' : random_state\n",
    "             }\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    predict_train = clf.predict(X_train)\n",
    "    predict_test = clf.predict(X_test)\n",
    "    \n",
    "    print_timestamp('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svc():\n",
    "\n",
    "    print_timestamp('\\n'*3+'Begin run_svc')\n",
    "    \n",
    "    # Let's do a linear Support Vector Classifier\n",
    "    print_timestamp('Running SVC(kernel=linear')\n",
    "    svm = SVC(kernel = 'linear')\n",
    "    \n",
    "    # Let's fit the training model\n",
    "    print_timestamp('Running svm.fit')\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Let's score the training set\n",
    "    print_timestamp('Running svm.score for the training set')\n",
    "    svm.score(X_train, y_train)\n",
    "    \n",
    "    # Let's score the test set\n",
    "    print_timestamp('Running svm.fit for the test set')\n",
    "    svm.score(X_test, y_test)\n",
    "\n",
    "    print_timestamp('\\n'*3+'End run_svc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_logistic_regression():\n",
    "    print_timestamp('\\n'*3+'Begin')\n",
    "\n",
    "    lr = LogisticRegression(C=1e20, solver='lbfgs', max_iter=1000)\n",
    "\n",
    "    print_timestamp('Running lr.fit for the training set')\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    print_timestamp('Running lr.fit for the training set')\n",
    "    print('\\nR-squared simple model training set yields:')\n",
    "    print(lr.score(X_train, y_train))\n",
    "    print(\"here comes the test set\")\n",
    "    lrscore = lr.score(X_test, y_test)\n",
    "    printFormatted(\"###  Logistic Regression score={:.2%}\".format(lrscore))\n",
    "    \n",
    "    print_timestamp('\\n'*3+'End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression():\n",
    "\n",
    "    print_timestamp('\\n'*3+'Begin')\n",
    "\n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "    print_timestamp('Running regr.fit for the training set')\n",
    "    regr.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"\\nCoeffecients: \\n\", regr.coef_)\n",
    "    print(\"\\nIntercept: \\n\", regr.intercept_)\n",
    "    print(\"\\nR-squared for training data set:\")\n",
    "    print(regr.score(X_train, y_train))\n",
    "    \n",
    "    print(\"\\nR-squared for test data set:\")\n",
    "    print(regr.score(X_test, y_test))\n",
    "    \n",
    "    print_timestamp('End run_linear_regression.\\n\\n')\n",
    "    \n",
    "    print_timestamp('\\n'*3+'End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def run_ridge_regression():\n",
    "    # Fitting a ridge regression model. Alpha is the regularization\n",
    "    # parameter (usually called lambda). As alpha gets larger, parameter\n",
    "    # shrinkage grows more pronounced. Note that by convention, the\n",
    "    # intercept is not regularized. Since we standardized the data\n",
    "    # earlier, the intercept should be equal to zero and can be dropped.\n",
    "    print_timestamp('\\n'*3+'Begin')\n",
    "    \n",
    "    ridgeregr = linear_model.Ridge(alpha=10, fit_intercept=False) \n",
    "    ridgeregr.fit(X_train, y_train)\n",
    "    print(ridgeregr.score(X_train, y_train))\n",
    "\n",
    "    print_timestamp('\\n'*3+'End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizer_nb(type_of_vectorizer):\n",
    "\n",
    "    print_timestamp(BegTimeStamp)\n",
    "    \n",
    "    # 1. import and instantiate CountVectorizer (with the default parameters)\n",
    "\n",
    "    # 2. instantiate CountVectorizer (vectorizer)\n",
    "\n",
    "#     X = df.message\n",
    "#     y = df.sentiment_label\n",
    "\n",
    "    # split X and y into training and testing sets\n",
    "    # by default, it splits 75% training and 25% test\n",
    "    # random_state=1 for reproducibility\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "\n",
    "    # 3. fit & transform\n",
    "    if type_of_vectorizer == 'Count':\n",
    "        print(\"We are running with CountVectorizer\")\n",
    "        vectorizer = CountVectorizer()\n",
    "        vectorizer.fit(X_train)\n",
    "        vectorizer_method = 'CountVectorizer'\n",
    "    elif type_of_vectorizer == 'Tfidf':\n",
    "        print(\"We are running with TfidfVectorizer\")\n",
    "        vectorizer = TfidfVectorizer()\n",
    "        vectorizer.fit_transform(X_train)\n",
    "        vectorizer_method = 'TfidfVectorizer'\n",
    "    \n",
    "    # 4. transform training data\n",
    "    X_train_dtm = vectorizer.transform(X_train)\n",
    "\n",
    "    # equivalently: combine fit and transform into a single step\n",
    "    # this is faster and what most people would do\n",
    "    X_train_dtm = vectorizer.fit_transform(X_train)\n",
    "\n",
    "    # 4. transform testing data (using fitted vocabulary) into a document-term matrix\n",
    "    X_test_dtm = vectorizer.transform(X_test)\n",
    "\n",
    "    # 1. import\n",
    "\n",
    "    # 2. instantiate a Multinomial Naive Bayes model\n",
    "    nb = MultinomialNB()\n",
    "\n",
    "    # 3. train the model \n",
    "    # using X_train_dtm (timing it with an IPython \"magic command\")\n",
    "\n",
    "    nb.fit(X_train_dtm, y_train)\n",
    "    \n",
    "    \n",
    "    # 4. make class predictions for X_test_dtm\n",
    "    y_pred_class = nb.predict(X_test_dtm)\n",
    "\n",
    "    # calculate accuracy of class predictions\n",
    "\n",
    "    met_test_score = metrics.accuracy_score(y_test, y_pred_class)\n",
    "    printFormatted('###  With {} vectorizer, the metrics accuracy score = {:.2%}'.format(vectorizer_method,\n",
    "                                                                                         met_test_score))\n",
    "    \n",
    "    print_timestamp(EndTimeStamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    print_timestamp('\\n'*3+'Begin')\n",
    "    \n",
    "    if Regression == True:\n",
    "        print_timestamp(\"We are running with a Regression model\")\n",
    "    elif Regression == False:\n",
    "        print_timestamp(\"We are running with a Classifier model\")\n",
    "    else:\n",
    "        print_timestamp(\"We have failed to set the Regression variable\")\n",
    "        sys.exit(main())\n",
    "        \n",
    "\n",
    "    if flag_to_plot_them == True:\n",
    "        plot_them()\n",
    "\n",
    "    if flag_to_run_features_importance == True:\n",
    "        \n",
    "        number_of_features_to_consider = 50\n",
    "        params = {'n_estimators': 100}\n",
    "\n",
    "        if Regression == True:\n",
    "            print_timestamp('We are running RandomForestRegressor')\n",
    "            rf = ensemble.RandomForestRegressor(**params)\n",
    "            \n",
    "        else:\n",
    "            print_timestamp('We are running RandomForestClassifier')\n",
    "            rf = ensemble.RandomForestClassifier(**params)\n",
    "\n",
    "        run_features_importance(rf, number_of_features_to_consider)\n",
    "\n",
    "    if flag_to_run_correlation_matrix == True:\n",
    "        run_correlation_matrix()\n",
    "\n",
    "    if flag_to_run_rf == True:\n",
    "        #     params = {}\n",
    "        params = {'n_estimators': 100} \n",
    "\n",
    "        if Regression == True:\n",
    "            rf = ensemble.RandomForestRegressor(**params)\n",
    "            print_timestamp('We are running RandomForestRegressor')\n",
    "        else:\n",
    "            rf = ensemble.RandomForestClassifier(**params)\n",
    "            print_timestamp('We are running RandomForestClassifier')\n",
    "\n",
    "        run_rf(rf)\n",
    "\n",
    "    if flag_to_run_gradient_boosting  == True:\n",
    "        run_gradient_boosting()\n",
    "\n",
    "    if flag_to_run_linear_regression  == True:\n",
    "        run_linear_regression()\n",
    "\n",
    "    if flag_to_run_logistic_regression == True:\n",
    "        run_logistic_regression()\n",
    "\n",
    "    if flag_to_run_svc == True:\n",
    "        run_svc() \n",
    "\n",
    "    if flag_to_run_ridge_regression == True:\n",
    "        run_ridge_regression()\n",
    "        \n",
    "    if flag_to_run_vectorizer_nb == True:\n",
    "        for vectorizer_iterator in ['Count', 'Tfidf']:\n",
    "            vectorizer_nb(vectorizer_iterator)\n",
    "\n",
    "    print_timestamp('End'+'\\n'*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-10 20:12:10: In: main \n",
      "\n",
      "\n",
      "Begin \n",
      "2019-06-10 20:12:10: In: main We are running with a Classifier model \n",
      "2019-06-10 20:12:10: In: run_linear_regression \n",
      "\n",
      "\n",
      "Begin \n",
      "2019-06-10 20:12:10: In: run_linear_regression Running regr.fit for the training set \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-244-263240bbee7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-243-a90dc6b0c7e9>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflag_to_run_linear_regression\u001b[0m  \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mrun_linear_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflag_to_run_logistic_regression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-240-d31161004665>\u001b[0m in \u001b[0;36mrun_linear_regression\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint_timestamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Running regr.fit for the training set'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nCoeffecients: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0mn_jobs_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         X, y = check_X_y(X, y, accept_sparse=['csr', 'csc', 'coo'],\n\u001b[0;32m--> 458\u001b[0;31m                          y_numeric=True, multi_output=True)\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0matleast_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 573\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
