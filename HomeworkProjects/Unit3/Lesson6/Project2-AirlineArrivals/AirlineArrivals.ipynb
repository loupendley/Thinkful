{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this dataset of airline arrival information to predict how late flights will be. \n",
    "A flight only counts as late if it is more than 30 minutes late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://stat-computing.org/dataexpo/2009/the-data.html'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "max_iterations         = 10            # set it to > 0 for determining the features inportance\n",
    "random_state           = 57\n",
    "rows_in_training_set   = 10000\n",
    "rows_in_test_set       = 200000\n",
    "test_size              = 0.20\n",
    "train_size             = 0.80\n",
    "rfc_test_size          = 50000\n",
    "rfc_train_size         = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Controls\n",
    "fit_train_rfc = False\n",
    "run_rfr = False\n",
    "plot_them = False\n",
    "run_correlation_matrix = False\n",
    "run_features_importance = False\n",
    "run_gradient_boosting  = False\n",
    "run_linear_regression  = True\n",
    "run_logistic_regression = False\n",
    "run_svc = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false,
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import datetime\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time, sys\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 7,009,728 entries in the data file Airline_Arrivals_2008.csv\n"
     ]
    }
   ],
   "source": [
    "file = 'Airline_Arrivals_2008.csv'\n",
    "path = path=\"../../../../Datafiles/\"\n",
    "df = pd.read_csv((path+file))\n",
    "\n",
    "print(\"there are {:,} entries in the data file {}\".format(len(df), file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are now cleaning up column DepTime\n",
      "we are now cleaning up column ArrTime\n",
      "we are now cleaning up column TailNum\n",
      "we are now cleaning up column ActualElapsedTime\n",
      "we are now cleaning up column CRSElapsedTime\n",
      "we are now cleaning up column AirTime\n",
      "we are now cleaning up column ArrDelay\n",
      "we are now cleaning up column DepDelay\n",
      "we are now cleaning up column TaxiIn\n",
      "we are now cleaning up column TaxiOut\n",
      "we are now cleaning up column CancellationCode\n",
      "we are now cleaning up column CarrierDelay\n",
      "we are now cleaning up column WeatherDelay\n",
      "we are now cleaning up column NASDelay\n",
      "we are now cleaning up column SecurityDelay\n",
      "we are now cleaning up column LateAircraftDelay\n",
      "[['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime', 'FlightNum', 'ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'ArrDelay', 'DepDelay', 'Origin', 'Dest', 'Distance', 'TaxiIn', 'TaxiOut', 'Cancelled', 'CancellationCode', 'Diverted', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', 'ArrDelay_Flag']]\n",
      "we have cleaned up the dataframe.\n"
     ]
    }
   ],
   "source": [
    "# data Cleanup\n",
    "columns_to_cleanup = ['DepTime', 'ArrTime', 'TailNum', 'ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'ArrDelay', 'DepDelay',\n",
    "'TaxiIn', 'TaxiOut', 'CancellationCode', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay']\n",
    "for column in columns_to_cleanup:\n",
    "    print(\"we are now cleaning up column {}\".format(column))\n",
    "    df[column].fillna(-1, inplace=True)\n",
    "columns_to_use = [['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime', 'ArrTime', 'CRSArrTime', 'FlightNum', \n",
    "                           'ActualElapsedTime', 'CRSElapsedTime', 'AirTime', 'ArrDelay', 'DepDelay', 'Origin', 'Dest', 'Distance', 'TaxiIn', \n",
    "                          'TaxiOut', 'Cancelled', 'CancellationCode', 'Diverted', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', \n",
    "                          'LateAircraftDelay', 'ArrDelay_Flag']]\n",
    "print(columns_to_use)\n",
    "print('we have cleaned up the dataframe.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_timestamp(displaytext):    \n",
    "    import sys\n",
    "    import datetime\n",
    "    \n",
    "    print(\"{}: {} \".format(datetime.datetime.now(), displaytext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definine outcome and predictors.\n",
    "print(\"the current time of start is {}\".format(str(datetime.datetime.now())))\n",
    "\n",
    "y = df['ArrDelay']\n",
    "# X = df.loc[:, ~df.columns.isin(['ArrDelay','UniqueCarrier', 'TailNum', 'Origin', 'Dest', 'CancellationCode', 'ArrDelay_Flag'])]\n",
    "\n",
    "X = df[['LateAircraftDelay','SecurityDelay','CRSDepTime','WeatherDelay','TaxiOut','DepDelay']] # remove Distance, DepTime\n",
    "\n",
    "print(\"End is {}\".format(str(datetime.datetime.now())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for column in X_train.columns:\n",
    "#     plt.hist(X_train[column]*100, bins=40)\n",
    "#     plt.xlabel(column)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = ensemble.RandomForestClassifier()\n",
    "rfr = ensemble.RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if plot_them == True:\n",
    "    for column in X_train.columns:\n",
    "        plt.hist(X_train[column]*100, bins=40)\n",
    "        plt.xlabel(column)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfc_and_feature_importances(leaf_values):    # Here we are using Gradient Boosting classifier method to determine the top 30 features.\n",
    "# train and then run RFC\n",
    "    \n",
    "    params = {'n_estimators': 500\n",
    "              ,'max_depth'    : 2\n",
    "             }\n",
    "\n",
    "    rfc = ensemble.RandomForestClassifier(**params)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=rfc_test_size, train_size=rfc_train_size)\n",
    "    \n",
    "    ## Fit the model on your training data.\n",
    "    rfc.fit(X_train, y_train) \n",
    "    \n",
    "    ## And score it on your testing data.\n",
    "    rfc.score(X_test, y_test)\n",
    "\n",
    "    feature_importance = rfc.feature_importances_\n",
    "\n",
    "    # Make importances relative to max importance.\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    cols=X.columns[sorted_idx].tolist() \n",
    "    cols=cols[::-1]\n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "    plt.yticks(pos, X.columns[sorted_idx])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.title('Variable Importance')\n",
    "    plt.show()\n",
    "    print(\"We are returning these columns {}\".format(cols))\n",
    "    return cols # return it sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we will return the feature importances\n",
    "if run_features_importance == True:\n",
    "    all_feature_important_columns = []\n",
    "#     max_iterations = 3\n",
    "    for i in range(1,max_iterations):\n",
    "        print_timestamp('running rfc iteration {} features importance for {} times'.format(i,max_iterations))\n",
    "        columns2 = rfc_and_feature_importances(i)\n",
    "#         columns2.extend('{}'.format(i))\n",
    "        all_feature_important_columns = all_feature_important_columns + columns2\n",
    "    #     print(\"all_feature_import_columns={}\".format(all_feature_important_columns))\n",
    "\n",
    "    print(\"\\nBOD:\\nall_feature_important_columns = {}\\nEOD\".format(sorted(all_feature_important_columns)))\n",
    "    for feature in set(all_feature_important_columns):\n",
    "        print(\"the number of occurrences of feature {} in all_feature_important_columns is {}\".format(feature, all_feature_important_columns.count(feature)))\n",
    "#         [['DepDelay', 'NASDelay', 'CarrierDelay', 'LateAircraftDelay', 'WeatherDelay', 'SecurityDelay', 'TaxiOut', 'DepTime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_correlation_matrix == True:\n",
    "    print_timestamp('Begin')\n",
    "    \n",
    "    # Setup the correlation matrix.\n",
    "    corrmat = X.corr()\n",
    "    print(corrmat)\n",
    "\n",
    "    # Set up the subplots\n",
    "    f, ax = plt.subplots(figsize=(12, 9))\n",
    "\n",
    "    # Let's draw the heatmap using seaborn.\n",
    "    sns.heatmap(corrmat, vmax=.6, square=True)\n",
    "    plt.show()\n",
    "    \n",
    "    print_timestamp('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's fit it with the RFC training set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, train_size=train_size, random_state=0)\n",
    "print(\"train_size = {}, X_train is {}, and y_train is {}\".format(train_size, len(X_train), len(y_train)))\n",
    "print(\"test_size  = {}, X_test  is {}, and y_test is {}\".format(test_size, len(y_train), len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fit_train_rfc == True:\n",
    "    print_timestamp('Begin fit_train_rfc')\n",
    "    \n",
    "    ## Fit the model on your training data.\n",
    "    rfc.fit(X_train, y_train) \n",
    "    #Let's run cross validate score with the training data set\n",
    "    cross_val_score(rfc, X_train, y_train, cv=5)\n",
    "        \n",
    "    ## Let's score it with the training data set\n",
    "    rfc.score(X_train, y_train)\n",
    "    \n",
    "    ## Let's score it with the test data set\n",
    "    rfc.score(X_test, y_test)\n",
    "    \n",
    "    print_timestamp('End fit_train_rfc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_rfr == True:\n",
    "    print_timestamp('Begin run_rfr part 1')\n",
    "    \n",
    "    ## Fit the model on your training data.\n",
    "    rfr.fit(X_train, y_train) \n",
    "    \n",
    "    #Let's run cross validate score with the training data set\n",
    "    cross_val_score(rfr, X_train, y_train, cv=5)\n",
    "    \n",
    "#     ## Let's score it with the training data set\n",
    "#     rfr.score(X_train, y_train)\n",
    "    \n",
    "#     ## Let's score it with the test data set\n",
    "#     rfr.score(X_test, y_test)\n",
    "    \n",
    "    print_timestamp('End run_rfr part 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_rfr == True:\n",
    "    print_timestamp('Begin run_rfr part 2')\n",
    "    \n",
    "#     ## Fit the model on your training data.\n",
    "#     rfr.fit(X_train, y_train) \n",
    "    \n",
    "#     #Let's run cross validate score with the training data set\n",
    "#     cross_val_score(rfr, X_train, y_train, cv=5)\n",
    "    \n",
    "    ## Let's score it with the training data set\n",
    "    rfr.score(X_train, y_train)\n",
    "    \n",
    "    ## Let's score it with the test data set\n",
    "    rfr.score(X_test, y_test)\n",
    "    \n",
    "    print_timestamp('End run_rfr part 2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try predicting with gradient boosting classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_gradient_boosting == True:\n",
    "    print_timestamp('Begin')\n",
    "    \n",
    "    clf = ensemble.GradientBoostingClassifier(**params)\n",
    "\n",
    "    #Let's run cross validate score with the training data set\n",
    "    cross_val_score(clf, X_train, y_train, cv=5)\n",
    "\n",
    "    loss_function = 'deviance' # could be exponential\n",
    "    depth_value = 8\n",
    "    params = {'n_estimators': 500,\n",
    "              'max_depth': 8,\n",
    "              'loss': loss_function,\n",
    "              'max_leaf_nodes': depth_value, # 8 worked best...\n",
    "              'min_samples_leaf': depth_value * 3\n",
    "              ,'random_state' : random_state\n",
    "             }\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    predict_train = clf.predict(X_train)\n",
    "    predict_test = clf.predict(X_test)\n",
    "    \n",
    "    print_timestamp('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_svc == True:\n",
    "    print_timestamp('Begin')\n",
    "    \n",
    "    # Let's do a linear Support Vector Classifier\n",
    "    print_timestamp('Running SVC(kernel=linear')\n",
    "    svm = SVC(kernel = 'linear')\n",
    "    \n",
    "    # Let's fit the training model\n",
    "    print_timestamp('Running svm.fit')\n",
    "    svm.fit(X_train, y_train)\n",
    "    \n",
    "    # Let's score the training set\n",
    "    print_timestamp('Running svm.score for the training set')\n",
    "    svm.score(X_train, y_train)\n",
    "    \n",
    "    # Let's score the test set\n",
    "    print_timestamp('Running svm.fit for the test set')\n",
    "    svm.score(X_test, y_test)\n",
    "\n",
    "    print_timestamp('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_logistic_regression == True: # Used for binary classification -- in this case, will the flight arrive on time?\n",
    "    print_timestamp('Begin')\n",
    "\n",
    "    lr = LogisticRegression(C=1e20, solver='lbfgs', max_iter=1000)\n",
    "\n",
    "    print_timestamp('Running lr.fit for the training set')\n",
    "    lr.fit(X_train, y_train)\n",
    "    \n",
    "    print_timestamp('Running lr.fit for the training set')\n",
    "    print('\\nR-squared simple model training set yields:')\n",
    "    print(lr.score(X_train, y_train))\n",
    "    print(\"here comes the test set\")\n",
    "    print(lr.score(X_test, y_test))\n",
    "    \n",
    "    print_timestamp('End')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_linear_regression == True: \n",
    "    print_timestamp('Begin run_linear_regression')\n",
    "    \n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "    print_timestamp('Running regr.fit for the training set')\n",
    "    regr.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"\\nCoeffecients: \\n\", regr.coef_)\n",
    "    print(\"\\nIntercept: \\n\", regr.intercept_)\n",
    "    print(\"\\nR-squared for training data set:\")\n",
    "    print(regr.score(X_train, y_train))\n",
    "    \n",
    "    print(\"\\nR-squared for test data set:\")\n",
    "    print(regr.score(X_test, y_test))\n",
    "    \n",
    "    print_timestamp('End run_linear_regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
