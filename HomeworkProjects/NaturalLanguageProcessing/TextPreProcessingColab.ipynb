{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "TextPreProcessing.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/loupendley/Thinkful/blob/master/.%5Cstuff%5CTextPreProcessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsvVOTGcA2JF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import nltk\n",
        "import spacy\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJSHjeHVA2JJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1b150235-cbd1-49ae-9ac8-4a504d9cb7c5"
      },
      "source": [
        "nltk.download('gutenberg')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVp9ZUCEA2JL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Why, oh why are all of the corpuses lowercase after Removing stopwords in the lesson????"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZGR5rCgA2JN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "09185e80-f237-49a9-f4cb-1504bae74773"
      },
      "source": [
        "# import the data we just downloaded\n",
        "from nltk.corpus import gutenberg\n",
        "\n",
        "persuasion = gutenberg.raw('austen-persuasion.txt')\n",
        "alice = gutenberg.raw('carroll-alice.txt')\n",
        "\n",
        "# print the first 100 characters of Alice\n",
        "print('\\nRaw:\\n', alice[0:100])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Raw:\n",
            " [Alice's Adventures in Wonderland by Lewis Carroll 1865]\n",
            "\n",
            "CHAPTER I. Down the Rabbit-Hole\n",
            "\n",
            "Alice was\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFiskT1oA2JQ",
        "colab_type": "text"
      },
      "source": [
        "## Basic Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBlqm58YA2JR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "66ab3989-bfb3-40a4-b3be-85216aa8d31b"
      },
      "source": [
        "# this pattern matches all text between square brackets\n",
        "pattern = \"[\\[].*?[\\]]\"\n",
        "persuasion = re.sub(pattern, \"\", persuasion)\n",
        "alice = re.sub(pattern, \"\", alice)\n",
        "\n",
        "# print the first 100 characters of Alice again\n",
        "print(\"Title removed:\", alice[0:100])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Title removed: \n",
            "\n",
            "CHAPTER I. Down the Rabbit-Hole\n",
            "\n",
            "Alice was beginning to get very tired of sitting by her sister on\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZPrrKW7A2JT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "7631c270-1fd9-44c7-bf55-bdfd887dca8d"
      },
      "source": [
        "# now we'll match and remove chapter headings\n",
        "persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
        "alice = re.sub(r'CHAPTER .*', '', alice)\n",
        "\n",
        "# ok, what does it look like now\n",
        "print('Chapter headings removed from alice:', alice[0:102])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chapter headings removed from alice: \n",
            "\n",
            "\n",
            "\n",
            "Alice was beginning to get very tired of sitting by her sister on the\n",
            "bank, and of having nothing \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tlemc6NA2JW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "95073a29-9085-4e26-db02-f0832132f5d6"
      },
      "source": [
        "# remove newlines and other extra whitespaces by splitting and rejoining\n",
        "persuasion = ' '.join(persuasion.split())\n",
        "alice = ' '.join(alice.split())\n",
        "\n",
        "# almost done with cleanup?  let's check it out\n",
        "print('Extra whitespace removed:\\n', alice[0:103])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extra whitespace removed:\n",
            " Alice was beginning to get very tired of sitting by her sister on the bank, and of having nothing to do\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HkLU2i_A2JZ",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1fRWsZcA2JZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load('en')\n",
        "\n",
        "# all the processing work is done below, sit it may take a while, Lou.\n",
        "\n",
        "alice_doc = nlp(alice)\n",
        "persuasion_doc = nlp(persuasion)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x2BmyvyA2Jc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "ee39d38d-5a10-4273-e553-122d2b7bbb6e"
      },
      "source": [
        "# let's explore the objects that we've built...\n",
        "\n",
        "print(\"the alice_doc is a {} object.\".format(type(alice_doc)))\n",
        "print(\"It is {} tokens long.\".format(len(alice_doc)))\n",
        "print(\"the first three tokens are: '{}'\".format(alice_doc[:3]))\n",
        "print(\"the type of each token is {}\".format(type(alice_doc[0])))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the alice_doc is a <class 'spacy.tokens.doc.Doc'> object.\n",
            "It is 34408 tokens long.\n",
            "the first three tokens are: 'Alice was beginning'\n",
            "the type of each token is <class 'spacy.tokens.token.Token'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-RUE-s7A2Je",
        "colab_type": "text"
      },
      "source": [
        "## Removing stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH5bPzI1A2Je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "alice_without_stopwords = [token for token in alice_doc if not token.is_stop]\n",
        "persuasion_without_stopwords = [token for token in persuasion_doc if not token.is_stop]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G702kWCA2Jg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "0b802b4e-34b2-4edd-8913-07377775b1e7"
      },
      "source": [
        "print(alice_without_stopwords[0:30])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Alice, beginning, tired, sitting, sister, bank, ,, having, :, twice, peeped, book, sister, reading, ,, pictures, conversations, ,, ', use, book, ,, ', thought, Alice, ', pictures, conversation, ?, ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HHGp32NA2Jj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a4880fca-8394-4161-ff41-dde43f0f57f1"
      },
      "source": [
        "# utility function to calculate how frequently words appear in the text\n",
        "def word_frequencies(text):\n",
        "    # build a list of words\n",
        "    # strip out punctuation\n",
        "    words = []\n",
        "    for token in text:\n",
        "        if not token.is_punct:\n",
        "            words.append(token.text) ## I just added lower() onto this function, and now all text items are lower!\n",
        "    \n",
        "    # build and return a Counter object containing the word counts\n",
        "    return Counter(words)\n",
        "\n",
        "# instantiate out list of most common words.\n",
        "alice_word_freq = word_frequencies(alice_without_stopwords).most_common(10)\n",
        "persuasion_word_freq = word_frequencies(persuasion_without_stopwords).most_common(10)\n",
        "print('\\nAlice', alice_word_freq)\n",
        "print('Persuasion:', persuasion_word_freq)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Alice [('said', 453), ('Alice', 394), ('little', 124), ('like', 84), ('went', 83), ('know', 83), ('thought', 74), ('Queen', 73), ('time', 68), ('King', 61)]\n",
            "Persuasion: [('Anne', 496), ('Captain', 297), ('Mrs', 291), ('Elliot', 288), ('Mr', 254), ('Wentworth', 217), ('Lady', 191), ('good', 181), ('little', 175), ('Charles', 166)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLu7gMhHA2Jm",
        "colab_type": "text"
      },
      "source": [
        "## Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMXLfjFoA2Jm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "67f0831e-5e3f-474f-f3ef-eca0b2dfb7b0"
      },
      "source": [
        "def lemma_frequencies(text):\n",
        "    # build a list of lemas\n",
        "    # strip out punctuation\n",
        "    lemmas = []\n",
        "    for token in text:\n",
        "        if not token.is_punct:\n",
        "            lemmas.append(token.lemma_)\n",
        "            \n",
        "    # build and return a Counter object containing lemma counts\n",
        "    return Counter(lemmas)\n",
        "\n",
        "# instantiate out list of most common lemmas\n",
        "alice_lemma_freq = lemma_frequencies(alice_without_stopwords).most_common(10)\n",
        "persuasion_lemma_freq = lemma_frequencies(persuasion_without_stopwords).most_common(10)\n",
        "\n",
        "print('\\nAlice:' ,alice_lemma_freq)\n",
        "print('Persuasion:' ,persuasion_lemma_freq)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Alice: [('say', 476), ('Alice', 394), ('think', 130), ('go', 130), ('little', 124), ('look', 105), ('know', 103), ('come', 96), ('like', 92), ('begin', 91)]\n",
            "Persuasion: [('Anne', 496), ('Captain', 297), ('Mrs', 291), ('Elliot', 288), ('think', 258), ('Mr', 254), ('know', 252), ('good', 222), ('Wentworth', 215), ('Lady', 191)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4x1YR7rA2Jo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bf7d9b30-f346-460d-af65-a8390d6ed9bf"
      },
      "source": [
        "alice_lemma_common = [pair[0] for pair in alice_lemma_freq]\n",
        "persuasion_lemma_common = [pair[0] for pair in persuasion_lemma_freq]\n",
        "\n",
        "print('Unique to Alice:', set(alice_lemma_common) - set(persuasion_lemma_common))\n",
        "print('Unique to Persuasion:', set(persuasion_lemma_common) - set(alice_lemma_common))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unique to Alice: {'Alice', 'little', 'say', 'like', 'look', 'come', 'go', 'begin'}\n",
            "Unique to Persuasion: {'Lady', 'Elliot', 'Mrs', 'good', 'Mr', 'Wentworth', 'Captain', 'Anne'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpiYzg7VA2Jr",
        "colab_type": "text"
      },
      "source": [
        "## Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXLH9MnUA2Jr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "84a63268-08b0-4949-f48e-231468782669"
      },
      "source": [
        "# initial exploration of sentences\n",
        "sentences = list(alice_doc.sents)\n",
        "print(\"Alice in Wonderland has {} sentences.\".format(len(sentences)))\n",
        "\n",
        "example_sentence = sentences[2]\n",
        "print(\"Here is an example: \\n{}\\n\".format(example_sentence))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Alice in Wonderland has 1989 sentences.\n",
            "Here is an example: \n",
            "There was nothing so VERY remarkable in that; nor did Alice think it so VERY much out of the way to hear the Rabbit say to itself, 'Oh dear!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ppXfEeNA2Jv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "d9bf2965-66ba-4a63-de2d-c3e1a18bb48d"
      },
      "source": [
        "# look at some metrics around this sentence\n",
        "\n",
        "example_words = [token for token in example_sentence if not token.is_punct]\n",
        "unique_words = set([token.text for token in example_words])\n",
        "\n",
        "print(\"this sentence is {}\".format(example_words))\n",
        "print((\"There are {} words in this sentence, and {} of them are unique\".format(len(example_words), len(unique_words))))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this sentence is [There, was, nothing, so, VERY, remarkable, in, that, nor, did, Alice, think, it, so, VERY, much, out, of, the, way, to, hear, the, Rabbit, say, to, itself, Oh, dear]\n",
            "There are 29 words in this sentence, and 25 of them are unique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmzLAf2jA2Jx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
