{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "TextPreProcessing.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/loupendley/Thinkful/blob/master/HomeworkProjects/NaturalLanguageProcessing/TextPreProcessingColab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90Hch0kNdJGB",
        "colab_type": "text"
      },
      "source": [
        "### **PreProcessing for Cornell Movie Dialogs Corpus Data**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsvVOTGcA2JF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "import nltk\n",
        "import spacy\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDuW7m3TdghL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def file_stuff(path, filename, usecols=None, dtypes=None, nrows=None):\n",
        "    \n",
        "    # zip_file = ZipFile(zipfil\n",
        "    print(\"path = {}, and filename = {}\".format(path, filename))\n",
        "    fullfilename = \"{}\".format(path+'/'+filename)\n",
        "    print(\"fullfilename = {}\".format(path+'/'+filename))\n",
        "    # df = pd.read_json(fullfilename,encoding = \"utf-8\")\n",
        "    df = pd.read_csv(filename, dtype=dtypes, usecols=usecols, nrows=nrows, header=0, sep=\"|\")\n",
        "\n",
        "    print(\"There are {} rows in this file.\".format(df.shape[0]))\n",
        "\n",
        "    # patients_df = pd.read_json('E:/datasets/patients.json')\n",
        "    \n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VfL_elj9sa3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "58df4cb8-2828-4dbf-fc1a-c51b9a8ebb5c"
      },
      "source": [
        "import os\n",
        "path = os.getcwd()\n",
        "\n",
        "print(path)\n",
        "\n",
        "arr = os.listdir('.')\n",
        "print(arr)\n",
        "# dtypes = 'string'\n",
        "# usecols = 'dialogs'\n",
        "usecols = ['dialogs']\n",
        "nrows = 160000\n",
        "dialogs_df = file_stuff(\"..\", 'dialogs_pipe_delimited.csv', usecols=usecols, nrows=nrows)\n",
        "dialogs_df.dialogs.head(20)\n",
        "# print(\"dialogs.dialogs is a {} datatype\".format(type(dialogs.dialogs[0])))"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "['.config', 'twitter_pipe_delimited.csv', 'dialogs_pipe_delimited.csv', 'sample_data']\n",
            "path = .., and filename = dialogs_pipe_delimited.csv\n",
            "fullfilename = ../dialogs_pipe_delimited.csv\n",
            "There are 160000 rows in this file.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     Can we make this quick?  Roxanne Korrine and A...\n",
              "1     Well, I thought we'd start with pronunciation,...\n",
              "2     Not the hacking and gagging and spitting part....\n",
              "3     Okay... then how 'bout we try out some French ...\n",
              "4     You're asking me out.  That's so cute. What's ...\n",
              "5                                            Forget it.\n",
              "6     No, no, it's my fault -- we didn't have a prop...\n",
              "7                                              Cameron.\n",
              "8     The thing is, Cameron -- I'm at the mercy of a...\n",
              "9        Seems like she could get a date easy enough...\n",
              "10                                                 Why?\n",
              "11    Unsolved mystery.  She used to be really popul...\n",
              "12                                      That's a shame.\n",
              "13       Gosh, if only we could find Kat a boyfriend...\n",
              "14                            Let me see what I can do.\n",
              "15                       C'esc ma tete. This is my head\n",
              "16             Right.  See?  You're ready for the quiz.\n",
              "17    I don't want to know how to say that though.  ...\n",
              "18                 That's because it's such a nice one.\n",
              "19                                       Forget French.\n",
              "Name: dialogs, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJSHjeHVA2JJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# nltk.download('gutenberg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVp9ZUCEA2JL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Why, oh why are all of the corpuses lowercase after Removing stopwords in the lesson????"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZGR5rCgA2JN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # import the data we just downloaded\n",
        "# from nltk.corpus import gutenberg\n",
        "\n",
        "# persuasion = gutenberg.raw('austen-persuasion.txt')\n",
        "# alice = gutenberg.raw('carroll-alice.txt')\n",
        "\n",
        "# # print the first 100 characters of Alice\n",
        "# print('\\nRaw:\\n', alice[0:100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFiskT1oA2JQ",
        "colab_type": "text"
      },
      "source": [
        "## Basic Text Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBlqm58YA2JR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # this pattern matches all text between square brackets\n",
        "# pattern = \"[\\[].*?[\\]]\"\n",
        "# persuasion = re.sub(pattern, \"\", persuasion)\n",
        "# alice = re.sub(pattern, \"\", alice)\n",
        "\n",
        "# # print the first 100 characters of Alice again\n",
        "# print(\"Title removed:\", alice[0:100])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZPrrKW7A2JT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # now we'll match and remove chapter headings\n",
        "# persuasion = re.sub(r'Chapter \\d+', '', persuasion)\n",
        "# alice = re.sub(r'CHAPTER .*', '', alice)\n",
        "\n",
        "# # ok, what does it look like now\n",
        "# print('Chapter headings removed from alice:', alice[0:102])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tlemc6NA2JW",
        "colab_type": "code",
        "outputId": "15ae0575-4669-464e-de2a-5ca11e7c8fd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# remove newlines and other extra whitespaces by splitting and rejoining\n",
        "# persuasion = ' '.join(persuasion.split())\n",
        "# alice = ' '.join(alice.split())\n",
        "print(\"checkpoint 1\")\n",
        "dialogs0 = dialogs_df.dialogs.to_string()\n",
        "print(\"checkpoint 2\")\n",
        "dialogs = ' '.join(dialogs0.split())\n",
        "dialogs_sample = dialogs[0:100]\n",
        "print(\"checkpoint 3\")\n",
        "print(\"dialogs is a {} datatype.\".format(type(dialogs)))\n",
        "print(\"sample of dialogs.dialogs {}\".format(dialogs_sample))\n",
        "print(\"checkpoint 4\")\n",
        "# dialogs3 = ' '.join(dialogs.dialogs.to_string())\n",
        "# print(\"dialogs3 is a {} datatype.\".format(type(dialogs3)))\n",
        "# print(\"sample of dialogs3: {}\".format(dialogs.dialogs))\n",
        "# # almost done with cleanup?  let's check it out\n",
        "# print('Extra whitespace removed:\\n', alice[0:103])\n",
        "# print(\"dialogs.dialogs[0] = {}\".format(dialogs.dialogs[0]))\n",
        "# print(\"type of dialogs.dialogs[0] is {}\".format(type(dialogs.dialogs[0])))\n",
        "print(\"length of dialogs3 is {}\".format(len(dialogs3)))\n",
        "# print(\"dialogs3 sample = {}\".format(dialogs3))\n",
        "print(\"dialogs3 is a {} datatype.\".format(type(dialogs3)))"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint 1\n",
            "checkpoint 2\n",
            "checkpoint 3\n",
            "dialogs is a <class 'str'> datatype.\n",
            "sample of dialogs.dialogs 0 Can we make this quick? Roxanne Korrine and A... 1 Well, I thought we'd start with pronunciation,.\n",
            "checkpoint 4\n",
            "length of dialogs3 is 19199997\n",
            "dialogs3 is a <class 'str'> datatype.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HkLU2i_A2JZ",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1fRWsZcA2JZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "897bfc58-2d3a-49b2-f497-3b5f9c9dfea3"
      },
      "source": [
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
        "nlp.max_length = 36533517\n",
        "\n",
        "# all the processing work is done below, sit it may take a while, Lou.\n",
        "\n",
        "# alice_doc = nlp(alice)\n",
        "# persuasion_doc = nlp(persuasion)\n",
        "\n",
        "# dialogs4 = dialogs.dialogs.to_string()\n",
        "dialogs_doc = nlp(dialogs)\n",
        "print(\"length of dialogs_dialogs = {}\".format(len(dialogs)))"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "length of dialogs_dialogs = 6423357\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x2BmyvyA2Jc",
        "colab_type": "code",
        "outputId": "eacc7c5a-15c2-4431-d0a7-83bd67843080",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "# let's explore the objects that we've built...\n",
        "\n",
        "print(\"the dialogs_doc is a {} object.\".format(type(dialogs_doc)))\n",
        "print(\"It is {} tokens long.\".format(len(dialogs_doc)))\n",
        "print(\"the first three tokens are: '{}'\".format(dialogs_doc[0:30]))\n",
        "print(\"the type of each token is {}\".format(type(dialogs_doc[0])))"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the dialogs_doc is a <class 'spacy.tokens.doc.Doc'> object.\n",
            "It is 1548675 tokens long.\n",
            "the first three tokens are: '0 Can we make this quick? Roxanne Korrine and A... 1 Well, I thought we'd start with pronunciation,... 2 Not the hacking and gagging'\n",
            "the type of each token is <class 'spacy.tokens.token.Token'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-RUE-s7A2Je",
        "colab_type": "text"
      },
      "source": [
        "## Removing stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JH5bPzI1A2Je",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# alice_without_stopwords = [token for token in alice_doc if not token.is_stop]\n",
        "# persuasion_without_stopwords = [token for token in persuasion_doc if not token.is_stop]\n",
        "dialogs_without_stopwords = [token for token in dialogs_doc if not token.is_stop]\n",
        "dialogs_wihout_stopwords = [token for token in dialogs_doc if not token.is_punct]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G702kWCA2Jg",
        "colab_type": "code",
        "outputId": "333353f0-66d2-4e8f-db40-c5bf61442405",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(dialogs_doc_without_stopwords[0:30])"
      ],
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0,         , quick, ?,  , Roxanne, Korrine, ..., \n",
            ", 1,         , ,, thought, start, pronunciation, ,, ..., \n",
            ", 2,         , hacking, gagging, spitting, ...., \n",
            ", 3,         , Okay, ..., 'bout]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HHGp32NA2Jj",
        "colab_type": "code",
        "outputId": "dd8c3b2a-14c2-47c3-dbc3-4432b3590ad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# utility function to calculate how frequently words appear in the text\n",
        "def word_frequencies(text):\n",
        "    # build a list of words\n",
        "    # strip out punctuation\n",
        "    words = []\n",
        "    for token in text:\n",
        "        if not token.is_punct:\n",
        "            words.append(token.text) ## I just added lower() onto this function, and now all text items are lower!\n",
        "    \n",
        "    # build and return a Counter object containing the word counts\n",
        "    return Counter(words)\n",
        "\n",
        "# instantiate out list of most common words.\n",
        "# alice_word_freq = word_frequencies(alice_without_stopwords).most_common(10)\n",
        "# persuasion_word_freq = word_frequencies(persuasion_without_stopwords).most_common(10)\n",
        "dialogs_word_freq = word_frequencies(dialogs_without_stopwords).most_common(10)\n",
        "\n",
        "print('\\ndialogs', dialogs_word_freq)\n",
        "# print('Persuasion:', persuasion_word_freq)"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "dialogs [('know', 7695), ('got', 4185), ('like', 4055), ('Oh', 3786), ('think', 3738), ('want', 3702), ('Yes', 3303), ('Yeah', 3231), ('right', 3019), ('going', 2810)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLu7gMhHA2Jm",
        "colab_type": "text"
      },
      "source": [
        "## Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMXLfjFoA2Jm",
        "colab_type": "code",
        "outputId": "860708f2-de59-4c7d-e683-c610d0c9c88e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "def lemma_frequencies(text):\n",
        "    # build a list of lemas\n",
        "    # strip out punctuation\n",
        "    lemmas = []\n",
        "    for token in text:\n",
        "        if not token.is_punct:\n",
        "            lemmas.append(token.lemma_)\n",
        "            \n",
        "    # build and return a Counter object containing lemma counts\n",
        "    return Counter(lemmas)\n",
        "\n",
        "# instantiate out list of most common lemmas\n",
        "# alice_lemma_freq = lemma_frequencies(alice_without_stopwords).most_common(10)\n",
        "# persuasion_lemma_freq = lemma_frequencies(persuasion_without_stopwords).most_common(10)\n",
        "dialogs_lemma_freq = lemma_frequencies(dialogs_without_stopwords).most_common(10)\n",
        "\n",
        "print('\\ndialogs:' ,dialogs_lemma_freq)\n",
        "# print('Persuasion:' ,persuasion_lemma_freq)"
      ],
      "execution_count": 202,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "dialogs: [('know', 8614), ('think', 5278), ('go', 5216), ('get', 4979), ('like', 4712), ('want', 4675), ('oh', 3906), ('yes', 3904), ('yeah', 3761), ('tell', 3672)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4x1YR7rA2Jo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# alice_lemma_common = [pair[0] for pair in alice_lemma_freq]\n",
        "# persuasion_lemma_common = [pair[0] for pair in persuasion_lemma_freq]\n",
        "dialogs_lemma_common = [pair[0] for pair in dialogs_lemma_freq]\n",
        "\n",
        "\n",
        "# print('Unique to Alice:', set(alice_lemma_common) - set(persuasion_lemma_common))\n",
        "# print('Unique to Persuasion:', set(persuasion_lemma_common) - set(alice_lemma_common))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpiYzg7VA2Jr",
        "colab_type": "text"
      },
      "source": [
        "## Sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXLH9MnUA2Jr",
        "colab_type": "code",
        "outputId": "44fd6aa5-91f4-470c-ca7b-71c71faff1a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "# initial exploration of sentences\n",
        "sentences = list(dialogs_doc.sents)\n",
        "# print(\"dialogs has {} sentences.\".format(len(sentences)))\n",
        "\n",
        "example_sentences = sentences[0:10]\n",
        "for example_sentence in example_sentences: \n",
        "  print(\"Here is an example: \\n{}\\n\".format(example_sentence))"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Here is an example: \n",
            "0 Can we make this quick?\n",
            "\n",
            "Here is an example: \n",
            "Roxanne Korrine and A... 1 Well, I thought we'd start with pronunciation,... 2 Not the hacking and gagging and spitting part.... 3 Okay... then how 'bout we try out some French ... 4 You're asking me out.\n",
            "\n",
            "Here is an example: \n",
            "That's so cute.\n",
            "\n",
            "Here is an example: \n",
            "What's ... 5 Forget it.\n",
            "\n",
            "Here is an example: \n",
            "6 No, no, it's my fault -- we didn't have a prop... 7 Cameron.\n",
            "\n",
            "Here is an example: \n",
            "8 The thing is, Cameron -- I'm at the mercy of a... 9 Seems like she could get a date easy enough... 10 Why?\n",
            "\n",
            "Here is an example: \n",
            "11 Unsolved mystery.\n",
            "\n",
            "Here is an example: \n",
            "She used to be really popul... 12 That's a shame.\n",
            "\n",
            "Here is an example: \n",
            "13 Gosh, if only we could find Kat a boyfriend... 14 Let me see what I can do.\n",
            "\n",
            "Here is an example: \n",
            "15 C'esc ma tete.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ppXfEeNA2Jv",
        "colab_type": "code",
        "outputId": "49e90c28-ab92-4d78-f082-1152a5a4a471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# look at some metrics around this sentence\n",
        "\n",
        "example_words = [token for token in example_sentence if not token.is_punct]\n",
        "unique_words = set([token.text for token in example_words])\n",
        "\n",
        "print(\"this sentence is {}\".format(example_words))\n",
        "print((\"There are {} words in this sentence, and {} of them are unique\".format(len(example_words), len(unique_words))))"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this sentence is [15, C'esc, ma, tete]\n",
            "There are 4 words in this sentence, and 4 of them are unique\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmzLAf2jA2Jx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}