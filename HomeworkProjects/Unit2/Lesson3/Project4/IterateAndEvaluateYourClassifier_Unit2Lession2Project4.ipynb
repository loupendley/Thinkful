{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Unit 2 / Lesson 3 / Project 4 - Iterate and Evaluate Your Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's time to revisit your classifier from the previous assignment. Using the evaluation techniques we've covered here, look at your classifier's performance in more detail. Then go back and iterate by engineering new features, removing poor features, or tuning parameters. Repeat this process until you have five different versions of your classifier. Once you've iterated, answer these questions to compare the performance of each:\n",
    "\n",
    "Do any of your classifiers seem to overfit?\n",
    "Which seem to perform the best? Why?\n",
    "Which features seemed to be most impactful to performance?\n",
    "Write up your iterations and answers to the above questions in a few pages. Submit a link below and go over it with your mentor to see if they have any other ideas on how you could improve your classifier's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_encoding(fn):\n",
    "    import chardet\n",
    "        \n",
    "    with open(fn, 'rb') as f:\n",
    "        content = f.read()\n",
    "\n",
    "    charset = chardet.detect(content)\n",
    "    # {'encoding': 'EUC-JP', 'confidence': 0.99}\n",
    "    #print(\"character set = {}\".format(charset['encoding']))\n",
    "    \n",
    "    return charset['encoding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's process the data)\n",
    "def open_and_load_file (filename, columnnames):\n",
    "    file_encoding = get_file_encoding(filename)\n",
    "    df = pd.read_csv(filename, delimiter= '\\t', header=None, encoding=file_encoding) \n",
    "    df.columns = columnnames\n",
    "    return df, file_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_Bernoulli_supervised_learning(d1, t1):\n",
    "# Our data is binary / boolean, so we're importing the Bernoulli classifier.\n",
    "    from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "    # Instantiate our model and store it in a new variable.\n",
    "    global bnb\n",
    "    \n",
    "    bnb = BernoulliNB()\n",
    "\n",
    "    # Fit our model to the data.\n",
    "    bnb.fit(d1, target)\n",
    "\n",
    "    # Classify, storing the result in a new variable.\n",
    "    y_pred = bnb.predict(d1)\n",
    "\n",
    "    # Display our results.\n",
    "    return_message = \"Number of mislabeled points out of a total {} points : {}\".format(\n",
    "        d1.shape[0],\n",
    "        (t1 != y_pred).sum()\n",
    "    )\n",
    "\n",
    "    return (return_message, d1.shape[0], (t1 != y_pred).sum(), (t1 != y_pred).sum()/d1.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_the_keywords():\n",
    "    for key in keywords:\n",
    "        # Add spaces around the key so that we are getting theword,\n",
    "        # not just pattern matching\n",
    "        sms_raw[str(key)] = sms_raw.message.str.contains(' ' + str(key) + ' ', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_the_heatmap(subplotno):\n",
    "    plt.subplot(3,1,subplotno) \n",
    "    sns.heatmap(sms_raw.corr(), cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_data_and_target():\n",
    "    global data \n",
    "    data = sms_raw[keywords]\n",
    "    # data.sample(5)\n",
    "    \n",
    "    global target \n",
    "    target = sms_raw['spam']\n",
    "    # target.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test your model with different holdout groups.\n",
    "def run_with_the_holdouts(holdout_percent):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    # Use train_test_split to create the necessary training and test groups\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=holdout_percent, random_state=20)\n",
    "    print('With {0:.0%} Holdout: '.format(holdout_percent*1) + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "    print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_the_cross_validations():\n",
    "    from sklearn.model_selection import cross_val_score\n",
    "    return cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_diff_min_max_cv_score(cv_in):\n",
    "    print(\"min cv_score is {0:.4%}, and max is {1:.4%}, and delta is {2:.4%}\".format(cv_in.min(),\n",
    "                                                                      cv_in.max(), \n",
    "                                                                      cv_in.max()-cv_in.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refresh_data_frame(column_list):\n",
    "    data_frame = pd.read_csv(data_path, delimiter= '\\t', header=None)\n",
    "    data_frame.columns = column_list\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = (\"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "             \"master/sms_spam_collection/SMSSpamCollection\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration 0 - the one provided in the lesson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is iteration 0\n",
      "With 20% Holdout: 0.884304932735426\n",
      "Testing on Sample: 0.8916008614501076\n",
      "[0.89784946 0.89426523 0.89426523 0.890681   0.89605735 0.89048474\n",
      " 0.88150808 0.89028777 0.88489209 0.89568345]\n",
      "min cv_score is 88.1508%, and max is 89.7849%, and delta is 1.6341%\n"
     ]
    }
   ],
   "source": [
    "print(\"Here is iteration 0\")\n",
    "# let's get the data\n",
    "sms_raw = refresh_data_frame(['spam', 'message'])\n",
    "\n",
    "keywords = ['click', 'offer', 'winner', 'buy', 'free', 'cash', 'urgent']\n",
    "\n",
    "do_the_keywords()\n",
    "# set_data_and_target()\n",
    "\n",
    "sms_raw['allcaps'] = sms_raw.message.str.isupper()\n",
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "\n",
    "data = sms_raw[keywords + ['allcaps']]\n",
    "target = sms_raw['spam']\n",
    "\n",
    "xmsg, y, z, z2 = run_Bernoulli_supervised_learning(data, target)\n",
    "\n",
    "run_with_the_holdouts(0.20)\n",
    "cv_score=cross_val_score(bnb, data, target, cv=10)\n",
    "print(cv_score)\n",
    "return_diff_min_max_cv_score(cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is iteration 1\n",
      "With 15% Holdout: 0.888755980861244\n",
      "Testing on Sample: 0.8953697056712132\n",
      "[0.89642857 0.91071429 0.88928571 0.89285714 0.89285714 0.89605735\n",
      " 0.89964158 0.9028777  0.88848921 0.90647482 0.88848921 0.89928058\n",
      " 0.88489209 0.89208633 0.89928058 0.89208633 0.88848921 0.89568345\n",
      " 0.88489209 0.90647482]\n",
      "min cv_score is 88.4892%, and max is 91.0714%, and delta is 2.5822%\n"
     ]
    }
   ],
   "source": [
    "print(\"Here is iteration 1\")\n",
    "# let's get the data\n",
    "sms_raw = refresh_data_frame(['spam', 'message'])\n",
    "\n",
    "keywords = [ 'buy', 'free', 'cash', 'urgent', \"i'm\", 'u feel', 'please confirm', \"if you reply no\",\n",
    "           'to claim', 'UR']\n",
    "\n",
    "do_the_keywords()\n",
    "\n",
    "sms_raw['alllower'] = sms_raw.message.str.islower()\n",
    "\n",
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "\n",
    "data = sms_raw[keywords + ['alllower']]\n",
    "target = sms_raw['spam']\n",
    "\n",
    "xmsg, y, z, z2 = run_Bernoulli_supervised_learning(data, target)\n",
    "\n",
    "run_with_the_holdouts(.15)\n",
    "cv_score=cross_val_score(bnb, data, target, cv=20)\n",
    "print(cv_score)\n",
    "type(cv_score)\n",
    "return_diff_min_max_cv_score(cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is iteration 2\n",
      "With 15% Holdout: 0.8552631578947368\n",
      "Testing on Sample: 0.8749102656137832\n",
      "[0.875      0.86785714 0.86428571 0.86785714 0.87142857 0.86738351\n",
      " 0.87455197 0.86330935 0.88489209 0.88489209 0.87410072 0.88129496\n",
      " 0.87410072 0.8705036  0.88129496 0.87769784 0.88489209 0.8705036\n",
      " 0.8705036  0.88129496]\n",
      "min cv_score is 86.3309%, and max is 88.4892%, and delta is 2.1583%\n"
     ]
    }
   ],
   "source": [
    "print(\"Here is iteration 2\")\n",
    "# let's get the data\n",
    "sms_raw = refresh_data_frame(['spam', 'message'])\n",
    "\n",
    "keywords = [ '!!!', 'Please call', 'Gent', 'PRIVATE', 'sexy', 'unlimited', 'free2day', 'sex', 'matched',\n",
    "           'to order']\n",
    "\n",
    "do_the_keywords()\n",
    "\n",
    "sms_raw['alllower'] = sms_raw.message.str.islower()\n",
    "sms_raw['allcaps'] = sms_raw.message.str.isupper()\n",
    "\n",
    "\n",
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "\n",
    "data = sms_raw[keywords + ['allcaps'] + ['alllower']]\n",
    "\n",
    "target = sms_raw['spam']\n",
    "\n",
    "xmsg, y, z, z2 = run_Bernoulli_supervised_learning(data, target)\n",
    "\n",
    "run_with_the_holdouts(.15)\n",
    "cv_score=cross_val_score(bnb, data, target, cv=20)\n",
    "print(cv_score)\n",
    "return_diff_min_max_cv_score(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is iteration 3\n",
      "With 15% Holdout: 0.8971291866028708\n",
      "Testing on Sample: 0.9038047379755922\n",
      "[0.90357143 0.91785714 0.89642857 0.90714286 0.92142857 0.91397849\n",
      " 0.89964158 0.9028777  0.91726619 0.92446043 0.89208633 0.91366906\n",
      " 0.9028777  0.89208633 0.88848921 0.89568345 0.89208633 0.88848921\n",
      " 0.89928058 0.9028777 ]\n",
      "min cv_score is 88.8489%, and max is 92.4460%, and delta is 3.5971%\n"
     ]
    }
   ],
   "source": [
    "print(\"Here is iteration 3\")\n",
    "# let's get the data\n",
    "sms_raw = refresh_data_frame(['spam', 'message'])\n",
    "\n",
    "keywords = [ 'free','winner', 'follow instructions', 'txt', 'please call', 'urgent']\n",
    "\n",
    "do_the_keywords()\n",
    "\n",
    "sms_raw['allcaps'] = sms_raw.message.str.isupper()\n",
    "\n",
    "\n",
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "\n",
    "data = sms_raw[keywords + ['allcaps']]\n",
    "\n",
    "target = sms_raw['spam']\n",
    "\n",
    "xmsg, y, z, z2 = run_Bernoulli_supervised_learning(data, target)\n",
    "\n",
    "run_with_the_holdouts(.15)\n",
    "cv_score=cross_val_score(bnb, data, target, cv=20)\n",
    "print(cv_score)\n",
    "return_diff_min_max_cv_score(cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is iteration 4\n",
      "With 15% Holdout: 0.8755980861244019\n",
      "Testing on Sample: 0.8907035175879398\n",
      "[0.91071429 0.88571429 0.88571429 0.87857143 0.88571429 0.87455197\n",
      " 0.90322581 0.90647482 0.88489209 0.87410072 0.86690647 0.92086331\n",
      " 0.88129496 0.9028777  0.89208633 0.89208633 0.88848921 0.89208633\n",
      " 0.88848921 0.89208633]\n",
      "min cv_score is 86.6906%, and max is 92.0863%, and delta is 5.3957%\n"
     ]
    }
   ],
   "source": [
    "print(\"Here is iteration 4\")\n",
    "# let's get the data\n",
    "sms_raw = refresh_data_frame(['spam', 'message'])\n",
    "\n",
    "keywords = ['have won', 'will be charged', 'dating service', 'apply', 'pleases call',\n",
    "           'to unsubscribe', 'landline', 'to claim', 'private', 'fantasies', 'to stop',\n",
    "           'claim code']\n",
    "\n",
    "do_the_keywords()\n",
    "\n",
    "sms_raw['allcaps'] = sms_raw.message.str.isupper()\n",
    "\n",
    "\n",
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "\n",
    "data = sms_raw[keywords + ['allcaps']]\n",
    "\n",
    "target = sms_raw['spam']\n",
    "\n",
    "xmsg, y, z, z2 = run_Bernoulli_supervised_learning(data, target)\n",
    "\n",
    "run_with_the_holdouts(.15)\n",
    "cv_score=cross_val_score(bnb, data, target, cv=20)\n",
    "print(cv_score)\n",
    "return_diff_min_max_cv_score(cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iteration 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is iteration 5\n",
      "With 50% Holdout: 0.8743718592964824\n",
      "Testing on Sample: 0.8715003589375449\n",
      "[0.87142857 0.86785714 0.86785714 0.86785714 0.87142857 0.86379928\n",
      " 0.86738351 0.8705036  0.86690647 0.8705036  0.86690647 0.8705036\n",
      " 0.88129496 0.87769784 0.87410072 0.87410072 0.87769784 0.87769784\n",
      " 0.8705036  0.87410072]\n",
      "min cv_score is 86.3799%, and max is 88.1295%, and delta is 1.7496%\n"
     ]
    }
   ],
   "source": [
    "print(\"Here is iteration 5\")\n",
    "# let's get the data\n",
    "sms_raw = refresh_data_frame(['spam', 'message'])\n",
    "\n",
    "keywords = ['SMS SERVICES', 'to get', 'shit', 'sex', 'right now', 'important message',\n",
    "           'latest offers']\n",
    "keywords = ['reply or call', 'your number matches', 'see her', 'winner', 'reward']\n",
    "\n",
    "do_the_keywords()\n",
    "\n",
    "sms_raw['allcaps'] = sms_raw.message.str.isupper()\n",
    "\n",
    "\n",
    "sms_raw['spam'] = (sms_raw['spam'] == 'spam')\n",
    "\n",
    "data = sms_raw[keywords + ['allcaps']]\n",
    "\n",
    "target = sms_raw['spam']\n",
    "\n",
    "xmsg, y, z, z2 = run_Bernoulli_supervised_learning(data, target)\n",
    "\n",
    "run_with_the_holdouts(.50)\n",
    "cv_score=cross_val_score(bnb, data, target, cv=20)\n",
    "print(cv_score)\n",
    "return_diff_min_max_cv_score(cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "### Do any of your classifiers seem to overfit?\n",
    "Yes,  Iterations 3, and 4 had more than 3 percentage points different between min and max cv scores.  \n",
    "### Which seem to perform the best? Why?\n",
    "It seems that having too many keywords affected performance, and seemed to cause overfitting.  Less seems to be more, as the original example from the lesson.\n",
    "### Which features seemed to be most impactful to performance?\n",
    "Having multi-word keywords seems to be a hit, and having a few of the most relevant ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
